{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8Ks9t8FO3Ds5ijh7zoa0Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saurabhmungale/DataScience_Assignements/blob/main/deep_learning_frameworks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que.1)What is TensorFlow 2.0, and how is it different from TensorFlow 1 and 2"
      ],
      "metadata": {
        "id": "rxt0KTaFg97t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TensorFlow 2.0 is a major release of Google's TensorFlow framework, designed to make it easier to build, train, and deploy machine learning models. It introduced significant changes compared to TensorFlow 1.x, aiming to improve usability, performance, and integration with modern machine learning workflows. Here's an overview and the key differences:\n",
        "\n",
        "---\n",
        "\n",
        "### **Overview of TensorFlow 2.0**\n",
        "TensorFlow 2.0 emphasizes simplicity and ease of use by adopting a more Pythonic and intuitive API. It integrates tightly with Keras, providing high-level abstractions while retaining the power for more complex model-building tasks.\n",
        "\n",
        "---\n",
        "\n",
        "### **Key Differences Between TensorFlow 2.0 and TensorFlow 1.x**\n",
        "\n",
        "#### 1. **Eager Execution by Default**\n",
        "   - **TensorFlow 1.x:** Used a static computational graph that required defining the graph first and then executing it in a session (`tf.Session`).\n",
        "   - **TensorFlow 2.0:** Uses eager execution by default, allowing operations to be executed immediately. This makes debugging and prototyping much simpler and more intuitive.\n",
        "     ```python\n",
        "     # TensorFlow 2.0\n",
        "     a = tf.constant(3)\n",
        "     b = tf.constant(4)\n",
        "     print(a + b)  # Outputs the result directly\n",
        "     ```\n",
        "\n",
        "#### 2. **Integrated Keras API**\n",
        "   - **TensorFlow 1.x:** Keras was available as a separate library or module (`tf.keras`), but its integration was less seamless.\n",
        "   - **TensorFlow 2.0:** Fully integrates the `tf.keras` module as the high-level API for model creation, training, and deployment. This ensures compatibility and consistency with TensorFlow's ecosystem.\n",
        "\n",
        "#### 3. **Simplified APIs**\n",
        "   - **TensorFlow 1.x:** Had a complex, sometimes inconsistent API with overlapping functionalities across different namespaces.\n",
        "   - **TensorFlow 2.0:** Streamlines APIs, making them more consistent and removing redundant functions.\n",
        "\n",
        "#### 4. **No More `tf.Session`**\n",
        "   - **TensorFlow 1.x:** Required the use of `tf.Session` to execute operations.\n",
        "   - **TensorFlow 2.0:** Eliminates the need for `tf.Session` due to eager execution.\n",
        "\n",
        "#### 5. **Enhanced `@tf.function` Decorator**\n",
        "   - Allows for converting Python functions into TensorFlow graphs for optimized performance. This bridges the gap between eager execution's flexibility and the efficiency of static graphs.\n",
        "\n",
        "#### 6. **Updated Estimator and Dataset API**\n",
        "   - The Estimator API is now more compatible with Keras models.\n",
        "   - The `tf.data` API for handling datasets is emphasized for better performance and scalability in data preprocessing pipelines.\n",
        "\n",
        "#### 7. **Backward Incompatibility**\n",
        "   - Some TensorFlow 1.x code is not directly compatible with TensorFlow 2.0. To assist with migration, TensorFlow provides a [compatibility module (`tf.compat.v1`)](https://www.tensorflow.org/guide/upgrade).\n",
        "\n",
        "#### 8. **Tight Integration with TensorFlow Extended (TFX)**\n",
        "   - TensorFlow 2.0 emphasizes the entire ML pipeline, supporting seamless deployment with tools like TensorFlow Extended (TFX) and TensorFlow Lite for mobile and embedded devices.\n",
        "\n",
        "#### 9. **Improved Documentation and Tutorials**\n",
        "   - TensorFlow 2.0 provides better, more structured guides and tutorials, making it easier for developers and researchers to learn and apply.\n",
        "\n",
        "---\n",
        "\n",
        "### **Why Use TensorFlow 2.0?**\n",
        "1. **Easier Debugging and Prototyping:** Eager execution allows for immediate feedback.\n",
        "2. **Better Performance:** Optimized for modern hardware and workflows.\n",
        "3. **Unified Ecosystem:** Tight integration with Keras and TFX makes end-to-end machine learning tasks simpler.\n",
        "4. **Future-Proof:** TensorFlow 2.0 is the standard for future developments, with active community support and updates.\n"
      ],
      "metadata": {
        "id": "yctmTlU6iSlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorFlow 2.0\n",
        "import tensorflow as tf\n",
        "a = tf.constant(3)\n",
        "b = tf.constant(4)\n",
        "print(a + b)  # Outputs the result directly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqi9-bfIiY6S",
        "outputId": "e77a93aa-103b-424d-81bd-c8e9b1058bb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(7, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "QUe.2)How do you install TensorFlow 2.02"
      ],
      "metadata": {
        "id": "AAXPtNe4ipff"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solution - To install TensorFlow 2.0, you can use Python's package manager, pip, in your Python environment. Follow these steps:\n",
        "1. Prerequisites\n",
        "Python Version: TensorFlow 2.0 supports Python 3.7+ (check your version with python --version).\n",
        "Pip Version: Ensure pip is updated\n"
      ],
      "metadata": {
        "id": "WLC2SAzhi7EE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade pip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tl7drxkRjeyw",
        "outputId": "8910a706-b79c-4e50-df38-bc6423edace7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-24.3.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Downloading pip-24.3.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-24.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Install TensorFlow 2.0\n"
      ],
      "metadata": {
        "id": "agAlQo6cjm2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow==2.0.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3m5kOhBSjrgg",
        "outputId": "9eb21af5-8352-441e-8438-fc2e087366e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.0.0 (from versions: 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0, 2.11.1, 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.12.1, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0, 2.13.1, 2.14.0rc0, 2.14.0rc1, 2.14.0, 2.14.1, 2.15.0rc0, 2.15.0rc1, 2.15.0, 2.15.0.post1, 2.15.1, 2.16.0rc0, 2.16.1, 2.16.2, 2.17.0rc0, 2.17.0rc1, 2.17.0, 2.17.1, 2.18.0rc0, 2.18.0rc1, 2.18.0rc2, 2.18.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==2.0.0\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Verify INstallation"
      ],
      "metadata": {
        "id": "vGKuR4uAjuaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07IR0mynj5Zo",
        "outputId": "ddc780f7-e5b4-452d-fb9d-f20704a53c53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.17.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. GPU Support (Optional)\n",
        "If you have a compatible NVIDIA GPU and want to leverage it for acceleration:\n",
        "\n"
      ],
      "metadata": {
        "id": "WjsYFZAuj8hE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow-gpu==2.0.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbFnSjcJkFZE",
        "outputId": "d988d8ff-d441-4328-db20-3bd7245341f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow-gpu==2.0.0 (from versions: 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0, 2.12.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow-gpu==2.0.0\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Use in Virtual Environment (Recommended)\n"
      ],
      "metadata": {
        "id": "_SKjsOnlkIOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a virtual environment\n",
        "!python -m venv tf_env\n",
        "# Activate the environment\n",
        "!source tf_env/bin/activate  # On Windows, use `tf_env\\Scripts\\activate`\n",
        "# Install TensorFlow\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ropeBwKhkJGC",
        "outputId": "6e2135cd-d61f-4d14-d861-757019db6864"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The virtual environment was not created successfully because ensurepip is not\n",
            "available.  On Debian/Ubuntu systems, you need to install the python3-venv\n",
            "package using the following command.\n",
            "\n",
            "    apt install python3.10-venv\n",
            "\n",
            "You may need to use sudo with that command.  After installing the python3-venv\n",
            "package, recreate your virtual environment.\n",
            "\n",
            "Failing command: /content/tf_env/bin/python3\n",
            "\n",
            "/bin/bash: line 1: tf_env/bin/activate: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "QUe.3) What is the primary function of the tf.function in TensorFlow 2.02"
      ],
      "metadata": {
        "id": "kts5MmtVkgOh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The primary function of tf.function in TensorFlow 2.0 is to convert a Python function into a TensorFlow graph for optimized execution. This enables the function to benefit from the performance improvements of TensorFlow's graph execution, such as parallelism, better optimization, and portability across different platforms.\n",
        "\n",
        "\n",
        "How tf.function Works\n",
        "Eager Execution: TensorFlow 2.0 uses eager execution by default, which is intuitive and easy to debug but can be slower for large computations.\n",
        "Graph Execution: When a Python function is decorated with @tf.function, TensorFlow traces the operations and builds a computational graph. This graph is then optimized for better performance.\n",
        "\n",
        "\n",
        "Usage Example\n",
        "\n"
      ],
      "metadata": {
        "id": "XTFQ8QN8km7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define a simple function\n",
        "@tf.function\n",
        "def add_numbers(x, y):\n",
        "    return x + y\n",
        "\n",
        "# Test the function\n",
        "x = tf.constant(3)\n",
        "y = tf.constant(5)\n",
        "\n",
        "result = add_numbers(x, y)\n",
        "print(result)  # Outputs: tf.Tensor(8, shape=(), dtype=int32)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CUqOO2Rk0FE",
        "outputId": "562adfad-9882-40b8-9b35-233bbb0cebce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(8, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The primary function of tf.function in TensorFlow 2.0 is to convert a Python function into a TensorFlow graph for optimized execution. This enables the function to benefit from the performance improvements of TensorFlow's graph execution, such as parallelism, better optimization, and portability across different platforms.\n",
        "\n",
        "How tf.function Works\n",
        "Eager Execution: TensorFlow 2.0 uses eager execution by default, which is intuitive and easy to debug but can be slower for large computations.\n",
        "Graph Execution: When a Python function is decorated with @tf.function, TensorFlow traces the operations and builds a computational graph. This graph is then optimized for better performance.\n",
        "Key Benefits of tf.function\n",
        "Performance Optimization:\n",
        "\n",
        "Graph execution is faster than eager execution, especially for repeated or large-scale computations.\n",
        "TensorFlow performs operation-level optimizations.\n",
        "Portability:\n",
        "\n",
        "Functions converted to graphs can be exported and run on different platforms, such as mobile (with TensorFlow Lite) or in production systems.\n",
        "Parallelism and Device Support:\n",
        "\n",
        "Graphs are optimized to leverage GPUs, TPUs, or multiple CPUs efficiently.\n",
        "Serialization:\n",
        "\n",
        "A graph can be saved as part of a TensorFlow SavedModel, making it deployable across environments.\n",
        "Usage Example\n",
        "python\n",
        "Copy code\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define a simple function\n",
        "@tf.function\n",
        "def add_numbers(x, y):\n",
        "    return x + y\n",
        "\n",
        "# Test the function\n",
        "x = tf.constant(3)\n",
        "y = tf.constant(5)\n",
        "\n",
        "result = add_numbers(x, y)\n",
        "print(result)  # Outputs: tf.Tensor(8, shape=(), dtype=int32)\n",
        "Comparison Without tf.function\n",
        "Without @tf.function, the function executes eagerly:\n",
        "\n",
        "python\n",
        "Copy code\n",
        "def add_numbers_eager(x, y):\n",
        "    return x + y\n",
        "\n",
        "result_eager = add_numbers_eager(x, y)\n",
        "print(result_eager)  # Outputs: tf.Tensor(8, shape=(), dtype=int32)\n",
        "While the output looks similar, the eager execution is less efficient for larger computations. Wrapping it with @tf.function boosts performance.\n",
        "\n",
        "Debugging tf.function\n",
        "When using @tf.function, the Python function is traced and converted into a graph, so standard Python debugging (e.g., print statements) might not work as expected. To debug, you can disable @tf.function temporarily or use tf.print instead of print.\n",
        "Would you like a practical example involving a more complex function or advice on debugging with tf.function?"
      ],
      "metadata": {
        "id": "j5zQsq9ak31w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que.4)What is the purpose of the Model class in TensorFlow 2.02"
      ],
      "metadata": {
        "id": "KXv7KoM0k6s5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solution - The Model class in TensorFlow 2.0 is a central component of the Keras API, which is tightly integrated with TensorFlow. It is used to define, train, and evaluate machine learning models in a structured and scalable way. The Model class is derived from tf.keras.layers.Layer and provides additional functionality tailored to complete machine learning workflows.\n",
        "\n",
        "Purpose of the Model Class\n",
        "The Model class serves as the foundation for building machine learning models in TensorFlow 2.0, offering tools for:\n",
        "\n",
        "1.Defining Models:\n",
        "\n",
        "Enables the creation of models by stacking layers or by using a functional or subclassing approach.\n",
        "\n",
        "2.Training Models:\n",
        "\n",
        "Provides methods like .fit() for training with ease, handling data batching, optimization, and callbacks.\n",
        "\n",
        "\n",
        "3.Evaluation:\n",
        "\n",
        "Offers methods like .evaluate() to measure the model's performance on validation or test data.\n",
        "\n",
        "\n",
        "4.Prediction:\n",
        "\n",
        "Facilitates inference with the .predict() method.\n",
        "\n",
        "\n",
        "5.Model Saving and Loading:\n",
        "\n",
        "Supports saving and restoring models using .save() and .load_model() for deployment or further training.\n",
        "\n",
        "\n",
        "Ways to Use the Model Class\n",
        "1. Using the Sequential API\n",
        "A simple stack of layers."
      ],
      "metadata": {
        "id": "onRlF7PCk_1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(32,)),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "kFRAoBMkltd3",
        "outputId": "46afe239-09d5-48a2-81d1-93be68284045"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m2,112\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m650\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,762\u001b[0m (10.79 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,762</span> (10.79 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,762\u001b[0m (10.79 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,762</span> (10.79 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Using the Functional API\n",
        "Enables creating complex models like multi-input or multi-output models"
      ],
      "metadata": {
        "id": "C7xp9HGFlyF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Model, Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "inputs = Input(shape=(32,))\n",
        "x = Dense(64, activation='relu')(inputs)\n",
        "outputs = Dense(10, activation='softmax')(x)\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "go_fkrY_l2bi",
        "outputId": "60489313-51e9-4898-dc89-7d6f5c768890"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m2,112\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m650\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,762\u001b[0m (10.79 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,762</span> (10.79 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,762\u001b[0m (10.79 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,762</span> (10.79 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Subclassing the Model Class\n",
        "For advanced use cases where complete customization is required."
      ],
      "metadata": {
        "id": "j-XGoYiIl5d9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "class MyModel(Model):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.dense1 = Dense(64, activation='relu')\n",
        "        self.dense2 = Dense(10, activation='softmax')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.dense1(inputs)\n",
        "        return self.dense2(x)\n",
        "\n",
        "model = MyModel()\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "YgZEWVa1l6sv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que.5)How do you create a neural network using TensorFlow 2.02"
      ],
      "metadata": {
        "id": "Jbl-L-Abl_CY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a neural network in TensorFlow 2.0 involves the following key steps:\n",
        "\n",
        "Define the architecture of the neural network.\n",
        "Compile the model by specifying the optimizer, loss function, and metrics.\n",
        "Train the model using a dataset.\n",
        "Evaluate and make predictions.\n",
        "Here are examples of creating a neural network using three common approaches in TensorFlow 2.0:\n",
        "\n"
      ],
      "metadata": {
        "id": "c21pJ3yqmank"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Using the Sequential API\n",
        "The Sequential API is best suited for simple, linear stacks of layers."
      ],
      "metadata": {
        "id": "J6x3LOENmdfo"
      }
    },
    {
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Generate some sample data (replace with your actual data)\n",
        "X = np.random.rand(100, 64)  # 100 samples with 64 features\n",
        "y = np.random.randint(0, 10, size=100)  # 100 labels (0-9)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(64,)),  # Input layer\n",
        "    Dense(64, activation='relu'),                     # Hidden layer\n",
        "    Dense(10, activation='softmax')                   # Output layer\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "# Evaluate the model\n",
        "model.evaluate(X_test, y_test)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51BJtDpHmoWw",
        "outputId": "1d516ef0-f231-4e7b-f46e-9b6d50d24cb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1211 - loss: 2.3462\n",
            "Epoch 2/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2547 - loss: 2.2683 \n",
            "Epoch 3/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2273 - loss: 2.1998 \n",
            "Epoch 4/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2641 - loss: 2.1564 \n",
            "Epoch 5/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2805 - loss: 2.1333 \n",
            "Epoch 6/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3508 - loss: 2.1032 \n",
            "Epoch 7/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3453 - loss: 2.1018 \n",
            "Epoch 8/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3664 - loss: 2.0489 \n",
            "Epoch 9/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3945 - loss: 2.0042 \n",
            "Epoch 10/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3477 - loss: 2.0020 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.1500 - loss: 2.3887\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.3887438774108887, 0.15000000596046448]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Using the Functional API\n",
        "The Functional API allows for building more complex architectures like multi-input/output models, skip connections, etc.\n",
        "\n"
      ],
      "metadata": {
        "id": "OJTzMq6gmv3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Model, Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Define the model\n",
        "inputs = Input(shape=(64,))\n",
        "x = Dense(128, activation='relu')(inputs)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "outputs = Dense(10, activation='softmax')(x)\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "# Evaluate the model\n",
        "model.evaluate(X_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYUyo32fm1QY",
        "outputId": "16413647-236f-44af-f9e8-d0cae816ebdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.0523 - loss: 2.3601\n",
            "Epoch 2/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1859 - loss: 2.2496 \n",
            "Epoch 3/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1953 - loss: 2.1995 \n",
            "Epoch 4/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1859 - loss: 2.1915 \n",
            "Epoch 5/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1820 - loss: 2.1675 \n",
            "Epoch 6/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1937 - loss: 2.1225 \n",
            "Epoch 7/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2047 - loss: 2.1082 \n",
            "Epoch 8/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2398 - loss: 2.0626 \n",
            "Epoch 9/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2773 - loss: 2.0398 \n",
            "Epoch 10/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3953 - loss: 1.9925 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.0500 - loss: 2.3859\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.3859453201293945, 0.05000000074505806]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Using Subclassing\n",
        "Subclassing the Model class provides maximum flexibility, ideal for dynamic architectures or custom training loops.\n"
      ],
      "metadata": {
        "id": "LzFWhwDPm5Ud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "class MyModel(Model):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.dense1 = Dense(128, activation='relu')\n",
        "        self.dense2 = Dense(64, activation='relu')\n",
        "        self.dense3 = Dense(10, activation='softmax')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.dense1(inputs)\n",
        "        x = self.dense2(x)\n",
        "        return self.dense3(x)\n",
        "\n",
        "# Instantiate the model\n",
        "model = MyModel()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "# Evaluate the model\n",
        "model.evaluate(X_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7uR9zqdm9jt",
        "outputId": "76d1b0a4-b920-4be8-b73e-6346175d10c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.0547 - loss: 2.3805\n",
            "Epoch 2/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0914 - loss: 2.3033 \n",
            "Epoch 3/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1430 - loss: 2.2381 \n",
            "Epoch 4/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2234 - loss: 2.2077 \n",
            "Epoch 5/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2562 - loss: 2.1710 \n",
            "Epoch 6/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2742 - loss: 2.1548 \n",
            "Epoch 7/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3484 - loss: 2.1169 \n",
            "Epoch 8/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3734 - loss: 2.0915 \n",
            "Epoch 9/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4172 - loss: 2.0675 \n",
            "Epoch 10/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3812 - loss: 2.0471 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.0500 - loss: 2.4631\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.463078737258911, 0.05000000074505806]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que.6)What is the importance of Tensor Space in TensorFlow2"
      ],
      "metadata": {
        "id": "6aviJC-AnBsQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solution-In TensorFlow 2.0, the concept of Tensor Space is fundamental because TensorFlow operates on tensors as its primary data structure. Understanding tensor spaces is crucial for defining, manipulating, and applying operations in machine learning models. Here's an explanation of the importance and role of tensor space in TensorFlow:\n",
        "\n",
        "\n",
        "In TensorFlow 2.0, the concept of Tensor Space is fundamental because TensorFlow operates on tensors as its primary data structure. Understanding tensor spaces is crucial for defining, manipulating, and applying operations in machine learning models. Here's an explanation of the importance and role of tensor space in TensorFlow:\n",
        "\n",
        "What is Tensor Space?\n",
        "A tensor space refers to the multi-dimensional array structure that encompasses all possible tensors of a specific shape, type, and size. Tensors generalize matrices to higher dimensions, forming the backbone of TensorFlow computations.\n",
        "\n",
        "Scalars: 0D tensors (e.g., single values like 3.0).\n",
        "Vectors: 1D tensors (e.g., [1.0, 2.0, 3.0]).\n",
        "Matrices: 2D tensors (e.g., a table of values like a grayscale image).\n",
        "Higher-Dimensional Tensors: 3D and above (e.g., RGB images, video sequences, etc.).\n",
        "\n",
        "\n",
        "\n",
        "Importance of Tensor Space in TensorFlow\n",
        "1. Foundation of Computation\n",
        "TensorFlow's operations are designed to work directly on tensors in the tensor space.\n",
        "Any machine learning operation, from addition to matrix multiplication, transforms input tensors into output tensors.\n",
        "2. Representation of Data\n",
        "All data in TensorFlow (e.g., images, text embeddings, time-series data) is represented as tensors.\n",
        "Example:\n",
        "A grayscale image of size 28x28 is a tensor of shape (28, 28).\n",
        "A batch of 32 such images is a tensor of shape (32, 28, 28).\n",
        "3. Multi-Dimensional Operations\n",
        "Tensor space facilitates operations across multiple dimensions simultaneously, enabling efficient computation for tasks like matrix multiplications, convolutions, and broadcasting.\n",
        "Example: In a neural network, weights and biases are tensors that interact with input data (also tensors).\n",
        "4. Efficient Resource Utilization\n",
        "TensorFlow is optimized for tensor operations, leveraging hardware acceleration (GPUs, TPUs) to process tensor data efficiently.\n",
        "5. Scalability\n",
        "Tensor spaces generalize computation to higher dimensions, making TensorFlow suitable for handling large datasets, multi-channel images, sequences, and more.\n",
        "6. Compatibility with Machine Learning Models\n",
        "Tensor spaces allow easy representation and manipulation of:\n",
        "Features (input tensors).\n",
        "Labels (output tensors).\n",
        "Weights and biases (model parameters).\n",
        "7. Facilitates Gradient Calculations\n",
        "TensorFlow uses tensors to calculate gradients during backpropagation. This is crucial for optimization in deep learning.\n",
        "8. Device Independence\n",
        "Tensor space abstracts data manipulation so that tensors can seamlessly move across devices (CPU, GPU, TPU) without altering the operations or models.\n",
        "\n"
      ],
      "metadata": {
        "id": "fyidQuuUnIAM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example"
      ],
      "metadata": {
        "id": "etSXIXcfngh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Scalar (0D tensor)\n",
        "scalar = tf.constant(5)\n",
        "print(scalar.shape)  # ()\n",
        "\n",
        "# Vector (1D tensor)\n",
        "vector = tf.constant([1, 2, 3])\n",
        "print(vector.shape)  # (3,)\n",
        "\n",
        "# Matrix (2D tensor)\n",
        "matrix = tf.constant([[1, 2], [3, 4]])\n",
        "print(matrix.shape)  # (2, 2)\n",
        "\n",
        "# Higher-Dimensional Tensor\n",
        "tensor = tf.constant([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
        "print(tensor.shape)  # (2, 2, 2)\n"
      ],
      "metadata": {
        "id": "FSOrh5RwniYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que.7)How can TensorBoard be integrated with TensorFlow 2.02"
      ],
      "metadata": {
        "id": "52RW1YaAnIOL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solution -  \n",
        "TensorBoard is a powerful tool integrated with TensorFlow 2.0 that helps in visualizing and monitoring various aspects of machine learning workflows, such as metrics, graphs, and distributions. It’s often used for debugging, comparing models, and gaining insights into training dynamics.\n",
        "\n",
        "Here’s how TensorBoard can be integrated with TensorFlow 2.0:\n",
        "\n",
        "\n",
        " 1.Setting Up TensorBoard\n"
      ],
      "metadata": {
        "id": "QbuNVKMnnIR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorboard\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDhuGIR6oCXa",
        "outputId": "cafa0b4d-49cd-4526-c684-c6ad1bc71b67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.68.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.7)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboard) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (4.25.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import TensorBoard:\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import TensorBoard\n"
      ],
      "metadata": {
        "id": "in8OvXBjoE3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Logging Data for TensorBoard"
      ],
      "metadata": {
        "id": "MSD514s_oL0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "log_dir = os.path.join(\"logs\", \"fit\", \"model_1\")\n"
      ],
      "metadata": {
        "id": "gasrtyeFoMx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Using TensorBoard with Model Training\n"
      ],
      "metadata": {
        "id": "pZIYj0mEoR9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n"
      ],
      "metadata": {
        "id": "ccxMO3N6oT-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assume X and y are your original data\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42  # Adjust test_size as needed\n",
        ")\n",
        "\n",
        "# Now you can use X_val and y_val in model.fit\n",
        "model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=10,\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=[tensorboard_callback],\n",
        ")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nyNfStRojdh",
        "outputId": "d945165e-bf11-4d7f-ec0a-7776aa0d666f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 138ms/step - accuracy: 0.0445 - loss: 2.3687 - val_accuracy: 0.0500 - val_loss: 2.3362\n",
            "Epoch 2/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.1352 - loss: 2.2804 - val_accuracy: 0.0000e+00 - val_loss: 2.3698\n",
            "Epoch 3/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.1695 - loss: 2.2344 - val_accuracy: 0.0500 - val_loss: 2.4036\n",
            "Epoch 4/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.1969 - loss: 2.1781 - val_accuracy: 0.0500 - val_loss: 2.4325\n",
            "Epoch 5/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.2133 - loss: 2.1605 - val_accuracy: 0.0500 - val_loss: 2.4375\n",
            "Epoch 6/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.2180 - loss: 2.1362 - val_accuracy: 0.1500 - val_loss: 2.4363\n",
            "Epoch 7/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.2758 - loss: 2.0920 - val_accuracy: 0.1500 - val_loss: 2.4292\n",
            "Epoch 8/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.2875 - loss: 2.0931 - val_accuracy: 0.1000 - val_loss: 2.4159\n",
            "Epoch 9/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.3344 - loss: 2.0839 - val_accuracy: 0.1000 - val_loss: 2.4076\n",
            "Epoch 10/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.3727 - loss: 2.0372 - val_accuracy: 0.1500 - val_loss: 2.4077\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7cee5a094f70>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Launching TensorBoard\n"
      ],
      "metadata": {
        "id": "0opPb13bopLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorboard --logdir logs/fit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOeY3CzloqeY",
        "outputId": "865dc1f3-b151-4535-a806-86c6d53aea28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-30 05:55:02.298981: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-30 05:55:02.323705: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-30 05:55:02.330911: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-30 05:55:04.079118: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            "NOTE: Using experimental fast data loading logic. To disable, pass\n",
            "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
            "    https://github.com/tensorflow/tensorboard/issues/4784\n",
            "\n",
            "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
            "TensorBoard 2.17.1 at http://localhost:6006/ (Press CTRL+C to quit)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que.8)What is the purpose of TensorFlow Playground2"
      ],
      "metadata": {
        "id": "t12c7THToywk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solution- The TensorFlow Playground is an interactive, browser-based tool designed to help users intuitively understand the workings of neural networks. Though not a part of TensorFlow itself, it serves as an educational tool, particularly for beginners, by visually demonstrating the behavior and learning process of neural networks.\n",
        "\n",
        "Purpose of TensorFlow Playground\n",
        "Educational Tool:\n",
        "\n",
        "TensorFlow Playground simplifies complex concepts in neural networks, such as activation functions, hidden layers, overfitting, and learning rates, making them accessible to beginners.\n",
        "Experimentation Platform:\n",
        "\n",
        "It allows users to experiment with different architectures and hyperparameters without needing to write code.\n",
        "Visualization of Training:\n",
        "\n",
        "Users can observe how weights and biases evolve during training, how decision boundaries form, and how the network adjusts to classify data.\n",
        "Understanding Key Concepts:\n",
        "\n",
        "TensorFlow Playground is ideal for grasping concepts like:\n",
        "Non-linearity and why activation functions are critical.\n",
        "The role of layers and neurons in solving complex problems.\n",
        "Overfitting and how regularization or dropout can mitigate it.\n",
        "Learning rate and its impact on convergence speed.\n",
        "Quick Prototyping:\n",
        "\n",
        "It’s a lightweight and fast way to see how certain changes to a network affect its performance without setting up a full TensorFlow project."
      ],
      "metadata": {
        "id": "0MAzWOheo4hj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "QUe.9What is Netron, and how is it useful for deep learning models2"
      ],
      "metadata": {
        "id": "slfjVMxdpAxx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solution - Netron is an open-source visualizer for deep learning, machine learning, and neural network models. It provides a graphical representation of model architectures, allowing users to inspect their layers, operations, and parameters interactively.\n",
        "\n",
        "\n",
        "Purpose of Netron\n",
        "Netron is primarily used to:\n",
        "\n",
        "Visualize Model Architectures:\n",
        "\n",
        "It offers a clear, detailed view of how a deep learning model is structured, including the flow of data through layers.\n",
        "Supports models from various frameworks, such as TensorFlow, PyTorch, Keras, ONNX, and more.\n",
        "Debugging and Inspection:\n",
        "\n",
        "Helps identify issues in a model’s structure, such as missing layers or incorrect connections.\n",
        "Provides insights into the shapes and types of inputs/outputs for each layer.\n",
        "Explaining Models:\n",
        "\n",
        "Ideal for presenting and explaining models to non-technical stakeholders or beginners.\n",
        "Facilitates understanding of model complexity and workflow.\n",
        "Verifying Model Conversion:\n",
        "\n",
        "Use Cases of Netron\n",
        "1. Inspecting a Model's Architecture\n",
        "Verify the order and types of layers in a model.\n",
        "Example: Confirm that a ResNet model contains residual connections.\n",
        "2. Understanding Input and Output Shapes\n",
        "Identify the expected input dimensions and output shapes for the model.\n",
        "3. Checking Layer Parameters\n",
        "Inspect layer-specific details like:\n",
        "Filter size in convolutional layers.\n",
        "Number of neurons in dense layers.\n",
        "Activation functions used.\n",
        "4. Debugging Model Export Issues\n",
        "When exporting models to formats like ONNX or TensorFlow Lite, use Netron to ensure the exported architecture matches the original.\n",
        "5. Educational and Presentation Tool\n",
        "Use Netron to explain complex architectures like transformers or convolutional neural networks (CNNs) during presentations or training.\n",
        "\n",
        "\n",
        "Useful when converting models between formats (e.g., TensorFlow to ONNX) to ensure no discrepancies exist in architecture.\n",
        "Parameter Inspection:\n",
        "\n",
        "Allows users to examine layer-specific details like weights, biases, kernel sizes, and activation functions.\n"
      ],
      "metadata": {
        "id": "7KSgHe2BpBuH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que.10.  What is the difference between TensorFlow and PyTorch2"
      ],
      "metadata": {
        "id": "XGCbbdpApk1O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solution- TensorFlow and PyTorch are two of the most popular deep learning frameworks, and while they both offer powerful tools for building and training machine learning models, they have several key differences in terms of usability, design philosophy, and implementation. Here's a detailed comparison:\n",
        "\n",
        "1. Framework Design: Static vs Dynamic Computation Graphs\n",
        "TensorFlow (1.x):\n",
        "\n",
        "Originally, TensorFlow used a static computation graph, where the model is defined first, and the computations (graph) are executed later in a session. This means you have to define the entire model structure before running any operations.\n",
        "However, TensorFlow 2.x introduced Eager Execution, making it more dynamic like PyTorch. Now, TensorFlow can run operations immediately, without needing to build and compile a graph first.\n",
        "PyTorch:\n",
        "\n",
        "Dynamic computation graph (also known as define-by-run). This means that the graph is built on the fly as operations are executed. You define the model as you go, and the computation graph is built during runtime, making debugging easier and more intuitive.\n",
        "2. Ease of Use\n",
        "TensorFlow:\n",
        "\n",
        "TensorFlow (prior to version 2.0) was often considered harder to use due to its static nature and the need for sessions, placeholders, and complicated configurations. TensorFlow 2.0 improved usability by focusing on Keras integration as its default high-level API for model building.\n",
        "TensorFlow 2.0 is more beginner-friendly, especially for those using Keras for high-level model building, but still provides flexibility for experts to work with low-level operations.\n",
        "PyTorch:\n",
        "\n",
        "PyTorch is generally regarded as more Pythonic and easier to use due to its dynamic nature. The models are defined in an intuitive, imperative style where code execution and graph building happen simultaneously.\n",
        "The syntax is closer to standard Python code, and it’s often considered easier to debug and experiment with.\n",
        "3. Performance and Scalability\n",
        "TensorFlow:\n",
        "\n",
        "TensorFlow is known for its high scalability and is optimized for production environments. It has features like TensorFlow Serving for serving models in production and TensorFlow Lite for mobile and embedded devices.\n",
        "TensorFlow has strong support for distributed computing and multi-GPU/TPU setups, which is useful for large-scale training.\n",
        "PyTorch:\n",
        "\n",
        "PyTorch is slightly less optimized for production out of the box, though recent updates like TorchServe (for serving models) and TorchScript (for optimizing models for production) have improved its scalability.\n",
        "PyTorch also supports multi-GPU and distributed training through libraries like torch.nn.DataParallel and DistributedDataParallel.\n",
        "4. Deployment\n",
        "TensorFlow:\n",
        "\n",
        "TensorFlow has strong deployment support. It integrates seamlessly with TensorFlow Serving for serving models in production and also has TensorFlow Lite for mobile applications and TensorFlow.js for deploying models in the browser.\n",
        "The framework also supports TensorFlow Hub for sharing and reusing models.\n",
        "PyTorch:\n",
        "\n",
        "PyTorch used to lag behind in deployment tools but now supports TorchServe for serving models and TorchScript for optimizing models for production. ONNX (Open Neural Network Exchange) also allows PyTorch models to be converted and deployed in other environments, like TensorFlow.\n",
        "5. Ecosystem and Libraries\n",
        "TensorFlow:\n",
        "TensorFlow has a rich ecosystem, including tools like:\n",
        "TensorFlow Hub for reusable model components.\n",
        "TensorFlow Lite for mobile and embedded devices.\n",
        "TensorFlow.js for browser-based ML.\n",
        "TensorFlow Extended (TFX) for end-to-end machine learning pipelines.\n",
        "TensorFlow Datasets (TFDS) for accessing datasets.\n",
        "PyTorch:\n",
        "PyTorch has a smaller, but growing ecosystem. Some notable libraries include:\n",
        "TorchVision for computer vision tasks.\n",
        "TorchText for natural language processing (NLP).\n",
        "PyTorch Lightning for simplifying model training and scaling.\n",
        "Hugging Face Transformers integrates seamlessly with PyTorch for state-of-the-art NLP models.\n",
        "6. Debugging\n",
        "TensorFlow:\n",
        "TensorFlow 2.0's Eager Execution allows for easier debugging since you can inspect operations step by step. However, TensorFlow 1.x’s static graph structure was harder to debug because the graph was built before execution.\n",
        "PyTorch:\n",
        "Dynamic graphs in PyTorch make it easier to debug using standard Python debugging tools like pdb or print. Since the computation happens immediately, you can use traditional debugging techniques to inspect variables during model training.\n",
        "7. Community and Adoption\n",
        "TensorFlow:\n",
        "\n",
        "TensorFlow has a larger corporate backing (Google) and is widely used in production environments, especially for large-scale applications.\n",
        "TensorFlow is often the framework of choice for researchers and practitioners working with distributed systems, production-ready models, and mobile/embedded systems.\n",
        "PyTorch:\n",
        "\n",
        "PyTorch has gained rapid adoption in academia and research because of its simplicity and flexibility, especially in the research community, where experimentation and model iteration are important.\n",
        "PyTorch is seen as the go-to framework for cutting-edge research in AI and deep learning.\n",
        "8. Model Training Speed and Flexibility\n",
        "TensorFlow:\n",
        "\n",
        "TensorFlow is known for its efficiency and optimization for training large models, especially with hardware accelerators like GPUs and TPUs.\n",
        "It provides TensorFlow Keras as a high-level API to train models easily.\n",
        "PyTorch:\n",
        "\n",
        "PyTorch provides flexibility in terms of model design and training, but may not always match TensorFlow in terms of out-of-the-box training speed for large models or distributed environments.\n"
      ],
      "metadata": {
        "id": "DwudEaZApmw6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que.11) How do you install PyTorch2"
      ],
      "metadata": {
        "id": "RlfFTxBrp2bz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solution - To install PyTorch, follow these steps depending on your system and preferred configuration:\n",
        "\n",
        "1. Install Using Pip\n",
        "The easiest way to install PyTorch is via pip, the Python package manager. You can install it directly from PyPI (Python Package Index) by following these steps:\n",
        "\n",
        "For CPU-Only Version (No CUDA Support)\n",
        "This is suitable if you don’t need GPU acceleration and want to run PyTorch on your CPU."
      ],
      "metadata": {
        "id": "geDiELvFp9x_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch torchvision torchaudio\n"
      ],
      "metadata": {
        "id": "p9DtgEspp_vz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solution"
      ],
      "metadata": {
        "id": "v5i7V3JZsof4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For GPU Version with CUDA Support\n",
        "If you have an NVIDIA GPU and want to utilize GPU acceleration, install the version with CUDA support. You’ll need to match the CUDA version supported by your system. PyTorch supports CUDA 11.7, 11.6, and other versions depending on your system.\n",
        "\n",
        "To install PyTorch with CUDA 11.7 (for example):"
      ],
      "metadata": {
        "id": "geliAz7qqCP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch torchvision torchaudio cudatoolkit=11.7\n"
      ],
      "metadata": {
        "id": "RQVvteSlqDab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Install Using Conda\n",
        "If you’re using Anaconda, installing PyTorch via conda is another easy way to ensure that the right dependencies, including CUDA, are installed.\n",
        "\n",
        "For CPU-Only Version"
      ],
      "metadata": {
        "id": "sx9uPHlaqF0l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conda install pytorch torchvision torchaudio cpuonly -c pytorch\n"
      ],
      "metadata": {
        "id": "67km-iFiqGqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "3. Verify Installation\n",
        "After installation, you can verify PyTorch is installed correctly by running the following Python code:\n"
      ],
      "metadata": {
        "id": "WbAb7R4-qWBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)  # Print PyTorch version\n",
        "print(torch.cuda.is_available())  # Check if CUDA is available\n"
      ],
      "metadata": {
        "id": "89FxwPIMqZIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Optional: Installing from Source\n",
        "If you want to install the latest nightly version or need to build PyTorch from source, you can follow the official installation guide, which provides the necessary commands based on your specific setup."
      ],
      "metadata": {
        "id": "P3zRZ9UiqbE2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "QUe.12)What is the basic structure of a PyTorch neural network2"
      ],
      "metadata": {
        "id": "m6Q6ne-dqg8O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solution -The basic structure of a PyTorch neural network involves defining a class that inherits from torch.nn.Module, where you define the layers of the network and how data flows through these layers. Below is a step-by-step guide to creating a simple neural network in PyTorch.\n",
        "\n",
        "Basic Components of a PyTorch Neural Network\n",
        "torch.nn.Module:\n",
        "\n",
        "Every model in PyTorch is derived from the nn.Module class, which provides methods like .forward() to define the forward pass of the network.\n",
        "Layers:\n",
        "\n",
        "In the __init__() method, you define the layers (like Linear, Conv2d, ReLU, etc.) as class attributes. These layers are then used in the forward() method to define how the input passes through the network.\n",
        "Forward Pass:\n",
        "\n",
        "The forward() method defines how the input data flows through the layers of the network, including any activation functions, reshaping, etc.\n",
        "Loss Function and Optimizer:\n",
        "\n",
        "After defining the network, you need to select a loss function (e.g., CrossEntropyLoss for classification) and an optimizer (e.g., Adam, SGD) for training.\n",
        "Basic Structure of a Simple Neural Network in PyTorch\n",
        "Here’s an example of how to define a simple feedforward neural network:"
      ],
      "metadata": {
        "id": "yB9vL8dwqmBs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define the neural network class\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "\n",
        "        # Define the layers\n",
        "        self.fc1 = nn.Linear(in_features=784, out_features=128)  # First fully connected layer\n",
        "        self.fc2 = nn.Linear(in_features=128, out_features=64)   # Second fully connected layer\n",
        "        self.fc3 = nn.Linear(in_features=64, out_features=10)    # Output layer (10 classes)\n",
        "        self.relu = nn.ReLU()  # ReLU activation function\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Define the forward pass\n",
        "        x = self.fc1(x)  # Pass through first layer\n",
        "        x = self.relu(x)  # Apply ReLU activation\n",
        "        x = self.fc2(x)  # Pass through second layer\n",
        "        x = self.relu(x)  # Apply ReLU activation again\n",
        "        x = self.fc3(x)  # Pass through output layer\n",
        "        return x  # Return the output\n",
        "\n",
        "# Instantiate the model\n",
        "model = SimpleNN()\n",
        "\n",
        "# Print model summary\n",
        "print(model)\n"
      ],
      "metadata": {
        "id": "eoJbGriHqtu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example for Training the Model:"
      ],
      "metadata": {
        "id": "0eqKBiUyq0LX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example training loop\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    for data, target in train_loader:  # Assuming train_loader is a DataLoader object\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(data)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = loss_fn(output, target)\n",
        "\n",
        "        # Backward pass (compute gradients)\n",
        "        loss.backward()\n",
        "\n",
        "        # Update the model weights\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n"
      ],
      "metadata": {
        "id": "bbwOrSF6q43S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que.13)What is the significance of tensors in PyTorch2"
      ],
      "metadata": {
        "id": "Ohcjkw-_rVKs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solution - In PyTorch, tensors are the fundamental building blocks for representing and manipulating data. A tensor is a multi-dimensional array (similar to NumPy arrays) that can hold data of various types, such as integers, floats, or even more complex structures. Tensors are designed to work efficiently with both CPUs and GPUs, and they are the primary data structure used for computations in PyTorch.\n",
        "\n",
        "Significance of Tensors in PyTorch\n",
        "Data Representation:\n",
        "\n",
        "Tensors serve as the basic unit for representing data in PyTorch. Whether you're working with input data, weights, or outputs in a neural network, they are all stored as tensors.\n",
        "Tensors can represent scalars (0-dimensional), vectors (1-dimensional), matrices (2-dimensional), or higher-dimensional data (n-dimensional). For example:\n",
        "Scalar: x = torch.tensor(5) (0D)\n",
        "Vector: x = torch.tensor([1, 2, 3]) (1D)\n",
        "Matrix: x = torch.tensor([[1, 2], [3, 4]]) (2D)\n",
        "Higher Dimensional Tensor: x = torch.randn(2, 3, 4) (3D)\n",
        "Efficient Computations on GPUs:\n",
        "\n",
        "One of the key features of PyTorch is its ability to efficiently perform computations on both the CPU and GPU.\n",
        "Tensors can be moved between devices (CPU and GPU) with simple commands, which accelerates mathematical operations on large datasets or deep learning models. For example:\n",
        "python\n",
        "Copy code\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "tensor = tensor.to(device='cuda')  # Move tensor to GPU\n",
        "Automatic Differentiation:\n",
        "\n",
        "Tensors in PyTorch are integrated with the autograd system, which automatically computes gradients for tensors during backpropagation in neural networks. This is essential for training deep learning models using optimization algorithms like gradient descent.\n",
        "To enable this feature, you create a tensor with the requires_grad attribute set to True:\n",
        "python\n",
        "Copy code\n",
        "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
        "This tensor will keep track of operations on it and can be used to compute gradients automatically via .backward().\n",
        "Matrix Operations and Linear Algebra:\n",
        "\n",
        "Tensors in PyTorch support a variety of mathematical operations, including matrix multiplication, element-wise operations, reshaping, and more.\n",
        "PyTorch provides efficient implementations of common linear algebra operations, making it a powerful tool for machine learning and deep learning. For example:\n",
        "python\n",
        "Copy code\n",
        "A = torch.tensor([[1, 2], [3, 4]])\n",
        "B = torch.tensor([[5, 6], [7, 8]])\n",
        "C = torch.matmul(A, B)  # Matrix multiplication\n",
        "Interoperability with NumPy:\n",
        "\n",
        "PyTorch tensors can easily interact with NumPy arrays. You can convert a PyTorch tensor to a NumPy array and vice versa:\n",
        "python\n",
        "Copy code\n",
        "np_array = tensor.numpy()  # Convert tensor to NumPy array\n",
        "tensor_from_np = torch.from_numpy(np_array)  # Convert NumPy array to tensor\n",
        "Creating Tensors:\n",
        "\n",
        "PyTorch provides various functions to create tensors in different ways:\n",
        "Random tensors: torch.randn(), torch.rand()\n",
        "Zeros and ones: torch.zeros(), torch.ones()\n",
        "Tensor from data: torch.tensor(data)\n",
        "Tensor with specified shape: torch.empty(), torch.zeros_like()\n",
        "Tensor Operations and Features\n",
        "Element-wise operations: Tensors support element-wise mathematical operations like addition, subtraction, multiplication, etc. These operations are performed efficiently and can be done on tensors of the same shape or broadcasted for different shapes.\n",
        "\n",
        "Example:\n",
        "\n",
        "python\n",
        "Copy code\n",
        "A = torch.tensor([1, 2, 3])\n",
        "B = torch.tensor([4, 5, 6])\n",
        "C = A + B  # Element-wise addition\n",
        "Reshaping: Tensors can be reshaped using operations like .view(), .reshape(), or .squeeze(). This is useful when you need to adjust the shape of tensors to match the requirements of a neural network layer or other operations.\n",
        "\n",
        "Example:\n",
        "\n",
        "python\n",
        "Copy code\n",
        "x = torch.randn(2, 3)\n",
        "y = x.view(3, 2)  # Reshape tensor to 3x2\n",
        "Broadcasting: Tensors of different shapes can be used in operations if their shapes are compatible for broadcasting. Broadcasting automatically expands smaller tensors to match the shape of the larger one, enabling element-wise operations between tensors of different sizes.\n",
        "\n",
        "Example:\n",
        "\n",
        "python\n",
        "Copy code\n",
        "x = torch.tensor([1, 2, 3])  # Shape: (3,)\n",
        "y = torch.tensor([[1], [2], [3]])  # Shape: (3, 1)\n",
        "z = x + y  # Broadcasting happens here\n",
        "Common Tensor Operations\n",
        "Here are some common tensor operations in PyTorch:\n",
        "\n",
        "Mathematical Operations:\n",
        "\n",
        "python\n",
        "Copy code\n",
        "A = torch.tensor([1, 2, 3])\n",
        "B = torch.tensor([4, 5, 6])\n",
        "print(A + B)  # Element-wise addition\n",
        "print(A * B)  # Element-wise multiplication\n",
        "Matrix Multiplication:\n",
        "\n",
        "python\n",
        "Copy code\n",
        "A = torch.tensor([[1, 2], [3, 4]])\n",
        "B = torch.tensor([[5, 6], [7, 8]])\n",
        "C = torch.matmul(A, B)  # Matrix multiplication\n",
        "Reshaping and Squeezing:\n",
        "\n",
        "python\n",
        "Copy code\n",
        "x = torch.randn(2, 3)\n",
        "x_reshaped = x.view(3, 2)\n",
        "Finding the Maximum:\n",
        "\n",
        "python\n",
        "Copy code\n",
        "x = torch.tensor([1, 2, 3, 4])\n",
        "print(torch.max(x))  # Returns the maximum element\n",
        "Importance of Tensors in Deep Learning\n",
        "Efficient Computation:\n",
        "\n",
        "Tensors allow efficient computation on both CPU and GPU, which is crucial for training deep learning models that involve large datasets and numerous parameters.\n",
        "Data Handling:\n",
        "\n",
        "Tensors are versatile for representing input data, model parameters (weights), intermediate activations, and outputs in neural networks.\n",
        "Automatic Gradient Computation:\n",
        "\n",
        "PyTorch's integration with the autograd module allows tensors to track operations for backpropagation. This is critical for updating model parameters during training.\n",
        "Optimization:\n",
        "\n",
        "Operations on tensors are highly optimized, making them suitable for large-scale training and deep learning workflows.\n"
      ],
      "metadata": {
        "id": "fG4mWgKarWNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Create a tensor\n",
        "x = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
        "\n",
        "# Perform an operation (e.g., scaling by 2)\n",
        "y = x * 2\n",
        "\n",
        "# Print the result\n",
        "print(y)\n"
      ],
      "metadata": {
        "id": "sfXLQgKgruE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que.14) What is the difference between torch.Tensor and torch.cuda.Tensor in PyTorch2\n"
      ],
      "metadata": {
        "id": "nSxKrW0Hr6hH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solution - In PyTorch, torch.Tensor and torch.cuda.Tensor are both used to represent multi-dimensional arrays, but they differ in where the data is stored and processed. Here's a detailed breakdown of the differences:\n",
        "\n",
        "1. torch.Tensor:\n",
        "A torch.Tensor is the standard tensor object in PyTorch, and it is stored in the CPU memory by default.\n",
        "When you create a tensor using torch.Tensor or torch.tensor(), it will be placed on the CPU unless specified otherwise."
      ],
      "metadata": {
        "id": "EHMJL-pdsC3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1.0, 2.0, 3.0])  # This tensor is on the CPU by default\n",
        "print(x.device)  # Should print \"cpu\"\n"
      ],
      "metadata": {
        "id": "ggSvi4stsG3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. torch.cuda.Tensor:\n",
        " A torch.cuda.Tensor is essentially a tensor that is moved to the GPU (specifically the CUDA-capable GPU) for accelerated computations.\n",
        "The torch.cuda module provides functions for allocating tensors on the GPU. Any tensor that resides on the GPU is a torch.cuda.Tensor.\n"
      ],
      "metadata": {
        "id": "xNIaCUOasJTO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1.0, 2.0, 3.0]).to('cuda')  # Move tensor to the GPU\n",
        "print(x.device)  # Should print something like \"cuda:0\" (first GPU)\n"
      ],
      "metadata": {
        "id": "uRnSzHz-sNUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que.15)What is the purpose of the torch.optim module in PyTorch2"
      ],
      "metadata": {
        "id": "qMpn_LTVs7Nx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solution - The torch.optim module in PyTorch provides a suite of optimization algorithms that are used to adjust the parameters (weights) of a neural network during training to minimize the loss function. These optimization algorithms are crucial in the process of training deep learning models because they guide the weights of the network toward values that lead to better predictions, reducing the error or loss.\n",
        "\n",
        "Purpose of the torch.optim Module:\n",
        "The primary purpose of the torch.optim module is to facilitate the optimization process during the training of neural networks. It provides different optimizers that perform various types of gradient-based optimization. These optimizers update the model's parameters based on the gradients calculated during backpropagation, which reflect how much the parameters need to be adjusted to reduce the loss.\n",
        "\n",
        "Key Concepts in Optimization:\n",
        "Gradient Descent: This is the core principle of most optimization algorithms. It involves adjusting the weights of the model in the direction that reduces the loss. The gradients (calculated during backpropagation) indicate the direction and magnitude of the adjustment.\n",
        "\n",
        "Learning Rate: The learning rate is a hyperparameter that controls the size of the updates to the model’s parameters. A larger learning rate might cause overshooting, while a smaller one might lead to slow convergence.\n",
        "\n",
        "Momentum, Adaptive Learning Rates, and Other Techniques: More advanced optimizers use techniques such as momentum, adaptive learning rates, or weight decay (L2 regularization) to improve the convergence of the model and avoid local minima or saddle points.\n",
        "\n",
        "Key Features of torch.optim:\n",
        "Provides a variety of optimization algorithms:\n",
        "\n",
        "SGD (Stochastic Gradient Descent)\n",
        "Adam\n",
        "RMSprop\n",
        "Adagrad\n",
        "Adadelta\n",
        "And others (such as LBFGS, ASGD, etc.)\n",
        "Handles parameter updates: Optimizers in torch.optim handle updating the parameters of the model, using gradients calculated during the backward pass (.backward() method).\n",
        "\n",
        "Supports various advanced techniques:\n",
        "\n",
        "Momentum: Helps accelerate the optimizer in the relevant direction and dampens oscillations.\n",
        "Weight Decay (L2 Regularization): Helps prevent overfitting by adding a penalty term to the loss function.\n",
        "Learning Rate Scheduling: Allows adjusting the learning rate during training, which can help the model converge more effectively.\n",
        "Common Optimizers in torch.optim:\n",
        "Below are some of the most commonly used optimizers from the torch.optim module:\n",
        "\n",
        "SGD (Stochastic Gradient Descent):\n",
        "\n",
        "One of the simplest optimization algorithms, which updates the weights by taking small steps proportional to the negative of the gradient.\n",
        "Can be used with momentum to improve convergence.\n",
        "Example:\n",
        "python\n",
        "Copy code\n",
        "import torch.optim as optim\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "Adam (Adaptive Moment Estimation):\n",
        "\n",
        "Combines the advantages of two other extensions of SGD: AdaGrad and RMSprop.\n",
        "It computes adaptive learning rates for each parameter, making it particularly effective for sparse gradients and problems with noisy data.\n",
        "Example:\n",
        "python\n",
        "Copy code\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "RMSprop:\n",
        "\n",
        "An adaptive learning rate method that adjusts the learning rate for each parameter based on recent gradient magnitudes.\n",
        "Often used for training Recurrent Neural Networks (RNNs) and other types of networks that involve large gradients.\n",
        "Example:\n",
        "python\n",
        "Copy code\n",
        "optimizer = optim.RMSprop(model.parameters(), lr=0.01, alpha=0.99)\n",
        "Adagrad:\n",
        "\n",
        "An algorithm that adapts the learning rate to the parameters, performing larger updates for infrequent and smaller updates for frequent parameters.\n",
        "Example:\n",
        "python\n",
        "Copy code\n",
        "optimizer = optim.Adagrad(model.parameters(), lr=0.01)\n",
        "Adadelta:\n",
        "\n",
        "A variant of Adagrad that seeks to fix its aggressive, monotonically decreasing learning rate by restricting the window of accumulated past gradients to a fixed size.\n",
        "Example:\n",
        "python\n",
        "Copy code\n",
        "optimizer = optim.Adadelta(model.parameters(), lr=1.0)\n",
        "LBFGS (Limited-memory Broyden–Fletcher–Goldfarb–Shanno):\n",
        "\n",
        "A second-order optimization algorithm that uses the approximation of the Hessian matrix (second derivatives) to improve convergence.\n",
        "This optimizer is useful for small datasets or models with a small number of parameters.\n",
        "Example:\n",
        "python\n",
        "Copy code\n",
        "optimizer = optim.LBFGS(model.parameters(), lr=1.0)\n",
        "How to Use torch.optim:\n",
        "To use any optimizer from torch.optim, you follow these general steps:\n",
        "\n",
        "Define the model: Create the neural network model.\n",
        "Choose an optimizer: Select the optimizer and initialize it with model parameters.\n",
        "Set the learning rate and other hyperparameters.\n",
        "Run the training loop: For each batch of data, perform the forward pass, compute the loss, backpropagate to compute gradients, and then call optimizer.step() to update the model's parameters.\n"
      ],
      "metadata": {
        "id": "S0AqaVFlsthQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Example\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "# Simple model\n",
        "model = nn.Linear(10, 1)\n",
        "\n",
        "# Loss function\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Dummy data\n",
        "inputs = torch.randn(32, 10)  # 32 samples, each with 10 features\n",
        "targets = torch.randn(32, 1)  # 32 target values\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(100):\n",
        "    optimizer.zero_grad()  # Zero the gradients\n",
        "    outputs = model(inputs)  # Forward pass\n",
        "    loss = loss_fn(outputs, targets)  # Compute loss\n",
        "    loss.backward()  # Backpropagate to compute gradients\n",
        "    optimizer.step()  # Update model parameters\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/100], Loss: {loss.item():.4f}\")\n"
      ],
      "metadata": {
        "id": "Daq8Gzgisw0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que.16=\u001b\u001a What are some common activation functions used in neural networks\n",
        "\n",
        "Solution - Activation functions are a critical component in neural networks as they introduce non-linearity into the model, allowing it to learn complex patterns. Without activation functions, neural networks would essentially behave like linear models, regardless of how many layers they had. Here are some of the most common activation functions used in neural networks:\n",
        "\n",
        "### 1. **Sigmoid (Logistic) Activation Function**:\n",
        "   - **Formula**:\n",
        "     \\[\n",
        "     \\sigma(x) = \\frac{1}{1 + e^{-x}}\n",
        "     \\]\n",
        "   - **Range**: (0, 1)\n",
        "   - **Use Case**: Primarily used in binary classification problems or when a model needs to output a probability (e.g., the output of a binary classification layer).\n",
        "   - **Pros**:\n",
        "     - Outputs values between 0 and 1, making it interpretable as probabilities.\n",
        "   - **Cons**:\n",
        "     - **Vanishing Gradient Problem**: For very large or very small inputs, the gradients can become very small, leading to slow training or difficulty in updating weights.\n",
        "     - Not zero-centered, which can make optimization harder.\n",
        "\n",
        "   ```python\n",
        "   import torch\n",
        "   output = torch.sigmoid(input)  # Sigmoid activation in PyTorch\n",
        "   ```\n",
        "\n",
        "### 2. **Tanh (Hyperbolic Tangent) Activation Function**:\n",
        "   - **Formula**:\n",
        "     \\[\n",
        "     \\tanh(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}\n",
        "     \\]\n",
        "   - **Range**: (-1, 1)\n",
        "   - **Use Case**: Often used in hidden layers of neural networks, as it is zero-centered, which helps with optimization.\n",
        "   - **Pros**:\n",
        "     - Zero-centered, which means that the output values are spread more evenly around zero.\n",
        "     - Helps mitigate some issues of the sigmoid function.\n",
        "   - **Cons**:\n",
        "     - **Vanishing Gradient Problem**: Similar to the sigmoid function, the gradient becomes very small for large positive or negative inputs.\n",
        "\n",
        "   ```python\n",
        "   import torch\n",
        "   output = torch.tanh(input)  # Tanh activation in PyTorch\n",
        "   ```\n",
        "\n",
        "### 3. **ReLU (Rectified Linear Unit) Activation Function**:\n",
        "   - **Formula**:\n",
        "     \\[\n",
        "     \\text{ReLU}(x) = \\max(0, x)\n",
        "     \\]\n",
        "   - **Range**: [0, ∞)\n",
        "   - **Use Case**: Widely used in the hidden layers of neural networks, especially deep networks.\n",
        "   - **Pros**:\n",
        "     - **Simple and fast**: Computation is straightforward, and it is less computationally expensive compared to sigmoid and tanh.\n",
        "     - **Helps mitigate the vanishing gradient problem**: ReLU does not saturate for large positive inputs.\n",
        "   - **Cons**:\n",
        "     - **Dying ReLU Problem**: Neurons can \"die\" if they enter a region where the output is always zero (for negative inputs). This can prevent the network from learning in certain cases.\n",
        "\n",
        "   ```python\n",
        "   import torch\n",
        "   output = torch.relu(input)  # ReLU activation in PyTorch\n",
        "   ```\n",
        "\n",
        "### 4. **Leaky ReLU**:\n",
        "   - **Formula**:\n",
        "     \\[\n",
        "     \\text{Leaky ReLU}(x) = \\begin{cases}\n",
        "     x & \\text{if } x > 0 \\\\\n",
        "     \\alpha x & \\text{if } x \\leq 0\n",
        "     \\end{cases}\n",
        "     \\]\n",
        "     where \\( \\alpha \\) is a small constant (e.g., 0.01).\n",
        "   - **Range**: (-∞, ∞)\n",
        "   - **Use Case**: A variant of ReLU that allows a small slope when \\(x\\) is negative, addressing the \"dying ReLU\" problem.\n",
        "   - **Pros**:\n",
        "     - Allows a small gradient when the input is negative, which helps prevent the \"dying\" issue in ReLU.\n",
        "   - **Cons**:\n",
        "     - The choice of \\( \\alpha \\) can impact training; however, it is usually a small constant value like 0.01.\n",
        "\n",
        "   ```python\n",
        "   import torch\n",
        "   output = torch.nn.functional.leaky_relu(input, negative_slope=0.01)  # Leaky ReLU activation in PyTorch\n",
        "   ```\n",
        "\n",
        "### 5. **ELU (Exponential Linear Unit)**:\n",
        "   - **Formula**:\n",
        "     \\[\n",
        "     \\text{ELU}(x) = \\begin{cases}\n",
        "     x & \\text{if } x > 0 \\\\\n",
        "     \\alpha(e^x - 1) & \\text{if } x \\leq 0\n",
        "     \\end{cases}\n",
        "     \\]\n",
        "     where \\( \\alpha \\) is a constant (e.g., 1).\n",
        "   - **Range**: (-α, ∞)\n",
        "   - **Use Case**: Used to avoid the vanishing gradient problem while providing smoother negative values, helping the network to converge faster.\n",
        "   - **Pros**:\n",
        "     - Zero-centered, which can help with training efficiency.\n",
        "     - Smooths negative values.\n",
        "   - **Cons**:\n",
        "     - More computationally expensive than ReLU and Leaky ReLU.\n",
        "     - Requires the choice of \\( \\alpha \\), which might need tuning.\n",
        "\n",
        "   ```python\n",
        "   import torch\n",
        "   output = torch.nn.functional.elu(input, alpha=1.0)  # ELU activation in PyTorch\n",
        "   ```\n",
        "\n",
        "### 6. **Softmax**:\n",
        "   - **Formula**:\n",
        "     \\[\n",
        "     \\text{Softmax}(x_i) = \\frac{e^{x_i}}{\\sum_j e^{x_j}}\n",
        "     \\]\n",
        "     where \\( x_i \\) is the input vector and the sum is over all elements in the input vector.\n",
        "   - **Range**: (0, 1) for each element, and the sum of all outputs equals 1.\n",
        "   - **Use Case**: Typically used in the output layer for multi-class classification problems, where the network needs to output a probability distribution over multiple classes.\n",
        "   - **Pros**:\n",
        "     - Converts the outputs into a probability distribution, making it suitable for classification tasks.\n",
        "   - **Cons**:\n",
        "     - Softmax is sensitive to outliers in the data.\n",
        "\n",
        "   ```python\n",
        "   import torch\n",
        "   output = torch.nn.functional.softmax(input, dim=1)  # Softmax activation in PyTorch\n",
        "   ```\n",
        "\n",
        "### 7. **Swish**:\n",
        "   - **Formula**:\n",
        "     \\[\n",
        "     \\text{Swish}(x) = x \\cdot \\sigma(x)\n",
        "     \\]\n",
        "     where \\( \\sigma(x) \\) is the sigmoid function.\n",
        "   - **Range**: (-∞, ∞)\n",
        "   - **Use Case**: Introduced by Google as an alternative to ReLU, Swish has been shown to outperform ReLU in some deep learning tasks.\n",
        "   - **Pros**:\n",
        "     - Smooth and non-monotonic, which allows the network to learn more complex patterns.\n",
        "   - **Cons**:\n",
        "     - More computationally expensive compared to ReLU and Leaky ReLU.\n",
        "\n",
        "   ```python\n",
        "   import torch\n",
        "   output = torch.nn.functional.silu(input)  # Swish activation in PyTorch\n",
        "   ```\n",
        "\n",
        "### Summary of Activation Functions:\n",
        "\n",
        "| **Activation Function** | **Formula** | **Range** | **Use Case** | **Pros** | **Cons** |\n",
        "|-------------------------|-------------|-----------|--------------|----------|----------|\n",
        "| **Sigmoid**             | \\( \\frac{1}{1 + e^{-x}} \\) | (0, 1) | Binary classification | Outputs probabilities | Vanishing gradient |\n",
        "| **Tanh**                | \\( \\frac{e^x - e^{-x}}{e^x + e^{-x}} \\) | (-1, 1) | Hidden layers | Zero-centered | Vanishing gradient |\n",
        "| **ReLU**                | \\( \\max(0, x) \\) | [0, ∞) | Hidden layers | Simple and efficient | Dying ReLU problem |\n",
        "| **Leaky ReLU**          | \\( \\max(0, x) \\) with small slope for \\( x < 0 \\) | (-∞, ∞) | Hidden layers | Solves Dying ReLU | Choice of \\( \\alpha \\) |\n",
        "| **ELU**                 | \\( x \\) for \\( x > 0 \\), \\( \\alpha(e^x - 1) \\) for \\( x \\leq 0 \\) | (-α, ∞) | Hidden layers | Zero-centered | Computationally expensive |\n",
        "| **Softmax**             | \\( \\frac{e^{x_i}}{\\sum_j e^{x_j}} \\) | (0, 1) | Multi-class classification | Probability distribution | Sensitive to outliers |\n",
        "| **Swish**               | \\( x \\cdot \\sigma(x) \\) | (-∞, ∞) | Hidden layers | Smooth and non-monotonic | Computationally expensive |\n",
        "\n",
        "### Conclusion:\n",
        "Each activation function has its strengths and weaknesses, and the choice of activation function depends on the specific task and the problem at hand. ReLU and its variants (Leaky ReLU, ELU) are the most commonly used for hidden layers, while sigmoid and softmax are often used in output layers for binary and multi-class classification problems, respectively."
      ],
      "metadata": {
        "id": "54UP-oq-tCpJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que.17. What is the difference between torch.nn.Module and torch.nn.Sequential in PyTorch2\n",
        "Solution - In PyTorch, both torch.nn.Module and torch.nn.Sequential are used for defining neural network models, but they serve slightly different purposes and offer different levels of flexibility.\n",
        "\n",
        "torch.nn.Module:\n",
        "Definition: The torch.nn.Module is the base class for all neural network modules in PyTorch. Any neural network model should subclass torch.nn.Module and implement the __init__ and forward methods.\n",
        "\n",
        "Flexibility: torch.nn.Module provides the most flexibility for building complex neural network architectures, especially when you need custom behavior in the forward pass or need to define your own layers, operations, or architectures.\n",
        "\n",
        "Components:\n",
        "\n",
        "__init__ Method: This method is used to define all the layers (as torch.nn modules) and other operations you want to use in the model.\n",
        "forward Method: This method defines the actual forward pass computation, where you specify how the input data flows through the layers.\n",
        "Custom Layers: You can define custom layers, activation functions, and other complex behaviors within the forward method."
      ],
      "metadata": {
        "id": "LK0Tv1Cttmsj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class CustomModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomModel, self).__init__()\n",
        "        # Define layers\n",
        "        self.fc1 = nn.Linear(10, 5)\n",
        "        self.fc2 = nn.Linear(5, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass using the defined layers\n",
        "        x = torch.relu(self.fc1(x))  # Apply activation after first layer\n",
        "        x = self.fc2(x)  # Second layer\n",
        "        return x\n",
        "\n",
        "model = CustomModel()\n"
      ],
      "metadata": {
        "id": "XLXUAkDmt-DM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.nn.Sequential:\n",
        "Definition: The torch.nn.Sequential class is a simpler way to define models that consist of a linear stack of layers, where the output of one layer is passed as the input to the next layer, in the specified order.\n",
        "\n",
        "Simplicity: torch.nn.Sequential is useful for straightforward models where the layers are applied sequentially with no branching or complex operations. It reduces the need to manually define a forward method.\n",
        "\n",
        "Components:\n",
        "\n",
        "You add layers (like nn.Linear, nn.Conv2d, etc.) directly to a Sequential container.\n",
        "The layers are applied in the order in which they are defined, with each layer automatically receiving the output of the previous layer."
      ],
      "metadata": {
        "id": "XsFd1PJPuBeb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(10, 5),   # First layer (input size = 10, output size = 5)\n",
        "    nn.ReLU(),          # Activation function\n",
        "    nn.Linear(5, 1)     # Second layer (input size = 5, output size = 1)\n",
        ")\n"
      ],
      "metadata": {
        "id": "b0Bp-rXKuCqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que.18. How can you monitor training progress in TensorFlow 2.02"
      ],
      "metadata": {
        "id": "93dM9-WvuGbZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SOlution - In TensorFlow 2.0, there are several ways to monitor the training progress of your model. Below are the key methods and tools you can use:\n",
        "\n",
        "1. Using TensorBoard:\n",
        "TensorBoard is one of the most popular and powerful tools for visualizing training metrics in TensorFlow. It provides insights into the model’s performance by displaying various statistics such as loss, accuracy, and even the model architecture during training.\n",
        "\n",
        "Steps to integrate TensorBoard:\n",
        "\n",
        "Create a TensorBoard callback: TensorFlow provides the TensorBoard callback that logs metrics during training, which you can later visualize.\n",
        "\n",
        "Specify a log directory: You'll need to specify a directory where TensorFlow can save the logs. These logs will be visualized in TensorBoard.\n",
        "\n",
        "Use the fit() method with the callback: Pass the TensorBoard callback to the fit() method of your model to log the metrics.\n",
        "\n"
      ],
      "metadata": {
        "id": "Y-nzjJ8Aus8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#example\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import os\n",
        "\n",
        "# Create a directory for saving logs\n",
        "log_dir = os.path.join(\"logs\", \"fit\")\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "# Model definition\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', input_shape=(32,)),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the model and use TensorBoard callback\n",
        "model.fit(x_train, y_train, epochs=10, callbacks=[tensorboard_callback])\n",
        "\n",
        "# After training, you can visualize the training progress in TensorBoard\n",
        "# Launch TensorBoard from the terminal (in the log directory)\n",
        "# tensorboard --logdir=logs/fit\n"
      ],
      "metadata": {
        "id": "SPp_hVvkuyCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualization\n",
        "tensorboard --logdir=logs/fit\n"
      ],
      "metadata": {
        "id": "WzvvAzlgu3UT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Progress Bar with tqdm:\n",
        "You can also integrate a progress bar to monitor training by using the tqdm library. This can be useful for monitoring training progress directly in the terminal.\n",
        "\n"
      ],
      "metadata": {
        "id": "ocwugcoKu7t1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Example\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "\n",
        "# Example model and data\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', input_shape=(32,)),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Use tqdm to wrap the training data\n",
        "for epoch in range(10):\n",
        "    # Wrap the training loop with tqdm\n",
        "    with tqdm(total=len(x_train), desc=f\"Epoch {epoch+1}\") as pbar:\n",
        "        for x_batch, y_batch in train_dataset:  # Assume train_dataset is a tf.data.Dataset object\n",
        "            loss = model.train_on_batch(x_batch, y_batch)\n",
        "            pbar.set_postfix(loss=loss)\n",
        "            pbar.update(len(x_batch))  # Update the progress bar\n"
      ],
      "metadata": {
        "id": "t9wZ-fGyu-Hc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Using Model.fit Verbose Option:\n",
        "When using model.fit(), you can set the verbose argument to control the amount of logging during training. The verbose can be set to:\n",
        "\n",
        "verbose=0: No output (silent mode).\n",
        "\n",
        "verbose=1: Progress bar (shows one line per epoch).\n",
        "\n",
        "verbose=2: One line per epoch, including the metrics at the end of each epoch"
      ],
      "metadata": {
        "id": "AmyOYwPPvCF5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, epochs=10, verbose=1)\n"
      ],
      "metadata": {
        "id": "YHdxxZVRvE5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Custom Callbacks:\n",
        "You can create custom callbacks to monitor specific aspects of the training, such as custom metrics, early stopping, or learning rate adjustme"
      ],
      "metadata": {
        "id": "FKM4Ab0rvI5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Exapple\n",
        "class CustomCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Print loss and accuracy after every epoch\n",
        "        print(f\"Epoch {epoch}: Loss = {logs['loss']}, Accuracy = {logs['accuracy']}\")\n",
        "\n",
        "# Use the custom callback during training\n",
        "model.fit(x_train, y_train, epochs=10, callbacks=[CustomCallback()])\n"
      ],
      "metadata": {
        "id": "ONILOPeqvKRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Monitoring Training with Keras Callbacks:\n"
      ],
      "metadata": {
        "id": "Z8-8C9MvvOyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "model.fit(x_train, y_train, epochs=100, validation_data=(x_val, y_val), callbacks=[early_stopping])\n",
        "\n"
      ],
      "metadata": {
        "id": "IwFa4eE-vPz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Training Metrics Visualization:\n"
      ],
      "metadata": {
        "id": "gNuyGWPxvSEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Example\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Train the model and store history\n",
        "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_val, y_val))\n",
        "\n",
        "# Plot loss and accuracy\n",
        "plt.plot(history.history['loss'], label='train_loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "usiwbe_nvSsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Using history Object:\n"
      ],
      "metadata": {
        "id": "WBmjpKTSvZ-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Exaple\n"
      ],
      "metadata": {
        "id": "yFiFWAn1vacZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_val, y_val))\n",
        "print(\"Training Loss: \", history.history['loss'])\n",
        "print(\"Validation Loss: \", history.history['val_loss'])\n"
      ],
      "metadata": {
        "id": "L1xII_BYvc3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que.19.How does the Keras API fit into TensorFlow 2.02"
      ],
      "metadata": {
        "id": "wHb0NRwsvkJy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solution - In TensorFlow 2.0, the Keras API has become the default high-level API for building and training deep learning models. Keras provides a user-friendly, Pythonic interface for defining, training, and evaluating neural networks, making it accessible to both beginners and experts in deep learning.\n",
        "\n",
        "1. Keras as the High-Level API in TensorFlow 2.0\n",
        "In TensorFlow 2.0, Keras is tightly integrated into TensorFlow. TensorFlow's core functionality is now extended through Keras, which provides high-level abstractions for building and training neural networks.\n",
        "The tf.keras module contains Keras functionalities within TensorFlow, allowing users to easily build complex deep learning models without needing to write low-level code.\n",
        "2. Key Features of Keras in TensorFlow 2.0\n",
        "a. Simple and Consistent API:\n",
        "Keras offers an intuitive, high-level API that is designed to be easy to use. It simplifies model creation, training, and evaluation processes. The Keras API is consistent and easy to learn, which reduces the complexity of building deep learning models.\n",
        "\n",
        "b. Model Building in Keras:\n",
        "Keras provides two primary ways to define models:\n",
        "\n",
        "Sequential API: For models where layers are stacked sequentially.\n",
        "Functional API: For more complex models (e.g., models with multiple inputs, outputs, or shared layers)."
      ],
      "metadata": {
        "id": "-DNkI-k3v7_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Sequential API Example:\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', input_shape=(32,)),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.fit(x_train, y_train, epochs=10)\n"
      ],
      "metadata": {
        "id": "NZpkZPUnv-M_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Functional API Example (for complex models):\n",
        "inputs = tf.keras.Input(shape=(32,))\n",
        "x = tf.keras.layers.Dense(64, activation='relu')(inputs)\n",
        "x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
        "outputs = tf.keras.layers.Dense(1)(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.fit(x_train, y_train, epochs=10)\n"
      ],
      "metadata": {
        "id": "aDWOc7ukwFQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "c. Pre-trained Models:\n",
        "Keras includes several pre-trained models that can be used for transfer learning. These models can be loaded from tf.keras.applications and include popular architectures like VGG16, ResNet, and Inception, which can be fine-tuned for specific tasks.\n",
        "\n",
        "d. Callbacks:\n",
        "Keras offers built-in callbacks like TensorBoard, EarlyStopping, and ModelCheckpoint that allow for better monitoring and control during training"
      ],
      "metadata": {
        "id": "rKFcwGtIwJmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Example: Using TensorBoard callback for logging:\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "tensorboard_callback = TensorBoard(log_dir='./logs')\n",
        "\n",
        "model.fit(x_train, y_train, epochs=10, callbacks=[tensorboard_callback])\n"
      ],
      "metadata": {
        "id": "Vn3_VrrLwL8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "d. Callbacks:\n",
        "Keras offers built-in callbacks like TensorBoard, EarlyStopping, and ModelCheckpoint that allow for better monitoring and control during training.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZQ6r9XxJwTVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Example: Using TensorBoard callback for\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "tensorboard_callback = TensorBoard(log_dir='./logs')\n",
        "\n",
        "model.fit(x_train, y_train, epochs=10, callbacks=[tensorboard_callback])\n"
      ],
      "metadata": {
        "id": "wNtQCtzXwW44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "e. Custom Layers, Models, and Callbacks:\n"
      ],
      "metadata": {
        "id": "BCXaigOawfb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Example of custom layer:\n",
        "class MyLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, units=32):\n",
        "        super(MyLayer, self).__init__()\n",
        "        self.units = units\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.kernel = self.add_weight('kernel', shape=(input_shape[1], self.units))\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.matmul(inputs, self.kernel)\n"
      ],
      "metadata": {
        "id": "gJY_pabSwjPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. How Keras is Integrated into TensorFlow 2.0:\n",
        "In TensorFlow 2.0, Keras is part of the tf.keras submodule, which means you can use all TensorFlow functionalities (such as tf.data, tf.function, etc.) in conjunction with Keras for building and training deep learning models. This deep integration provides the following advantages:\n",
        "\n",
        "Eager Execution: TensorFlow 2.0 has eager execution enabled by default, which allows Keras models to be more dynamic and intuitive to debug and experiment with.\n",
        "\n",
        "Distributed Training: Keras supports distributed training with tf.distribute.Strategy, which is useful for training large models on multiple devices (e.g., GPUs, TPUs).\n",
        "\n",
        "TensorFlow Hub Integration: Keras seamlessly integrates with TensorFlow Hub, which provides a collection of reusable machine learning models. These can be used for transfer learning tasks.\n",
        "\n",
        "Automatic Differentiation: Keras models in TensorFlow 2.0 can take full advantage of TensorFlow’s automatic differentiation, which computes gradients for optimization during training.\n",
        "\n",
        "Optimizers and Loss Functions: TensorFlow offers a wide range of optimizers and loss functions that can be used directly within Keras.\n",
        "\n",
        "4. Training and Evaluation in Keras:\n",
        "Keras makes it easy to train, evaluate, and predict with models using simple commands such as fit(), evaluate(), and predict()."
      ],
      "metadata": {
        "id": "WDeZ6x-Ews8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Training:\n",
        "model.fit(x_train, y_train, epochs=10)\n",
        "#Evaluation:\n",
        "\n",
        "loss = model.evaluate(x_test, y_test)\n",
        "\n",
        "#Predection\n",
        "predictions = model.predict(x_input)\n"
      ],
      "metadata": {
        "id": "nlbJm56Awt9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Why Use Keras with TensorFlow 2.0?\n",
        "Simplicity: Keras abstracts away much of the complexity of building deep learning models, allowing you to focus on defining and improving your architecture.\n",
        "Flexibility: Keras provides both the simple Sequential API for basic models and the powerful Functional API for more advanced architectures.\n",
        "Integration with TensorFlow: Keras benefits from TensorFlow’s optimized backend, which includes performance enhancements, distribution strategies, and access to advanced machine learning tools.\n",
        "Extensibility: TensorFlow 2.0 allows you to extend Keras with custom layers, loss functions, and optimizers, making it suitable for research and production.\n"
      ],
      "metadata": {
        "id": "ieG6lqTHxBsS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que.20. What is an example of a deep learning project that can be implemented using TensorFlow 2.02\n"
      ],
      "metadata": {
        "id": "kodPCei9xJDz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solution - One example of a deep learning project that can be implemented using TensorFlow 2.0 is an Image Classification project, such as classifying images of cats and dogs using a Convolutional Neural Network (CNN).\n",
        "\n",
        "Project: Image Classification (Cats vs. Dogs)\n",
        "In this project, you will train a model to classify images into two categories: cats and dogs. This project uses a dataset containing labeled images of cats and dogs (e.g., the Kaggle \"Dogs vs. Cats\" dataset).\n",
        "\n",
        "Steps to Implement the Project:\n",
        "1. Setup and Import Required Libraries:"
      ],
      "metadata": {
        "id": "uojMqJGKxYKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "metadata": {
        "id": "NHWJLlmrxZ37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Load and Preprocess Data:\n",
        "You'll need to prepare the dataset by loading the images, resizing them, and scaling pixel values. TensorFlow's ImageDataGenerator can be used to augment the dataset for better model generalization.\n",
        "\n",
        "python\n",
        "Copy code\n"
      ],
      "metadata": {
        "id": "TeH84iMixddi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the directories (replace with your dataset paths)\n",
        "train_dir = '/path/to/train'\n",
        "validation_dir = '/path/to/validation'\n",
        "\n",
        "# Define image preprocessing and augmentation\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load and iterate the data from directories\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n"
      ],
      "metadata": {
        "id": "QeaPiljpxfdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Build the Model:\n",
        "Create a Convolutional Neural Network (CNN) for image classification. CNNs are particularly well-suited for tasks like image classification due to their ability to extract spatial features from images."
      ],
      "metadata": {
        "id": "r3Zqu-23xhdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "AU3Hx6xixiYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Train the Model:\n",
        "Once the model is defined, use the fit method to train it. You can specify the number of epochs, batch size, and validation data."
      ],
      "metadata": {
        "id": "w-_g5RrAxkE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=100,  # Number of batches per epoch\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=50  # Number of validation batches\n",
        ")\n"
      ],
      "metadata": {
        "id": "FCksOUS9xlLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Evaluate the Model:\n",
        "After training, evaluate the model using the validation set to see how well it generalizes to new data."
      ],
      "metadata": {
        "id": "-yLIi1ePxm6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model's performance\n",
        "test_loss, test_acc = model.evaluate(validation_generator)\n",
        "print(f\"Test Accuracy: {test_acc*100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "rVNYPWsUxq3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Visualize Training Progress:\n",
        "To monitor the training process, plot graphs of the training and validation accuracy and loss."
      ],
      "metadata": {
        "id": "nhVo6VlKxtfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot accuracy and loss\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Accuracy plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Accuracy Over Epochs')\n",
        "\n",
        "# Loss plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Loss Over Epochs')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bjDe0xhbxu73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Make Predictions:\n",
        "After training, you can use the model to make predictions on new, unseen images.\n"
      ],
      "metadata": {
        "id": "IvyuCCYsxyKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example prediction on a new image\n",
        "img = tf.keras.preprocessing.image.load_img('path_to_image.jpg', target_size=(150, 150))\n",
        "img_array = tf.keras.preprocessing.image.img_to_array(img) / 255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "prediction = model.predict(img_array)\n",
        "if prediction[0] > 0.5:\n",
        "    print(\"Prediction: Dog\")\n",
        "else:\n",
        "    print(\"Prediction: Cat\")\n"
      ],
      "metadata": {
        "id": "wLZAN2YUx03g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que.21 What is the main advantage of using pre-trained models in TensorFlow and PyTorch?\n",
        "\n",
        "\n",
        "Solution - The main advantage of using **pre-trained models** in **TensorFlow** and **PyTorch** is **transfer learning**, which allows you to leverage knowledge gained from a model trained on a large, general-purpose dataset (such as ImageNet) to solve a new, often smaller, and more specific task with minimal effort and resources. Here are the key benefits:\n",
        "\n",
        "### 1. **Reduced Training Time**\n",
        "- **Pre-trained models** save a significant amount of training time because the model has already learned useful features from a large dataset.\n",
        "- You don’t need to train the model from scratch. Instead, you can fine-tune it on your specific dataset, which requires much less data and fewer epochs.\n",
        "\n",
        "### 2. **Improved Performance**\n",
        "- Pre-trained models are typically trained on large, diverse datasets (like ImageNet, COCO, or similar). They have learned complex patterns and features, which can significantly boost the performance of your model, even on smaller datasets.\n",
        "- The model has already learned fundamental features such as edges, textures, shapes, and even higher-level features, which are transferable to many tasks like classification, object detection, and segmentation.\n",
        "\n",
        "### 3. **Efficient Use of Resources**\n",
        "- Training deep learning models from scratch, especially on large datasets, is computationally expensive and requires significant resources (like GPUs or TPUs). Pre-trained models save you from these high computational costs by reducing the amount of training needed.\n",
        "- They allow you to focus your computational resources on fine-tuning or adjusting the model to your specific problem rather than starting from scratch.\n",
        "\n",
        "### 4. **Smaller Datasets for Fine-Tuning**\n",
        "- Pre-trained models are particularly useful when you don’t have a large labeled dataset for your task. Fine-tuning a pre-trained model typically requires fewer data points compared to training a model from scratch.\n",
        "- For example, fine-tuning a model trained on ImageNet for a specific task (like classifying medical images or recognizing certain objects) can achieve good performance even with relatively small datasets.\n",
        "\n",
        "### 5. **Better Generalization**\n",
        "- Pre-trained models, having been exposed to diverse data during their initial training, often generalize better than models trained from scratch on a single, smaller dataset.\n",
        "- They have already learned to capture various kinds of patterns and features that can be useful across different domains and tasks.\n",
        "\n",
        "### 6. **Flexibility in Application**\n",
        "- **TensorFlow** and **PyTorch** both offer a wide variety of pre-trained models (like **ResNet**, **VGG**, **Inception**, **BERT**, etc.), which can be used for multiple tasks such as:\n",
        "  - **Image Classification**: ResNet, VGG, Inception\n",
        "  - **Object Detection**: Faster R-CNN, YOLO\n",
        "  - **Natural Language Processing**: BERT, GPT, Transformer-based models\n",
        "  - **Speech Recognition**: DeepSpeech\n",
        "- You can use pre-trained models not just for classification, but also for **feature extraction**, **embedding generation**, or as the backbone for more complex architectures like object detection and segmentation.\n",
        "\n",
        "### 7. **State-of-the-Art Architectures**\n",
        "- Pre-trained models are often state-of-the-art (SOTA) models that have been optimized and validated by the research community. Using these models means you’re starting from a high-quality, reliable baseline that is likely to outperform custom models trained from scratch on small datasets.\n",
        "\n",
        "### 8. **Simpler for Beginners**\n",
        "- Pre-trained models lower the barrier for entry into deep learning. Beginners can easily use and fine-tune pre-trained models without needing to understand every complex detail of neural network training. This enables rapid experimentation and learning.\n",
        "\n",
        "### Example in Practice:\n",
        "- In **TensorFlow**, you can use models from `tf.keras.applications` (like ResNet50, MobileNet) and quickly fine-tune them for tasks like facial recognition, medical image analysis, etc.\n",
        "- In **PyTorch**, models from `torchvision.models` (like ResNet, AlexNet) or Hugging Face’s `transformers` library (for NLP tasks) allow you to perform tasks such as sentiment analysis or image classification by fine-tuning pre-trained weights.\n",
        "\n"
      ],
      "metadata": {
        "id": "HckA3jt5x3-y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SOlution of practical questions"
      ],
      "metadata": {
        "id": "KoPpCLK4ycRy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que.1, =\u001a How do you install and verify that TensorFlow 2.0 was installed successfully2\n"
      ],
      "metadata": {
        "id": "4YdL94jqyiU3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To install and verify that TensorFlow 2.0 (or a later version) is successfully installed, follow these steps:"
      ],
      "metadata": {
        "id": "yGfr3jPvyzah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Install TensorFlow 2.0\n",
        "!pip install tensorflow==2.0\n",
        "\n"
      ],
      "metadata": {
        "id": "InLF2I4-y2TT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Verify TensorFlow 2.0 Installatio\n",
        "#step 1  Import TensorFlow\n",
        "import tensorflow as tf\n",
        "# step 2 Verify the TensorFlow Version\n",
        "print(tf.__version__)\n",
        "#Step 3: Test TensorFlow Functionality\n",
        "# Test TensorFlow with a basic operation\n",
        "hello = tf.constant(\"Hello, TensorFlow!\")\n",
        "print(hello.numpy())\n",
        "\n"
      ],
      "metadata": {
        "id": "L1J3YSFUzUOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Troubleshooting:\n",
        "Installation Issues: If the installation fails or you encounter errors, ensure that your Python version is compatible (TensorFlow 2.0 supports Python 3.5–3.8).\n",
        "\n",
        "CUDA/cuDNN for GPU Support: If you're using the GPU version (tensorflow-gpu), ensure that you have CUDA and cuDNN correctly installed and that your system's GPU is compatible. You can verify TensorFlow's GPU availability with:"
      ],
      "metadata": {
        "id": "sH9CVNkU0Xqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
      ],
      "metadata": {
        "id": "ckr6muUg0ZNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que2. $\u001a How can you define a simple function in TensorFlow 2.0 to perform addition\n"
      ],
      "metadata": {
        "id": "VuiHHq0i0J0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define a simple function to perform addition\n",
        "@tf.function\n",
        "def add(a, b):\n",
        "    return a + b\n",
        "\n",
        "# Test the function with TensorFlow tensors\n",
        "a = tf.constant(5)\n",
        "b = tf.constant(3)\n",
        "\n",
        "result = add(a, b)\n",
        "print(\"Addition result:\", result.numpy())  # Convert the result to a numpy value for display\n"
      ],
      "metadata": {
        "id": "SkVg6x7P0jyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que.3) \u001a How can you create a simple neural network in TensorFlow 2.0 with one hidden layer2\n"
      ],
      "metadata": {
        "id": "LWhUgvlj0m5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#step 1- Import Necessary Libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "#Step 2. Define the Model\n",
        "# Define the model\n",
        "model = models.Sequential()\n",
        "\n",
        "# Input layer (implicitly defined by the input shape) + Hidden layer with 64 neurons\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(784,)))\n",
        "\n",
        "# Output layer with 10 neurons (for example, 10 classes for classification)\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "#Step 3- 3. Compile the Model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#4. Train the Model\n",
        "# Example: Use the MNIST dataset for training (as an example)\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Preprocess the data (flatten images and normalize)\n",
        "x_train = x_train.reshape(-1, 784).astype('float32') / 255\n",
        "x_test = x_test.reshape(-1, 784).astype('float32') / 255\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=32)\n",
        "\n",
        "#5. Evaluate the Model\n",
        "\n",
        "# Evaluate the model on test data\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f\"Test accuracy: {test_acc * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "g8I2T8tC0pJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que.4)8\u001a How can you visualize the training progress using TensorFlow and Matplotlib2\n"
      ],
      "metadata": {
        "id": "K-0mPA6W2D8D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SOlution -To visualize the training progress in TensorFlow 2.0, you can use Matplotlib to plot metrics such as loss and accuracy during training. TensorFlow provides a simple way to track these metrics via the history object returned by the model.fit() method. This history object contains the loss and accuracy values for each epoch.\n",
        "\n",
        "Steps to Visualize the Training Progress"
      ],
      "metadata": {
        "id": "qYAFqcoC2PzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visualize the training progress in **TensorFlow 2.0**, you can use **Matplotlib** to plot metrics such as **loss** and **accuracy** during training. TensorFlow provides a simple way to track these metrics via the `history` object returned by the `model.fit()` method. This `history` object contains the loss and accuracy values for each epoch.\n",
        "\n",
        "### Steps to Visualize the Training Progress\n",
        "\n",
        "#### 1. **Install Necessary Libraries**\n",
        "Ensure you have **TensorFlow** and **Matplotlib** installed:\n",
        "\n",
        "```bash\n",
        "pip install tensorflow matplotlib\n",
        "```\n",
        "\n",
        "#### 2. **Define and Train the Model**\n",
        "\n",
        "Let's first define a simple neural network model and train it on a dataset like **MNIST**. During training, we'll store the metrics in the `history` object.\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Preprocess the data (normalize and flatten)\n",
        "x_train = x_train.reshape(-1, 784).astype('float32') / 255\n",
        "x_test = x_test.reshape(-1, 784).astype('float32') / 255\n",
        "\n",
        "# Define a simple neural network\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', input_shape=(784,)),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')  # Output layer for 10 classes\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model and store the training history\n",
        "history = model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_test, y_test))\n",
        "```\n",
        "\n",
        "#### 3. **Plot the Training Progress**\n",
        "\n",
        "Once the model is trained, we can extract the loss and accuracy values from the `history` object and plot them using **Matplotlib**.\n",
        "\n",
        "```python\n",
        "# Plot training & validation accuracy values\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Training accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Training & validation loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Show the plots\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "### Explanation:\n",
        "- **`history.history['accuracy']`**: This contains the training accuracy at each epoch.\n",
        "- **`history.history['val_accuracy']`**: This contains the validation accuracy at each epoch.\n",
        "- **`history.history['loss']`**: This contains the training loss at each epoch.\n",
        "- **`history.history['val_loss']`**: This contains the validation loss at each epoch.\n",
        "\n",
        "The **Matplotlib** plots will show:\n",
        "- **Training and validation accuracy**: How well the model is performing on both the training and validation data.\n",
        "- **Training and validation loss**: How the model’s error decreases over time for both the training and validation data.\n",
        "\n",
        "### Example Output:\n",
        "- **Left plot (Accuracy)**: You will see curves showing how the accuracy improves with each epoch for both training and validation data.\n",
        "- **Right plot (Loss)**: You will see the loss values for training and validation, ideally showing a decreasing trend as the model learns.\n",
        "\n"
      ],
      "metadata": {
        "id": "qNy02n1u23wT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que.5.How do you install PyTorch and verify the PyTorch installation2\n"
      ],
      "metadata": {
        "id": "EKOwm5Te3L99"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solution -  To install **PyTorch** and verify that it has been installed correctly, follow the steps below:\n",
        "\n",
        "### 1. **Install PyTorch**\n",
        "You can install **PyTorch** using the `pip` package manager. The installation process varies depending on whether you want the **CPU version** or the **GPU version** (with CUDA support).\n",
        "\n",
        "#### For the CPU version:\n",
        "Run the following command in your terminal or command prompt:\n",
        "\n",
        "```bash\n",
        "pip install torch torchvision torchaudio\n",
        "```\n",
        "\n",
        "#### For the GPU version (CUDA support):\n",
        "If you have a compatible NVIDIA GPU and want to take advantage of hardware acceleration, install the **GPU version** with CUDA support. You need to check the PyTorch website for the appropriate command depending on your CUDA version.\n",
        "\n",
        "For example, for **CUDA 11.8**:\n",
        "\n",
        "```bash\n",
        "pip install torch torchvision torchaudio\n",
        "```\n",
        "\n",
        "Alternatively, you can use the official PyTorch website to get the correct installation command tailored to your setup (CUDA version, OS, etc.). Visit: [PyTorch Get Started](https://pytorch.org/get-started/locally/)\n",
        "\n",
        "### 2. **Verify PyTorch Installation**\n",
        "\n",
        "Once the installation is complete, you can verify it by checking the version and making sure everything is set up correctly.\n",
        "\n",
        "#### Step 1: Import PyTorch and Check the Version\n",
        "\n",
        "Open a Python interpreter or Jupyter notebook and type the following:\n",
        "\n",
        "```python\n",
        "import torch\n",
        "print(torch.__version__)  # Print the installed PyTorch version\n",
        "```\n",
        "\n",
        "You should see the installed version of PyTorch printed, for example:\n",
        "\n",
        "```\n",
        "1.13.0\n",
        "```\n",
        "\n",
        "#### Step 2: Check if PyTorch is Using the GPU (if applicable)\n",
        "\n",
        "If you installed the GPU version of PyTorch, you can check if it detects your GPU with the following command:\n",
        "\n",
        "```python\n",
        "print(torch.cuda.is_available())  # True if a CUDA-enabled GPU is available, else False\n",
        "```\n",
        "\n",
        "If the output is `True`, PyTorch can access your GPU. If it's `False`, either your system doesn't have a compatible GPU or the CUDA installation is not set up correctly.\n",
        "\n",
        "#### Step 3: Test a Simple Tensor Operation\n",
        "\n",
        "To verify that PyTorch is functioning properly, you can perform a simple tensor operation:\n",
        "\n",
        "```python\n",
        "x = torch.tensor([1.0, 2.0, 3.0])\n",
        "y = torch.tensor([4.0, 5.0, 6.0])\n",
        "\n",
        "result = x + y\n",
        "print(result)\n",
        "```\n",
        "\n",
        "This should output:\n",
        "\n",
        "```\n",
        "tensor([5., 7., 9.])\n",
        "```\n",
        "\n",
        "### 3. **Troubleshooting**\n",
        "\n",
        "- **Installation issues**: If you encounter errors during installation, ensure you are using the correct Python version (PyTorch supports Python 3.6 and later).\n",
        "- **GPU version issues**: If `torch.cuda.is_available()` returns `False`, make sure you have installed the GPU version correctly and that your system has compatible drivers and CUDA installed.\n",
        "\n",
        "By following these steps, you should be able to install and verify the installation of **PyTorch** successfully."
      ],
      "metadata": {
        "id": "3e-vDMBX4c7-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que-6. How do you create a simple neural network in PyTorch2\n"
      ],
      "metadata": {
        "id": "mTLQkM6Q4vmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define the model\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.softmax(x)\n",
        "        return x\n",
        "\n",
        "# Load the MNIST dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "testloader = DataLoader(testset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Instantiate the model, loss function, and optimizer\n",
        "model = SimpleNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in trainloader:\n",
        "        inputs = inputs.view(-1, 784)\n",
        "        optimize\n",
        "\n"
      ],
      "metadata": {
        "id": "wWboW-Yw45LE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que.7. How do you define a loss function and optimizer in PyTorch2\n"
      ],
      "metadata": {
        "id": "wjpuwzub5Tj_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solution - n PyTorch, the loss function and optimizer are key components when training a neural network. Here’s how you can define them:\n",
        "\n",
        "1. Defining a Loss Function\n",
        "The loss function measures how well the model’s predictions match the actual target values. PyTorch provides a variety of loss functions in the torch.nn module.\n",
        "\n",
        "Common Loss Functions:\n",
        "nn.CrossEntropyLoss(): For multi-class classification problems.\n",
        "nn.MSELoss(): For regression tasks.\n",
        "nn.BCEWithLogitsLoss(): For binary classification tasks.\n",
        "You typically define the loss function by instantiating the appropriate class.\n",
        "\n",
        "Example:\n",
        "For Multi-Class Classification (e.g., MNIST):\n",
        "python\n",
        "Copy code\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the loss function for classification (Cross-Entropy Loss)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "For Regression:\n",
        "python\n",
        "Copy code\n",
        "# Define the loss function for regression (Mean Squared Error)\n",
        "criterion = nn.MSELoss()\n",
        "For Binary Classification:\n",
        "python\n",
        "Copy code\n",
        "# Define the loss function for binary classification\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "2. Defining an Optimizer\n",
        "The optimizer updates the model's weights during training. PyTorch provides several optimizers in the torch.optim module.\n",
        "\n",
        "Common Optimizers:\n",
        "optim.SGD: Stochastic Gradient Descent.\n",
        "optim.Adam: Adaptive Moment Estimation (commonly used).\n",
        "optim.AdamW: Adam optimizer with weight decay (for better regularization).\n",
        "You typically define the optimizer by passing the model parameters to the optimizer class, which will update them based on gradients computed during training.\n",
        "\n",
        "Example:\n",
        "For the Adam Optimizer:\n",
        "python\n",
        "Copy code\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define the optimizer (Adam)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "For Stochastic Gradient Descent (SGD):\n",
        "python\n",
        "Copy code\n",
        "# Define the optimizer (SGD)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n"
      ],
      "metadata": {
        "id": "pVrOy8QZ5d9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Example neural network model\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 128)  # 784 input features (28x28) for MNIST\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)    # 10 output classes for MNIST\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "model = SimpleNN()\n",
        "\n",
        "# Define the loss function (Cross-Entropy for multi-class classification)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define the optimizer (Adam)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Example of forward pass, loss calculation, and backward pass in training loop\n",
        "# Assume `inputs` is a batch of images (e.g., 64x784) and `labels` are the true labels\n",
        "inputs = torch.randn(64, 784)  # Random batch for illustration\n",
        "labels = torch.randint(0, 10, (64,))  # Random labels for illustration\n",
        "\n",
        "# Zero the parameter gradients\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# Forward pass: Compute predicted outputs by passing inputs to the model\n",
        "outputs = model(inputs)\n",
        "\n",
        "# Compute the loss\n",
        "loss = criterion(outputs, labels)\n",
        "\n",
        "# Backward pass: Compute gradient of the loss with respect to model parameters\n",
        "loss.backward()\n",
        "\n",
        "# Optimize the model by updating the weights\n",
        "optimizer.step()\n",
        "\n",
        "print(f\"Loss: {loss.item()}\")\n"
      ],
      "metadata": {
        "id": "UKeVEraC5lWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que.8. How do you implement a custom loss function in PyTorch2\n",
        "\n",
        "SOlutio - In **PyTorch**, you can easily implement a custom loss function by subclassing the `torch.nn.Module` class. By doing this, you can define your own loss calculation in the `forward()` method.\n",
        "\n",
        "Here’s a step-by-step guide on how to implement a custom loss function in PyTorch:\n",
        "\n",
        "### 1. **Subclass `torch.nn.Module`**\n",
        "To create a custom loss function, you need to subclass `torch.nn.Module` and define the `forward()` method. The `forward()` method will take the model's predictions and the true labels (targets) as inputs, and it should return the computed loss.\n",
        "\n",
        "### 2. **Implementing the Custom Loss Function**\n",
        "Let's walk through an example of implementing a custom Mean Squared Error (MSE) loss function, where we apply a custom scaling factor to the loss.\n",
        "\n",
        "#### Example: Custom Loss Function (Scaled MSE Loss)\n",
        "We will create a custom loss function that calculates the Mean Squared Error and multiplies it by a custom scaling factor.\n",
        "\n",
        "```python\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the custom loss function by subclassing nn.Module\n",
        "class CustomMSELoss(nn.Module):\n",
        "    def __init__(self, scale_factor=1.0):\n",
        "        super(CustomMSELoss, self).__init__()\n",
        "        self.scale_factor = scale_factor  # Scaling factor for the loss\n",
        "\n",
        "    def forward(self, outputs, targets):\n",
        "        # Compute Mean Squared Error\n",
        "        mse_loss = torch.mean((outputs - targets) ** 2)\n",
        "        \n",
        "        # Apply custom scaling factor\n",
        "        scaled_loss = mse_loss * self.scale_factor\n",
        "        \n",
        "        return scaled_loss\n",
        "```\n",
        "\n",
        "### Explanation:\n",
        "- **`__init__`**: The constructor is where we initialize any parameters or constants needed by the loss function. In this case, we initialize a custom `scale_factor` that will be applied to the loss.\n",
        "- **`forward()`**: This method defines how the loss is calculated. We compute the Mean Squared Error (MSE) loss and then apply the custom scaling factor.\n",
        "\n",
        "### 3. **Using the Custom Loss Function**\n",
        "Now that we have defined the custom loss function, we can use it in a PyTorch training loop just like any other loss function.\n",
        "\n",
        "#### Example: Using the Custom Loss Function\n",
        "Here’s an example of using this custom loss function in a training loop:\n",
        "\n",
        "```python\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define a simple model (for demonstration)\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 128)  # Input layer (784 for MNIST)\n",
        "        self.fc2 = nn.Linear(128, 10)   # Output layer (10 classes for MNIST)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model and custom loss function\n",
        "model = SimpleNN()\n",
        "criterion = CustomMSELoss(scale_factor=2.0)  # Using the custom loss function with a scale factor of 2.0\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Example of training loop (simplified)\n",
        "inputs = torch.randn(64, 784)  # Random batch of input data (64 samples, 784 features)\n",
        "targets = torch.randn(64, 10)  # Random batch of target values (64 samples, 10 classes)\n",
        "\n",
        "# Zero the parameter gradients\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# Forward pass: Get predictions from the model\n",
        "outputs = model(inputs)\n",
        "\n",
        "# Compute the loss using the custom loss function\n",
        "loss = criterion(outputs, targets)\n",
        "\n",
        "# Backward pass: Compute gradients\n",
        "loss.backward()\n",
        "\n",
        "# Update the model parameters\n",
        "optimizer.step()\n",
        "\n",
        "# Print the loss value\n",
        "print(f\"Custom MSE Loss: {loss.item()}\")\n",
        "```\n",
        "\n",
        "### 4. **Use Case: Custom Loss with More Complex Operations**\n",
        "You can implement more complex custom loss functions depending on your requirements. For example:\n",
        "- **Hinge Loss** for Support Vector Machines.\n",
        "- **Contrastive Loss** for metric learning.\n",
        "- **Focal Loss** to address class imbalance in classification tasks.\n",
        "\n",
        "Here is an example of a more complex custom loss function, such as **Focal Loss**:\n",
        "\n",
        "```python\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=1.0, gamma=2.0):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha  # Balancing factor\n",
        "        self.gamma = gamma  # Focusing parameter\n",
        "\n",
        "    def forward(self, outputs, targets):\n",
        "        # Apply softmax to the model outputs\n",
        "        softmax_outputs = torch.softmax(outputs, dim=1)\n",
        "        \n",
        "        # Get the log probabilities\n",
        "        log_probs = torch.log(softmax_outputs)\n",
        "        \n",
        "        # Get the probabilities of the correct classes\n",
        "        correct_probs = softmax_outputs.gather(1, targets.unsqueeze(1))\n",
        "        \n",
        "        # Compute the focal loss\n",
        "        loss = -self.alpha * (1 - correct_probs) ** self.gamma * log_probs.gather(1, targets.unsqueeze(1))\n",
        "        \n",
        "        return loss.mean()\n",
        "```\n",
        "\n",
        "### Summary:\n",
        "- **Custom loss functions** are useful for specific tasks or when you need to apply custom behavior to the loss calculation.\n",
        "- To implement a custom loss function in PyTorch, subclass `torch.nn.Module` and implement the `forward()` method.\n",
        "- You can apply any mathematical operations to the model’s predictions and target values to compute the loss.\n",
        "\n",
        "By subclassing `torch.nn.Module`, you can create complex custom loss functions tailored to your problem."
      ],
      "metadata": {
        "id": "v51Ldk385umr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que.8. How do you save and load a TensorFlow model?\n",
        "Solution-In **TensorFlow 2.x**, you can save and load models in various formats, such as the **SavedModel** format (recommended for TensorFlow 2.x) or the **HDF5** format. Here’s how you can save and load a model in TensorFlow 2.0:\n",
        "\n",
        "### 1. **Saving a TensorFlow Model**\n",
        "\n",
        "You can save a model using the `model.save()` function. It will store both the architecture and the weights of the model.\n",
        "\n",
        "#### a. **Saving the Model in SavedModel Format (Default)**\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "\n",
        "# Example: Define a simple model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Save the model in SavedModel format\n",
        "model.save(\"path_to_my_model\")\n",
        "```\n",
        "\n",
        "- The `model.save()` function saves the model in TensorFlow’s **SavedModel** format by default, which is a directory containing the model's architecture, weights, and metadata.\n",
        "\n",
        "#### b. **Saving the Model in HDF5 Format (Optional)**\n",
        "You can save the model in HDF5 format (a single `.h5` file) by specifying the file extension.\n",
        "\n",
        "```python\n",
        "# Save the model in HDF5 format\n",
        "model.save(\"path_to_my_model.h5\")\n",
        "```\n",
        "\n",
        "### 2. **Loading a TensorFlow Model**\n",
        "\n",
        "After saving a model, you can load it back using `tf.keras.models.load_model()`. This function loads both the architecture and the weights of the model.\n",
        "\n",
        "#### a. **Loading the SavedModel**\n",
        "\n",
        "```python\n",
        "# Load the model from the SavedModel format\n",
        "loaded_model = tf.keras.models.load_model(\"path_to_my_model\")\n",
        "\n",
        "# Check the summary of the loaded model\n",
        "loaded_model.summary()\n",
        "```\n",
        "\n",
        "#### b. **Loading the HDF5 Model**\n",
        "\n",
        "If you saved the model in the HDF5 format, you can load it like this:\n",
        "\n",
        "```python\n",
        "# Load the model from the HDF5 file\n",
        "loaded_model = tf.keras.models.load_model(\"path_to_my_model.h5\")\n",
        "\n",
        "# Check the summary of the loaded model\n",
        "loaded_model.summary()\n",
        "```\n",
        "\n",
        "### 3. **Saving and Loading Model Weights Only**\n",
        "\n",
        "Sometimes, you may only want to save the model weights without saving the entire model architecture. This is useful if you want to keep the model architecture separate from its learned parameters.\n",
        "\n",
        "#### a. **Saving Weights**\n",
        "\n",
        "```python\n",
        "# Save the model weights only\n",
        "model.save_weights(\"path_to_model_weights.h5\")\n",
        "```\n",
        "\n",
        "#### b. **Loading Weights**\n",
        "\n",
        "You can load the weights into the model with the same architecture as before:\n",
        "\n",
        "```python\n",
        "# Assume model architecture is defined\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Load the model weights\n",
        "model.load_weights(\"path_to_model_weights.h5\")\n",
        "```\n",
        "\n",
        "### Summary of Formats:\n",
        "- **SavedModel**: Recommended format for TensorFlow 2.x. It saves the entire model, including architecture, weights, and training configuration.\n",
        "- **HDF5**: A single file format (usually `.h5`). It saves the model in a compact format, but it’s not as flexible for TensorFlow 2.x’s features as SavedModel.\n"
      ],
      "metadata": {
        "id": "ABOBNgFg59u5"
      }
    }
  ]
}