{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNhqB5FAdydrvNI2toHR8eE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saurabhmungale/DataScience_Assignements/blob/main/Neural_Network_A_Simple_Perception_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que.1) How do you create a simple perceptron for basic binary classification!"
      ],
      "metadata": {
        "id": "ry84w0c5Yr1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Step 1: Define the Perceptron class\n",
        "class Perceptron:\n",
        "    def __init__(self, input_size, learning_rate=0.1):\n",
        "        # Initialize weights and bias\n",
        "        self.weights = np.zeros(input_size)\n",
        "        self.bias = 0\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    # Activation function (step function)\n",
        "    def step_function(self, x):\n",
        "        return 1 if x >= 0 else 0\n",
        "\n",
        "    # Predict function (calculate weighted sum and apply activation)\n",
        "    def predict(self, X):\n",
        "        weighted_sum = np.dot(X, self.weights) + self.bias\n",
        "        return self.step_function(weighted_sum)\n",
        "\n",
        "    # Training function (Perceptron Learning Rule)\n",
        "    def train(self, X, y, epochs=100):\n",
        "        for epoch in range(epochs):\n",
        "            for i in range(len(X)):\n",
        "                # Get prediction\n",
        "                prediction = self.predict(X[i])\n",
        "                # Update weights and bias if there's an error\n",
        "                error = y[i] - prediction\n",
        "                self.weights += self.learning_rate * error * X[i]\n",
        "                self.bias += self.learning_rate * error\n",
        "\n",
        "# Step 2: Example Dataset for binary classification (AND operation)\n",
        "# Inputs (X) and Labels (y) for the AND operation\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])  # Input features\n",
        "y = np.array([0, 0, 0, 1])  # Target labels (AND output)\n",
        "\n",
        "# Step 3: Initialize Perceptron and Train\n",
        "perceptron = Perceptron(input_size=2)\n",
        "perceptron.train(X, y, epochs=10)\n",
        "\n",
        "# Step 4: Test the perceptron\n",
        "for i in range(len(X)):\n",
        "    print(f\"Input: {X[i]}, Predicted: {perceptron.predict(X[i])}, Actual: {y[i]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6XpPNYXYw8K",
        "outputId": "ddc4ebc4-8c73-4b2c-d3dd-2fd20d0d8e77"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: [0 0], Predicted: 0, Actual: 0\n",
            "Input: [0 1], Predicted: 0, Actual: 0\n",
            "Input: [1 0], Predicted: 0, Actual: 0\n",
            "Input: [1 1], Predicted: 1, Actual: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que.2)How can you build a neural network with one hidden layer using Keras!"
      ],
      "metadata": {
        "id": "l70RtVnKY9ae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Step 1: Load and prepare the data (Iris dataset for example)\n",
        "data = load_iris()\n",
        "X = data.data  # Features (4 features)\n",
        "y = data.target  # Labels (3 classes)\n",
        "\n",
        "# Convert labels to binary for simplicity (e.g., class 0 vs classes 1 and 2)\n",
        "y = np.where(y == 0, 0, 1)  # Binary classification: Class 0 vs Class 1 or 2\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 2: Define the Neural Network model\n",
        "model = Sequential()\n",
        "\n",
        "# Input layer (number of features = 4) and the hidden layer with 10 neurons\n",
        "model.add(Dense(10, input_dim=4, activation='relu'))  # One hidden layer with 10 neurons\n",
        "\n",
        "# Output layer (binary classification with 1 neuron)\n",
        "model.add(Dense(1, activation='sigmoid'))  # Sigmoid for binary classification\n",
        "\n",
        "# Step 3: Compile the model\n",
        "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Train the model\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=10, validation_data=(X_test, y_test))\n",
        "\n",
        "# Step 5: Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n",
        "\n",
        "# Step 6: Make predictions\n",
        "predictions = model.predict(X_test)\n",
        "predictions = (predictions > 0.5).astype(int)  # Convert probabilities to binary values\n",
        "print(\"Predictions:\", predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9nVis_NZAJ0",
        "outputId": "6b3e6bd8-04d5-4e9e-8945-a7c527147106"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3800 - loss: 1.6952 - val_accuracy: 0.3333 - val_loss: 1.6421\n",
            "Epoch 2/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3220 - loss: 1.5534 - val_accuracy: 0.3333 - val_loss: 1.3743\n",
            "Epoch 3/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2946 - loss: 1.3817 - val_accuracy: 0.3333 - val_loss: 1.1370\n",
            "Epoch 4/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3432 - loss: 1.0584 - val_accuracy: 0.3333 - val_loss: 0.9404\n",
            "Epoch 5/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3710 - loss: 0.8499 - val_accuracy: 0.3333 - val_loss: 0.7783\n",
            "Epoch 6/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3277 - loss: 0.7452 - val_accuracy: 0.4000 - val_loss: 0.6492\n",
            "Epoch 7/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3360 - loss: 0.6647 - val_accuracy: 0.5667 - val_loss: 0.5519\n",
            "Epoch 8/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7084 - loss: 0.5344 - val_accuracy: 0.9000 - val_loss: 0.4867\n",
            "Epoch 9/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9035 - loss: 0.4626 - val_accuracy: 0.9667 - val_loss: 0.4377\n",
            "Epoch 10/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.4319 - val_accuracy: 1.0000 - val_loss: 0.4015\n",
            "Epoch 11/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.3957 - val_accuracy: 1.0000 - val_loss: 0.3755\n",
            "Epoch 12/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.3808 - val_accuracy: 1.0000 - val_loss: 0.3578\n",
            "Epoch 13/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.3593 - val_accuracy: 1.0000 - val_loss: 0.3444\n",
            "Epoch 14/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.3384 - val_accuracy: 1.0000 - val_loss: 0.3341\n",
            "Epoch 15/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.3467 - val_accuracy: 1.0000 - val_loss: 0.3263\n",
            "Epoch 16/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.3282 - val_accuracy: 1.0000 - val_loss: 0.3197\n",
            "Epoch 17/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.3363 - val_accuracy: 1.0000 - val_loss: 0.3142\n",
            "Epoch 18/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.3104 - val_accuracy: 1.0000 - val_loss: 0.3088\n",
            "Epoch 19/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9943 - loss: 0.2994 - val_accuracy: 1.0000 - val_loss: 0.3040\n",
            "Epoch 20/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9915 - loss: 0.3156 - val_accuracy: 1.0000 - val_loss: 0.2993\n",
            "Epoch 21/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9987 - loss: 0.3041 - val_accuracy: 1.0000 - val_loss: 0.2948\n",
            "Epoch 22/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9972 - loss: 0.2909 - val_accuracy: 1.0000 - val_loss: 0.2904\n",
            "Epoch 23/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9954 - loss: 0.2851 - val_accuracy: 1.0000 - val_loss: 0.2860\n",
            "Epoch 24/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9972 - loss: 0.2787 - val_accuracy: 1.0000 - val_loss: 0.2815\n",
            "Epoch 25/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9915 - loss: 0.2670 - val_accuracy: 1.0000 - val_loss: 0.2773\n",
            "Epoch 26/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9972 - loss: 0.2699 - val_accuracy: 1.0000 - val_loss: 0.2727\n",
            "Epoch 27/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.2778 - val_accuracy: 1.0000 - val_loss: 0.2682\n",
            "Epoch 28/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.2807 - val_accuracy: 1.0000 - val_loss: 0.2636\n",
            "Epoch 29/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.2612 - val_accuracy: 1.0000 - val_loss: 0.2592\n",
            "Epoch 30/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.2495 - val_accuracy: 1.0000 - val_loss: 0.2550\n",
            "Epoch 31/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.2557 - val_accuracy: 1.0000 - val_loss: 0.2505\n",
            "Epoch 32/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.2355 - val_accuracy: 1.0000 - val_loss: 0.2461\n",
            "Epoch 33/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.2275 - val_accuracy: 1.0000 - val_loss: 0.2418\n",
            "Epoch 34/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.2386 - val_accuracy: 1.0000 - val_loss: 0.2369\n",
            "Epoch 35/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.2549 - val_accuracy: 1.0000 - val_loss: 0.2323\n",
            "Epoch 36/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.2252 - val_accuracy: 1.0000 - val_loss: 0.2281\n",
            "Epoch 37/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.2043 - val_accuracy: 1.0000 - val_loss: 0.2240\n",
            "Epoch 38/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.2130 - val_accuracy: 1.0000 - val_loss: 0.2198\n",
            "Epoch 39/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.2000 - val_accuracy: 1.0000 - val_loss: 0.2154\n",
            "Epoch 40/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.2064 - val_accuracy: 1.0000 - val_loss: 0.2112\n",
            "Epoch 41/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.2248 - val_accuracy: 1.0000 - val_loss: 0.2067\n",
            "Epoch 42/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.2176 - val_accuracy: 1.0000 - val_loss: 0.2026\n",
            "Epoch 43/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1899 - val_accuracy: 1.0000 - val_loss: 0.1986\n",
            "Epoch 44/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1981 - val_accuracy: 1.0000 - val_loss: 0.1944\n",
            "Epoch 45/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1858 - val_accuracy: 1.0000 - val_loss: 0.1904\n",
            "Epoch 46/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1913 - val_accuracy: 1.0000 - val_loss: 0.1866\n",
            "Epoch 47/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1836 - val_accuracy: 1.0000 - val_loss: 0.1828\n",
            "Epoch 48/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1903 - val_accuracy: 1.0000 - val_loss: 0.1787\n",
            "Epoch 49/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1709 - val_accuracy: 1.0000 - val_loss: 0.1750\n",
            "Epoch 50/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1707 - val_accuracy: 1.0000 - val_loss: 0.1715\n",
            "Epoch 51/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1615 - val_accuracy: 1.0000 - val_loss: 0.1680\n",
            "Epoch 52/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1546 - val_accuracy: 1.0000 - val_loss: 0.1645\n",
            "Epoch 53/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1618 - val_accuracy: 1.0000 - val_loss: 0.1609\n",
            "Epoch 54/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1587 - val_accuracy: 1.0000 - val_loss: 0.1573\n",
            "Epoch 55/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1511 - val_accuracy: 1.0000 - val_loss: 0.1541\n",
            "Epoch 56/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1512 - val_accuracy: 1.0000 - val_loss: 0.1508\n",
            "Epoch 57/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1503 - val_accuracy: 1.0000 - val_loss: 0.1473\n",
            "Epoch 58/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1454 - val_accuracy: 1.0000 - val_loss: 0.1442\n",
            "Epoch 59/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1368 - val_accuracy: 1.0000 - val_loss: 0.1413\n",
            "Epoch 60/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1399 - val_accuracy: 1.0000 - val_loss: 0.1380\n",
            "Epoch 61/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1349 - val_accuracy: 1.0000 - val_loss: 0.1352\n",
            "Epoch 62/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1368 - val_accuracy: 1.0000 - val_loss: 0.1323\n",
            "Epoch 63/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1186 - val_accuracy: 1.0000 - val_loss: 0.1297\n",
            "Epoch 64/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1289 - val_accuracy: 1.0000 - val_loss: 0.1267\n",
            "Epoch 65/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1280 - val_accuracy: 1.0000 - val_loss: 0.1240\n",
            "Epoch 66/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1213 - val_accuracy: 1.0000 - val_loss: 0.1214\n",
            "Epoch 67/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1110 - val_accuracy: 1.0000 - val_loss: 0.1189\n",
            "Epoch 68/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1211 - val_accuracy: 1.0000 - val_loss: 0.1160\n",
            "Epoch 69/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1223 - val_accuracy: 1.0000 - val_loss: 0.1138\n",
            "Epoch 70/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1149 - val_accuracy: 1.0000 - val_loss: 0.1115\n",
            "Epoch 71/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1087 - val_accuracy: 1.0000 - val_loss: 0.1091\n",
            "Epoch 72/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1083 - val_accuracy: 1.0000 - val_loss: 0.1067\n",
            "Epoch 73/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1037 - val_accuracy: 1.0000 - val_loss: 0.1044\n",
            "Epoch 74/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1011 - val_accuracy: 1.0000 - val_loss: 0.1023\n",
            "Epoch 75/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0992 - val_accuracy: 1.0000 - val_loss: 0.1000\n",
            "Epoch 76/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1099 - val_accuracy: 1.0000 - val_loss: 0.0978\n",
            "Epoch 77/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0934 - val_accuracy: 1.0000 - val_loss: 0.0961\n",
            "Epoch 78/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.1049 - val_accuracy: 1.0000 - val_loss: 0.0938\n",
            "Epoch 79/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0922 - val_accuracy: 1.0000 - val_loss: 0.0920\n",
            "Epoch 80/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0915 - val_accuracy: 1.0000 - val_loss: 0.0900\n",
            "Epoch 81/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0836 - val_accuracy: 1.0000 - val_loss: 0.0883\n",
            "Epoch 82/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0877 - val_accuracy: 1.0000 - val_loss: 0.0864\n",
            "Epoch 83/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0849 - val_accuracy: 1.0000 - val_loss: 0.0846\n",
            "Epoch 84/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0832 - val_accuracy: 1.0000 - val_loss: 0.0828\n",
            "Epoch 85/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0815 - val_accuracy: 1.0000 - val_loss: 0.0812\n",
            "Epoch 86/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0806 - val_accuracy: 1.0000 - val_loss: 0.0797\n",
            "Epoch 87/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0881 - val_accuracy: 1.0000 - val_loss: 0.0779\n",
            "Epoch 88/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0773 - val_accuracy: 1.0000 - val_loss: 0.0763\n",
            "Epoch 89/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0817 - val_accuracy: 1.0000 - val_loss: 0.0749\n",
            "Epoch 90/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0746 - val_accuracy: 1.0000 - val_loss: 0.0733\n",
            "Epoch 91/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0796 - val_accuracy: 1.0000 - val_loss: 0.0720\n",
            "Epoch 92/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0678 - val_accuracy: 1.0000 - val_loss: 0.0704\n",
            "Epoch 93/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0720 - val_accuracy: 1.0000 - val_loss: 0.0691\n",
            "Epoch 94/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0698 - val_accuracy: 1.0000 - val_loss: 0.0676\n",
            "Epoch 95/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0608 - val_accuracy: 1.0000 - val_loss: 0.0664\n",
            "Epoch 96/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0697 - val_accuracy: 1.0000 - val_loss: 0.0651\n",
            "Epoch 97/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0613 - val_accuracy: 1.0000 - val_loss: 0.0638\n",
            "Epoch 98/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0596 - val_accuracy: 1.0000 - val_loss: 0.0625\n",
            "Epoch 99/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0640 - val_accuracy: 1.0000 - val_loss: 0.0613\n",
            "Epoch 100/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0597 - val_accuracy: 1.0000 - val_loss: 0.0603\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 1.0000 - loss: 0.0603\n",
            "Test Accuracy: 100.00%\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "Predictions: [[1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que.3)How do you initialize weights using the Xavier (Glorot) initialization method in Keras!"
      ],
      "metadata": {
        "id": "mF9PrvIQZLlc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.initializers import GlorotUniform\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load and prepare the data (Iris dataset for example)\n",
        "data = load_iris()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Labels\n",
        "\n",
        "# Convert labels to binary for simplicity (e.g., class 0 vs classes 1 and 2)\n",
        "y = (y == 0).astype(int)  # Convert to binary classification: Class 0 vs Class 1 or 2\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Add a hidden layer with Xavier initialization\n",
        "model.add(Dense(10, input_dim=4, activation='relu', kernel_initializer=GlorotUniform()))  # GlorotUniform initialization\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(1, activation='sigmoid', kernel_initializer=GlorotUniform()))  # Xavier initialization for output layer\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=10, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOIoZCGdZNpi",
        "outputId": "690501c3-d65a-4367-c140-e3da2022c5f8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6705 - loss: 0.7676 - val_accuracy: 0.6667 - val_loss: 0.7043\n",
            "Epoch 2/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6709 - loss: 0.6946 - val_accuracy: 0.6667 - val_loss: 0.6344\n",
            "Epoch 3/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6604 - loss: 0.6384 - val_accuracy: 0.6667 - val_loss: 0.5759\n",
            "Epoch 4/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6480 - loss: 0.6008 - val_accuracy: 0.6667 - val_loss: 0.5285\n",
            "Epoch 5/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7016 - loss: 0.5001 - val_accuracy: 0.6667 - val_loss: 0.4975\n",
            "Epoch 6/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6728 - loss: 0.5051 - val_accuracy: 0.6667 - val_loss: 0.4724\n",
            "Epoch 7/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6867 - loss: 0.4600 - val_accuracy: 0.6667 - val_loss: 0.4541\n",
            "Epoch 8/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6716 - loss: 0.4626 - val_accuracy: 0.6667 - val_loss: 0.4384\n",
            "Epoch 9/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6483 - loss: 0.4630 - val_accuracy: 0.6667 - val_loss: 0.4236\n",
            "Epoch 10/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6369 - loss: 0.4634 - val_accuracy: 0.6667 - val_loss: 0.4098\n",
            "Epoch 11/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6561 - loss: 0.4369 - val_accuracy: 0.6667 - val_loss: 0.3970\n",
            "Epoch 12/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6059 - loss: 0.4497 - val_accuracy: 0.6667 - val_loss: 0.3848\n",
            "Epoch 13/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6971 - loss: 0.3821 - val_accuracy: 0.6667 - val_loss: 0.3729\n",
            "Epoch 14/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6842 - loss: 0.3893 - val_accuracy: 0.7333 - val_loss: 0.3608\n",
            "Epoch 15/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7274 - loss: 0.3573 - val_accuracy: 0.7667 - val_loss: 0.3491\n",
            "Epoch 16/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7259 - loss: 0.3875 - val_accuracy: 0.8333 - val_loss: 0.3372\n",
            "Epoch 17/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8485 - loss: 0.3718 - val_accuracy: 0.9000 - val_loss: 0.3260\n",
            "Epoch 18/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8955 - loss: 0.3248 - val_accuracy: 0.9000 - val_loss: 0.3152\n",
            "Epoch 19/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9031 - loss: 0.3440 - val_accuracy: 0.9333 - val_loss: 0.3045\n",
            "Epoch 20/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9370 - loss: 0.3251 - val_accuracy: 1.0000 - val_loss: 0.2936\n",
            "Epoch 21/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9517 - loss: 0.3145 - val_accuracy: 1.0000 - val_loss: 0.2834\n",
            "Epoch 22/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9716 - loss: 0.2725 - val_accuracy: 1.0000 - val_loss: 0.2739\n",
            "Epoch 23/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9849 - loss: 0.2819 - val_accuracy: 1.0000 - val_loss: 0.2643\n",
            "Epoch 24/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9954 - loss: 0.2787 - val_accuracy: 1.0000 - val_loss: 0.2543\n",
            "Epoch 25/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9896 - loss: 0.2551 - val_accuracy: 1.0000 - val_loss: 0.2454\n",
            "Epoch 26/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9896 - loss: 0.2824 - val_accuracy: 1.0000 - val_loss: 0.2359\n",
            "Epoch 27/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.2364 - val_accuracy: 1.0000 - val_loss: 0.2277\n",
            "Epoch 28/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.2442 - val_accuracy: 1.0000 - val_loss: 0.2195\n",
            "Epoch 29/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.2262 - val_accuracy: 1.0000 - val_loss: 0.2114\n",
            "Epoch 30/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.2280 - val_accuracy: 1.0000 - val_loss: 0.2032\n",
            "Epoch 31/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.2227 - val_accuracy: 1.0000 - val_loss: 0.1957\n",
            "Epoch 32/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.2083 - val_accuracy: 1.0000 - val_loss: 0.1884\n",
            "Epoch 33/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.2142 - val_accuracy: 1.0000 - val_loss: 0.1812\n",
            "Epoch 34/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1787 - val_accuracy: 1.0000 - val_loss: 0.1747\n",
            "Epoch 35/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1725 - val_accuracy: 1.0000 - val_loss: 0.1679\n",
            "Epoch 36/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1671 - val_accuracy: 1.0000 - val_loss: 0.1618\n",
            "Epoch 37/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1952 - val_accuracy: 1.0000 - val_loss: 0.1552\n",
            "Epoch 38/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1488 - val_accuracy: 1.0000 - val_loss: 0.1495\n",
            "Epoch 39/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1538 - val_accuracy: 1.0000 - val_loss: 0.1445\n",
            "Epoch 40/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1410 - val_accuracy: 1.0000 - val_loss: 0.1388\n",
            "Epoch 41/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1374 - val_accuracy: 1.0000 - val_loss: 0.1334\n",
            "Epoch 42/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1497 - val_accuracy: 1.0000 - val_loss: 0.1284\n",
            "Epoch 43/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1254 - val_accuracy: 1.0000 - val_loss: 0.1239\n",
            "Epoch 44/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1298 - val_accuracy: 1.0000 - val_loss: 0.1194\n",
            "Epoch 45/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1259 - val_accuracy: 1.0000 - val_loss: 0.1152\n",
            "Epoch 46/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1273 - val_accuracy: 1.0000 - val_loss: 0.1109\n",
            "Epoch 47/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1260 - val_accuracy: 1.0000 - val_loss: 0.1070\n",
            "Epoch 48/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1246 - val_accuracy: 1.0000 - val_loss: 0.1032\n",
            "Epoch 49/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1112 - val_accuracy: 1.0000 - val_loss: 0.0996\n",
            "Epoch 50/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1178 - val_accuracy: 1.0000 - val_loss: 0.0961\n",
            "Epoch 51/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1175 - val_accuracy: 1.0000 - val_loss: 0.0927\n",
            "Epoch 52/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1053 - val_accuracy: 1.0000 - val_loss: 0.0898\n",
            "Epoch 53/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1079 - val_accuracy: 1.0000 - val_loss: 0.0864\n",
            "Epoch 54/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0868 - val_accuracy: 1.0000 - val_loss: 0.0837\n",
            "Epoch 55/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0827 - val_accuracy: 1.0000 - val_loss: 0.0811\n",
            "Epoch 56/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0883 - val_accuracy: 1.0000 - val_loss: 0.0784\n",
            "Epoch 57/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0788 - val_accuracy: 1.0000 - val_loss: 0.0758\n",
            "Epoch 58/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0837 - val_accuracy: 1.0000 - val_loss: 0.0730\n",
            "Epoch 59/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0880 - val_accuracy: 1.0000 - val_loss: 0.0705\n",
            "Epoch 60/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0849 - val_accuracy: 1.0000 - val_loss: 0.0685\n",
            "Epoch 61/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0810 - val_accuracy: 1.0000 - val_loss: 0.0665\n",
            "Epoch 62/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0670 - val_accuracy: 1.0000 - val_loss: 0.0646\n",
            "Epoch 63/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0754 - val_accuracy: 1.0000 - val_loss: 0.0623\n",
            "Epoch 64/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0689 - val_accuracy: 1.0000 - val_loss: 0.0604\n",
            "Epoch 65/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0715 - val_accuracy: 1.0000 - val_loss: 0.0586\n",
            "Epoch 66/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0595 - val_accuracy: 1.0000 - val_loss: 0.0569\n",
            "Epoch 67/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0643 - val_accuracy: 1.0000 - val_loss: 0.0553\n",
            "Epoch 68/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0648 - val_accuracy: 1.0000 - val_loss: 0.0536\n",
            "Epoch 69/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0591 - val_accuracy: 1.0000 - val_loss: 0.0519\n",
            "Epoch 70/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0597 - val_accuracy: 1.0000 - val_loss: 0.0503\n",
            "Epoch 71/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0575 - val_accuracy: 1.0000 - val_loss: 0.0490\n",
            "Epoch 72/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0596 - val_accuracy: 1.0000 - val_loss: 0.0477\n",
            "Epoch 73/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0546 - val_accuracy: 1.0000 - val_loss: 0.0464\n",
            "Epoch 74/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0539 - val_accuracy: 1.0000 - val_loss: 0.0451\n",
            "Epoch 75/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0471 - val_accuracy: 1.0000 - val_loss: 0.0439\n",
            "Epoch 76/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0509 - val_accuracy: 1.0000 - val_loss: 0.0426\n",
            "Epoch 77/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0448 - val_accuracy: 1.0000 - val_loss: 0.0414\n",
            "Epoch 78/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0486 - val_accuracy: 1.0000 - val_loss: 0.0403\n",
            "Epoch 79/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0379 - val_accuracy: 1.0000 - val_loss: 0.0394\n",
            "Epoch 80/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0464 - val_accuracy: 1.0000 - val_loss: 0.0381\n",
            "Epoch 81/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0450 - val_accuracy: 1.0000 - val_loss: 0.0372\n",
            "Epoch 82/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0429 - val_accuracy: 1.0000 - val_loss: 0.0363\n",
            "Epoch 83/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0401 - val_accuracy: 1.0000 - val_loss: 0.0353\n",
            "Epoch 84/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0391 - val_accuracy: 1.0000 - val_loss: 0.0345\n",
            "Epoch 85/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0401 - val_accuracy: 1.0000 - val_loss: 0.0336\n",
            "Epoch 86/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0388 - val_accuracy: 1.0000 - val_loss: 0.0328\n",
            "Epoch 87/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0419 - val_accuracy: 1.0000 - val_loss: 0.0319\n",
            "Epoch 88/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0381 - val_accuracy: 1.0000 - val_loss: 0.0311\n",
            "Epoch 89/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0370 - val_accuracy: 1.0000 - val_loss: 0.0304\n",
            "Epoch 90/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0362 - val_accuracy: 1.0000 - val_loss: 0.0298\n",
            "Epoch 91/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0341 - val_accuracy: 1.0000 - val_loss: 0.0290\n",
            "Epoch 92/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0335 - val_accuracy: 1.0000 - val_loss: 0.0283\n",
            "Epoch 93/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0345 - val_accuracy: 1.0000 - val_loss: 0.0276\n",
            "Epoch 94/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0331 - val_accuracy: 1.0000 - val_loss: 0.0269\n",
            "Epoch 95/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0288 - val_accuracy: 1.0000 - val_loss: 0.0263\n",
            "Epoch 96/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0279 - val_accuracy: 1.0000 - val_loss: 0.0258\n",
            "Epoch 97/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0253 - val_accuracy: 1.0000 - val_loss: 0.0252\n",
            "Epoch 98/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0316 - val_accuracy: 1.0000 - val_loss: 0.0247\n",
            "Epoch 99/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0323 - val_accuracy: 1.0000 - val_loss: 0.0242\n",
            "Epoch 100/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0243 - val_accuracy: 1.0000 - val_loss: 0.0237\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 0.0237\n",
            "Test Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "QUe.4)How can you apply different activation functions in a neural network in Keras!"
      ],
      "metadata": {
        "id": "Hc5vujTZaiiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load and prepare the data (Iris dataset for example)\n",
        "data = load_iris()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Labels\n",
        "\n",
        "# Convert labels to binary for simplicity (e.g., class 0 vs classes 1 and 2)\n",
        "y = (y == 0).astype(int)  # Binary classification: Class 0 vs Class 1 or 2\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Add layers with different activation functions\n",
        "model.add(Dense(10, input_dim=4, activation='relu'))  # ReLU for hidden layer\n",
        "model.add(Dense(10, activation='tanh'))  # Tanh for another hidden layer\n",
        "model.add(Dense(1, activation='sigmoid'))  # Sigmoid for output layer (binary classification)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=10, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNkjU4TzakAT",
        "outputId": "903c8c8b-88d1-44b8-801c-4a51a9334146"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6828 - loss: 0.6817 - val_accuracy: 0.6667 - val_loss: 0.6581\n",
            "Epoch 2/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6356 - loss: 0.6642 - val_accuracy: 0.6667 - val_loss: 0.6164\n",
            "Epoch 3/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7102 - loss: 0.5859 - val_accuracy: 0.6667 - val_loss: 0.5649\n",
            "Epoch 4/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7413 - loss: 0.5229 - val_accuracy: 0.7000 - val_loss: 0.5034\n",
            "Epoch 5/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8992 - loss: 0.5113 - val_accuracy: 1.0000 - val_loss: 0.4431\n",
            "Epoch 6/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.4390 - val_accuracy: 1.0000 - val_loss: 0.3961\n",
            "Epoch 7/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.3898 - val_accuracy: 1.0000 - val_loss: 0.3561\n",
            "Epoch 8/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.3434 - val_accuracy: 1.0000 - val_loss: 0.3172\n",
            "Epoch 9/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.3086 - val_accuracy: 1.0000 - val_loss: 0.2766\n",
            "Epoch 10/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.2572 - val_accuracy: 1.0000 - val_loss: 0.2334\n",
            "Epoch 11/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.2235 - val_accuracy: 1.0000 - val_loss: 0.1923\n",
            "Epoch 12/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.1867 - val_accuracy: 1.0000 - val_loss: 0.1629\n",
            "Epoch 13/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.1579 - val_accuracy: 1.0000 - val_loss: 0.1425\n",
            "Epoch 14/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.1360 - val_accuracy: 1.0000 - val_loss: 0.1273\n",
            "Epoch 15/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.1215 - val_accuracy: 1.0000 - val_loss: 0.1159\n",
            "Epoch 16/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1135 - val_accuracy: 1.0000 - val_loss: 0.1051\n",
            "Epoch 17/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0996 - val_accuracy: 1.0000 - val_loss: 0.0966\n",
            "Epoch 18/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0957 - val_accuracy: 1.0000 - val_loss: 0.0894\n",
            "Epoch 19/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0886 - val_accuracy: 1.0000 - val_loss: 0.0829\n",
            "Epoch 20/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0807 - val_accuracy: 1.0000 - val_loss: 0.0774\n",
            "Epoch 21/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0759 - val_accuracy: 1.0000 - val_loss: 0.0721\n",
            "Epoch 22/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0722 - val_accuracy: 1.0000 - val_loss: 0.0677\n",
            "Epoch 23/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0690 - val_accuracy: 1.0000 - val_loss: 0.0635\n",
            "Epoch 24/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0644 - val_accuracy: 1.0000 - val_loss: 0.0597\n",
            "Epoch 25/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0595 - val_accuracy: 1.0000 - val_loss: 0.0561\n",
            "Epoch 26/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0577 - val_accuracy: 1.0000 - val_loss: 0.0531\n",
            "Epoch 27/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0534 - val_accuracy: 1.0000 - val_loss: 0.0502\n",
            "Epoch 28/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0506 - val_accuracy: 1.0000 - val_loss: 0.0474\n",
            "Epoch 29/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0471 - val_accuracy: 1.0000 - val_loss: 0.0449\n",
            "Epoch 30/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0457 - val_accuracy: 1.0000 - val_loss: 0.0426\n",
            "Epoch 31/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0427 - val_accuracy: 1.0000 - val_loss: 0.0405\n",
            "Epoch 32/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0400 - val_accuracy: 1.0000 - val_loss: 0.0385\n",
            "Epoch 33/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0397 - val_accuracy: 1.0000 - val_loss: 0.0367\n",
            "Epoch 34/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0364 - val_accuracy: 1.0000 - val_loss: 0.0350\n",
            "Epoch 35/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0348 - val_accuracy: 1.0000 - val_loss: 0.0335\n",
            "Epoch 36/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0338 - val_accuracy: 1.0000 - val_loss: 0.0321\n",
            "Epoch 37/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0332 - val_accuracy: 1.0000 - val_loss: 0.0306\n",
            "Epoch 38/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0302 - val_accuracy: 1.0000 - val_loss: 0.0294\n",
            "Epoch 39/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0290 - val_accuracy: 1.0000 - val_loss: 0.0282\n",
            "Epoch 40/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0275 - val_accuracy: 1.0000 - val_loss: 0.0271\n",
            "Epoch 41/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0276 - val_accuracy: 1.0000 - val_loss: 0.0260\n",
            "Epoch 42/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0258 - val_accuracy: 1.0000 - val_loss: 0.0251\n",
            "Epoch 43/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0248 - val_accuracy: 1.0000 - val_loss: 0.0241\n",
            "Epoch 44/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0241 - val_accuracy: 1.0000 - val_loss: 0.0232\n",
            "Epoch 45/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0237 - val_accuracy: 1.0000 - val_loss: 0.0224\n",
            "Epoch 46/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0226 - val_accuracy: 1.0000 - val_loss: 0.0216\n",
            "Epoch 47/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0214 - val_accuracy: 1.0000 - val_loss: 0.0209\n",
            "Epoch 48/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0212 - val_accuracy: 1.0000 - val_loss: 0.0202\n",
            "Epoch 49/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0209 - val_accuracy: 1.0000 - val_loss: 0.0196\n",
            "Epoch 50/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0201 - val_accuracy: 1.0000 - val_loss: 0.0190\n",
            "Epoch 51/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0186 - val_accuracy: 1.0000 - val_loss: 0.0184\n",
            "Epoch 52/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0183 - val_accuracy: 1.0000 - val_loss: 0.0178\n",
            "Epoch 53/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0185 - val_accuracy: 1.0000 - val_loss: 0.0173\n",
            "Epoch 54/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0172 - val_accuracy: 1.0000 - val_loss: 0.0167\n",
            "Epoch 55/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0169 - val_accuracy: 1.0000 - val_loss: 0.0163\n",
            "Epoch 56/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0164 - val_accuracy: 1.0000 - val_loss: 0.0158\n",
            "Epoch 57/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0158 - val_accuracy: 1.0000 - val_loss: 0.0154\n",
            "Epoch 58/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0157 - val_accuracy: 1.0000 - val_loss: 0.0149\n",
            "Epoch 59/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0154 - val_accuracy: 1.0000 - val_loss: 0.0145\n",
            "Epoch 60/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0148 - val_accuracy: 1.0000 - val_loss: 0.0142\n",
            "Epoch 61/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0139 - val_accuracy: 1.0000 - val_loss: 0.0138\n",
            "Epoch 62/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0141 - val_accuracy: 1.0000 - val_loss: 0.0134\n",
            "Epoch 63/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0130 - val_accuracy: 1.0000 - val_loss: 0.0131\n",
            "Epoch 64/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0136 - val_accuracy: 1.0000 - val_loss: 0.0128\n",
            "Epoch 65/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0134 - val_accuracy: 1.0000 - val_loss: 0.0125\n",
            "Epoch 66/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0124 - val_accuracy: 1.0000 - val_loss: 0.0121\n",
            "Epoch 67/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0126 - val_accuracy: 1.0000 - val_loss: 0.0119\n",
            "Epoch 68/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0125 - val_accuracy: 1.0000 - val_loss: 0.0116\n",
            "Epoch 69/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0116 - val_accuracy: 1.0000 - val_loss: 0.0113\n",
            "Epoch 70/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0111 - val_accuracy: 1.0000 - val_loss: 0.0111\n",
            "Epoch 71/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0115 - val_accuracy: 1.0000 - val_loss: 0.0108\n",
            "Epoch 72/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0112 - val_accuracy: 1.0000 - val_loss: 0.0106\n",
            "Epoch 73/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0107 - val_accuracy: 1.0000 - val_loss: 0.0103\n",
            "Epoch 74/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0106 - val_accuracy: 1.0000 - val_loss: 0.0101\n",
            "Epoch 75/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0105 - val_accuracy: 1.0000 - val_loss: 0.0099\n",
            "Epoch 76/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0102 - val_accuracy: 1.0000 - val_loss: 0.0097\n",
            "Epoch 77/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0098 - val_accuracy: 1.0000 - val_loss: 0.0095\n",
            "Epoch 78/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0094 - val_accuracy: 1.0000 - val_loss: 0.0093\n",
            "Epoch 79/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0095 - val_accuracy: 1.0000 - val_loss: 0.0091\n",
            "Epoch 80/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0091 - val_accuracy: 1.0000 - val_loss: 0.0089\n",
            "Epoch 81/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0088 - val_accuracy: 1.0000 - val_loss: 0.0087\n",
            "Epoch 82/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0087 - val_accuracy: 1.0000 - val_loss: 0.0086\n",
            "Epoch 83/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0088 - val_accuracy: 1.0000 - val_loss: 0.0084\n",
            "Epoch 84/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0086 - val_accuracy: 1.0000 - val_loss: 0.0082\n",
            "Epoch 85/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0083 - val_accuracy: 1.0000 - val_loss: 0.0081\n",
            "Epoch 86/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0082 - val_accuracy: 1.0000 - val_loss: 0.0079\n",
            "Epoch 87/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0080 - val_accuracy: 1.0000 - val_loss: 0.0078\n",
            "Epoch 88/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0085 - val_accuracy: 1.0000 - val_loss: 0.0076\n",
            "Epoch 89/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 1.0000 - val_loss: 0.0075\n",
            "Epoch 90/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0076 - val_accuracy: 1.0000 - val_loss: 0.0073\n",
            "Epoch 91/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 1.0000 - val_loss: 0.0072\n",
            "Epoch 92/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0074 - val_accuracy: 1.0000 - val_loss: 0.0071\n",
            "Epoch 93/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 1.0000 - val_loss: 0.0070\n",
            "Epoch 94/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 1.0000 - val_loss: 0.0068\n",
            "Epoch 95/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 1.0000 - val_loss: 0.0067\n",
            "Epoch 96/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 1.0000 - val_loss: 0.0066\n",
            "Epoch 97/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 1.0000 - val_loss: 0.0065\n",
            "Epoch 98/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 1.0000 - val_loss: 0.0064\n",
            "Epoch 99/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0064 - val_accuracy: 1.0000 - val_loss: 0.0063\n",
            "Epoch 100/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0064 - val_accuracy: 1.0000 - val_loss: 0.0062\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 1.0000 - loss: 0.0062\n",
            "Test Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que.5)How do you add dropout to a neural network model to prevent overfitting!"
      ],
      "metadata": {
        "id": "KDojbE1varM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load and prepare the data (Iris dataset for example)\n",
        "data = load_iris()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Labels\n",
        "\n",
        "# Convert labels to binary for simplicity (e.g., class 0 vs classes 1 and 2)\n",
        "y = (y == 0).astype(int)  # Binary classification: Class 0 vs Class 1 or 2\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Add a hidden layer with ReLU activation and dropout\n",
        "model.add(Dense(10, input_dim=4, activation='relu'))\n",
        "model.add(Dropout(0.2))  # Dropout layer with 20% dropout rate\n",
        "\n",
        "# Add another hidden layer with ReLU activation and dropout\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dropout(0.2))  # Dropout layer with 20% dropout rate\n",
        "\n",
        "# Output layer with Sigmoid activation for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=10, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtP-pZ7Gaszj",
        "outputId": "04b0a1e1-cf49-44e3-f9c7-e10cffce942b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.2861 - loss: 0.9545 - val_accuracy: 0.0000e+00 - val_loss: 0.7834\n",
            "Epoch 2/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3855 - loss: 0.8207 - val_accuracy: 0.3667 - val_loss: 0.7139\n",
            "Epoch 3/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4609 - loss: 0.7758 - val_accuracy: 0.6667 - val_loss: 0.6534\n",
            "Epoch 4/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5220 - loss: 0.7275 - val_accuracy: 0.6667 - val_loss: 0.6119\n",
            "Epoch 5/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6276 - loss: 0.6257 - val_accuracy: 0.6667 - val_loss: 0.5825\n",
            "Epoch 6/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7371 - loss: 0.5945 - val_accuracy: 0.9000 - val_loss: 0.5538\n",
            "Epoch 7/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6948 - loss: 0.6071 - val_accuracy: 1.0000 - val_loss: 0.5244\n",
            "Epoch 8/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8266 - loss: 0.5262 - val_accuracy: 1.0000 - val_loss: 0.4951\n",
            "Epoch 9/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7849 - loss: 0.5328 - val_accuracy: 1.0000 - val_loss: 0.4690\n",
            "Epoch 10/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7345 - loss: 0.5173 - val_accuracy: 1.0000 - val_loss: 0.4450\n",
            "Epoch 11/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7881 - loss: 0.5278 - val_accuracy: 1.0000 - val_loss: 0.4243\n",
            "Epoch 12/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7878 - loss: 0.4666 - val_accuracy: 1.0000 - val_loss: 0.4064\n",
            "Epoch 13/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9304 - loss: 0.4284 - val_accuracy: 1.0000 - val_loss: 0.3830\n",
            "Epoch 14/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8471 - loss: 0.4359 - val_accuracy: 1.0000 - val_loss: 0.3598\n",
            "Epoch 15/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9090 - loss: 0.3882 - val_accuracy: 1.0000 - val_loss: 0.3371\n",
            "Epoch 16/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8432 - loss: 0.4294 - val_accuracy: 1.0000 - val_loss: 0.3162\n",
            "Epoch 17/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8760 - loss: 0.3964 - val_accuracy: 1.0000 - val_loss: 0.2970\n",
            "Epoch 18/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8824 - loss: 0.3467 - val_accuracy: 1.0000 - val_loss: 0.2785\n",
            "Epoch 19/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9248 - loss: 0.3186 - val_accuracy: 1.0000 - val_loss: 0.2624\n",
            "Epoch 20/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9611 - loss: 0.2807 - val_accuracy: 1.0000 - val_loss: 0.2420\n",
            "Epoch 21/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8966 - loss: 0.3203 - val_accuracy: 1.0000 - val_loss: 0.2259\n",
            "Epoch 22/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8732 - loss: 0.3198 - val_accuracy: 1.0000 - val_loss: 0.2120\n",
            "Epoch 23/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9640 - loss: 0.2257 - val_accuracy: 1.0000 - val_loss: 0.1979\n",
            "Epoch 24/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8779 - loss: 0.2765 - val_accuracy: 1.0000 - val_loss: 0.1844\n",
            "Epoch 25/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8790 - loss: 0.2825 - val_accuracy: 1.0000 - val_loss: 0.1719\n",
            "Epoch 26/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9388 - loss: 0.2482 - val_accuracy: 1.0000 - val_loss: 0.1598\n",
            "Epoch 27/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9346 - loss: 0.2457 - val_accuracy: 1.0000 - val_loss: 0.1483\n",
            "Epoch 28/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9587 - loss: 0.1965 - val_accuracy: 1.0000 - val_loss: 0.1380\n",
            "Epoch 29/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9483 - loss: 0.2121 - val_accuracy: 1.0000 - val_loss: 0.1280\n",
            "Epoch 30/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9841 - loss: 0.1896 - val_accuracy: 1.0000 - val_loss: 0.1196\n",
            "Epoch 31/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9414 - loss: 0.1971 - val_accuracy: 1.0000 - val_loss: 0.1099\n",
            "Epoch 32/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9088 - loss: 0.1857 - val_accuracy: 1.0000 - val_loss: 0.1016\n",
            "Epoch 33/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9683 - loss: 0.1498 - val_accuracy: 1.0000 - val_loss: 0.0947\n",
            "Epoch 34/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9954 - loss: 0.1585 - val_accuracy: 1.0000 - val_loss: 0.0873\n",
            "Epoch 35/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9610 - loss: 0.1727 - val_accuracy: 1.0000 - val_loss: 0.0821\n",
            "Epoch 36/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9693 - loss: 0.1516 - val_accuracy: 1.0000 - val_loss: 0.0772\n",
            "Epoch 37/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9642 - loss: 0.1601 - val_accuracy: 1.0000 - val_loss: 0.0716\n",
            "Epoch 38/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9636 - loss: 0.1487 - val_accuracy: 1.0000 - val_loss: 0.0646\n",
            "Epoch 39/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9401 - loss: 0.1528 - val_accuracy: 1.0000 - val_loss: 0.0611\n",
            "Epoch 40/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9298 - loss: 0.1393 - val_accuracy: 1.0000 - val_loss: 0.0581\n",
            "Epoch 41/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9754 - loss: 0.0943 - val_accuracy: 1.0000 - val_loss: 0.0536\n",
            "Epoch 42/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9860 - loss: 0.1127 - val_accuracy: 1.0000 - val_loss: 0.0485\n",
            "Epoch 43/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9393 - loss: 0.1362 - val_accuracy: 1.0000 - val_loss: 0.0448\n",
            "Epoch 44/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9931 - loss: 0.0916 - val_accuracy: 1.0000 - val_loss: 0.0412\n",
            "Epoch 45/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9768 - loss: 0.1011 - val_accuracy: 1.0000 - val_loss: 0.0380\n",
            "Epoch 46/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9441 - loss: 0.1331 - val_accuracy: 1.0000 - val_loss: 0.0355\n",
            "Epoch 47/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9274 - loss: 0.1562 - val_accuracy: 1.0000 - val_loss: 0.0344\n",
            "Epoch 48/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9582 - loss: 0.1029 - val_accuracy: 1.0000 - val_loss: 0.0329\n",
            "Epoch 49/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9520 - loss: 0.1126 - val_accuracy: 1.0000 - val_loss: 0.0314\n",
            "Epoch 50/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9863 - loss: 0.0925 - val_accuracy: 1.0000 - val_loss: 0.0293\n",
            "Epoch 51/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9980 - loss: 0.0614 - val_accuracy: 1.0000 - val_loss: 0.0274\n",
            "Epoch 52/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9918 - loss: 0.0772 - val_accuracy: 1.0000 - val_loss: 0.0258\n",
            "Epoch 53/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9713 - loss: 0.0822 - val_accuracy: 1.0000 - val_loss: 0.0242\n",
            "Epoch 54/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9643 - loss: 0.0838 - val_accuracy: 1.0000 - val_loss: 0.0226\n",
            "Epoch 55/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9798 - loss: 0.0859 - val_accuracy: 1.0000 - val_loss: 0.0208\n",
            "Epoch 56/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9810 - loss: 0.0721 - val_accuracy: 1.0000 - val_loss: 0.0194\n",
            "Epoch 57/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9489 - loss: 0.1036 - val_accuracy: 1.0000 - val_loss: 0.0185\n",
            "Epoch 58/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0647 - val_accuracy: 1.0000 - val_loss: 0.0178\n",
            "Epoch 59/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9265 - loss: 0.1186 - val_accuracy: 1.0000 - val_loss: 0.0171\n",
            "Epoch 60/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9719 - loss: 0.0847 - val_accuracy: 1.0000 - val_loss: 0.0162\n",
            "Epoch 61/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9503 - loss: 0.1353 - val_accuracy: 1.0000 - val_loss: 0.0152\n",
            "Epoch 62/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9898 - loss: 0.0702 - val_accuracy: 1.0000 - val_loss: 0.0142\n",
            "Epoch 63/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9670 - loss: 0.0926 - val_accuracy: 1.0000 - val_loss: 0.0135\n",
            "Epoch 64/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9928 - loss: 0.0521 - val_accuracy: 1.0000 - val_loss: 0.0126\n",
            "Epoch 65/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9843 - loss: 0.0638 - val_accuracy: 1.0000 - val_loss: 0.0119\n",
            "Epoch 66/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9685 - loss: 0.0987 - val_accuracy: 1.0000 - val_loss: 0.0112\n",
            "Epoch 67/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9851 - loss: 0.0466 - val_accuracy: 1.0000 - val_loss: 0.0104\n",
            "Epoch 68/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9843 - loss: 0.0620 - val_accuracy: 1.0000 - val_loss: 0.0096\n",
            "Epoch 69/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9953 - loss: 0.0702 - val_accuracy: 1.0000 - val_loss: 0.0089\n",
            "Epoch 70/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9896 - loss: 0.0585 - val_accuracy: 1.0000 - val_loss: 0.0085\n",
            "Epoch 71/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9719 - loss: 0.0624 - val_accuracy: 1.0000 - val_loss: 0.0081\n",
            "Epoch 72/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9863 - loss: 0.0586 - val_accuracy: 1.0000 - val_loss: 0.0076\n",
            "Epoch 73/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9595 - loss: 0.0989 - val_accuracy: 1.0000 - val_loss: 0.0074\n",
            "Epoch 74/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9775 - loss: 0.0714 - val_accuracy: 1.0000 - val_loss: 0.0068\n",
            "Epoch 75/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9911 - loss: 0.0699 - val_accuracy: 1.0000 - val_loss: 0.0064\n",
            "Epoch 76/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9972 - loss: 0.0425 - val_accuracy: 1.0000 - val_loss: 0.0062\n",
            "Epoch 77/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9648 - loss: 0.0682 - val_accuracy: 1.0000 - val_loss: 0.0059\n",
            "Epoch 78/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9690 - loss: 0.1082 - val_accuracy: 1.0000 - val_loss: 0.0056\n",
            "Epoch 79/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9832 - loss: 0.0968 - val_accuracy: 1.0000 - val_loss: 0.0054\n",
            "Epoch 80/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0254 - val_accuracy: 1.0000 - val_loss: 0.0052\n",
            "Epoch 81/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9945 - loss: 0.0621 - val_accuracy: 1.0000 - val_loss: 0.0049\n",
            "Epoch 82/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9987 - loss: 0.0405 - val_accuracy: 1.0000 - val_loss: 0.0046\n",
            "Epoch 83/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9801 - loss: 0.0528 - val_accuracy: 1.0000 - val_loss: 0.0043\n",
            "Epoch 84/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9814 - loss: 0.0426 - val_accuracy: 1.0000 - val_loss: 0.0041\n",
            "Epoch 85/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9787 - loss: 0.0629 - val_accuracy: 1.0000 - val_loss: 0.0040\n",
            "Epoch 86/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9613 - loss: 0.0738 - val_accuracy: 1.0000 - val_loss: 0.0040\n",
            "Epoch 87/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9819 - loss: 0.0351 - val_accuracy: 1.0000 - val_loss: 0.0039\n",
            "Epoch 88/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9515 - loss: 0.0878 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
            "Epoch 89/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9838 - loss: 0.0797 - val_accuracy: 1.0000 - val_loss: 0.0035\n",
            "Epoch 90/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9943 - loss: 0.0602 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
            "Epoch 91/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9972 - loss: 0.0422 - val_accuracy: 1.0000 - val_loss: 0.0030\n",
            "Epoch 92/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9578 - loss: 0.0610 - val_accuracy: 1.0000 - val_loss: 0.0030\n",
            "Epoch 93/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0291 - val_accuracy: 1.0000 - val_loss: 0.0031\n",
            "Epoch 94/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9826 - loss: 0.0321 - val_accuracy: 1.0000 - val_loss: 0.0029\n",
            "Epoch 95/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9708 - loss: 0.0830 - val_accuracy: 1.0000 - val_loss: 0.0029\n",
            "Epoch 96/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9755 - loss: 0.0541 - val_accuracy: 1.0000 - val_loss: 0.0028\n",
            "Epoch 97/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9960 - loss: 0.0326 - val_accuracy: 1.0000 - val_loss: 0.0027\n",
            "Epoch 98/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9430 - loss: 0.0771 - val_accuracy: 1.0000 - val_loss: 0.0026\n",
            "Epoch 99/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9775 - loss: 0.0625 - val_accuracy: 1.0000 - val_loss: 0.0025\n",
            "Epoch 100/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0262 - val_accuracy: 1.0000 - val_loss: 0.0023\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.0023\n",
            "Test Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que.6)How do you manually implement forward propagation in a simple neural network!"
      ],
      "metadata": {
        "id": "XrZ8gukya14f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sigmoid Activation Function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Sigmoid Derivative (for later use in backpropagation, if needed)\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Initialize input data (e.g., XOR problem with two inputs)\n",
        "# X is the input matrix (2 input features)\n",
        "X = np.array([[0, 0],\n",
        "              [0, 1],\n",
        "              [1, 0],\n",
        "              [1, 1]])\n",
        "\n",
        "# Expected output (Y)\n",
        "y = np.array([[0],\n",
        "              [1],\n",
        "              [1],\n",
        "              [0]])\n",
        "\n",
        "# Initialize weights and biases\n",
        "# 2 inputs, 2 neurons in the hidden layer\n",
        "input_layer_neurons = 2\n",
        "hidden_layer_neurons = 2\n",
        "output_layer_neurons = 1\n",
        "\n",
        "# Randomly initialize weights and biases\n",
        "# Weights for input to hidden layer (2 inputs, 2 neurons in hidden layer)\n",
        "w1 = np.random.rand(input_layer_neurons, hidden_layer_neurons)\n",
        "\n",
        "# Bias for hidden layer (1 for each neuron in the hidden layer)\n",
        "b1 = np.random.rand(1, hidden_layer_neurons)\n",
        "\n",
        "# Weights for hidden to output layer (2 hidden neurons, 1 output neuron)\n",
        "w2 = np.random.rand(hidden_layer_neurons, output_layer_neurons)\n",
        "\n",
        "# Bias for output layer\n",
        "b2 = np.random.rand(1, output_layer_neurons)\n",
        "\n",
        "# Forward propagation\n",
        "def forward_propagation(X):\n",
        "    # Hidden layer input\n",
        "    z1 = np.dot(X, w1) + b1  # Matrix multiplication + bias addition\n",
        "    # Hidden layer output (after applying sigmoid activation)\n",
        "    a1 = sigmoid(z1)\n",
        "\n",
        "    # Output layer input\n",
        "    z2 = np.dot(a1, w2) + b2  # Matrix multiplication + bias addition\n",
        "    # Output layer output (after applying sigmoid activation)\n",
        "    a2 = sigmoid(z2)\n",
        "\n",
        "    return a2  # Final output after forward propagation\n",
        "\n",
        "# Perform forward propagation on the input data\n",
        "output = forward_propagation(X)\n",
        "print(\"Output from the neural network:\\n\", output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5R2BfqwAa6XR",
        "outputId": "e2c44e40-eecc-4f47-9a43-58c6e59ce2bf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output from the neural network:\n",
            " [[0.81333414]\n",
            " [0.83144069]\n",
            " [0.82651852]\n",
            " [0.83968207]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que.7)How do you add batch normalization to a neural network model in Keras!"
      ],
      "metadata": {
        "id": "j4sCP4I3bAd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load and prepare the data (Iris dataset for example)\n",
        "data = load_iris()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Labels\n",
        "\n",
        "# Convert labels to binary for simplicity (e.g., class 0 vs classes 1 and 2)\n",
        "y = (y == 0).astype(int)  # Binary classification: Class 0 vs Class 1 or 2\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Add a hidden layer with Batch Normalization\n",
        "model.add(Dense(10, input_dim=4))  # Dense layer with 10 neurons\n",
        "model.add(BatchNormalization())  # Batch Normalization layer\n",
        "model.add(Dense(10, activation='relu'))  # ReLU activation for the second hidden layer\n",
        "\n",
        "# Add output layer with Sigmoid activation for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=10, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qA9u5gsfbFG0",
        "outputId": "86a961bc-adac-4911-b8ac-9cbbaa100e3a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.7044 - loss: 0.8042 - val_accuracy: 0.6667 - val_loss: 1.0977\n",
            "Epoch 2/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6930 - loss: 0.6871 - val_accuracy: 0.6667 - val_loss: 1.0631\n",
            "Epoch 3/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6412 - loss: 0.6157 - val_accuracy: 0.6667 - val_loss: 0.9644\n",
            "Epoch 4/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6976 - loss: 0.5458 - val_accuracy: 0.6667 - val_loss: 0.8478\n",
            "Epoch 5/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7117 - loss: 0.4721 - val_accuracy: 0.6667 - val_loss: 0.7397\n",
            "Epoch 6/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6183 - loss: 0.4512 - val_accuracy: 0.6667 - val_loss: 0.6135\n",
            "Epoch 7/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6895 - loss: 0.3917 - val_accuracy: 0.6667 - val_loss: 0.5046\n",
            "Epoch 8/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7128 - loss: 0.3656 - val_accuracy: 0.6667 - val_loss: 0.4323\n",
            "Epoch 9/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9746 - loss: 0.3268 - val_accuracy: 0.6667 - val_loss: 0.3838\n",
            "Epoch 10/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9794 - loss: 0.2910 - val_accuracy: 0.6667 - val_loss: 0.3194\n",
            "Epoch 11/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9294 - loss: 0.3001 - val_accuracy: 0.8333 - val_loss: 0.2518\n",
            "Epoch 12/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9483 - loss: 0.2427 - val_accuracy: 0.9667 - val_loss: 0.1931\n",
            "Epoch 13/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9339 - loss: 0.2362 - val_accuracy: 0.9667 - val_loss: 0.1490\n",
            "Epoch 14/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9980 - loss: 0.1605 - val_accuracy: 1.0000 - val_loss: 0.1182\n",
            "Epoch 15/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9670 - loss: 0.1402 - val_accuracy: 1.0000 - val_loss: 0.0977\n",
            "Epoch 16/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9914 - loss: 0.1230 - val_accuracy: 1.0000 - val_loss: 0.0836\n",
            "Epoch 17/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9796 - loss: 0.1325 - val_accuracy: 1.0000 - val_loss: 0.0772\n",
            "Epoch 18/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9469 - loss: 0.1583 - val_accuracy: 1.0000 - val_loss: 0.0748\n",
            "Epoch 19/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9607 - loss: 0.1532 - val_accuracy: 1.0000 - val_loss: 0.0755\n",
            "Epoch 20/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9660 - loss: 0.1391 - val_accuracy: 1.0000 - val_loss: 0.0795\n",
            "Epoch 21/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9928 - loss: 0.0924 - val_accuracy: 0.9667 - val_loss: 0.0855\n",
            "Epoch 22/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0906 - val_accuracy: 0.9667 - val_loss: 0.0911\n",
            "Epoch 23/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9857 - loss: 0.1037 - val_accuracy: 0.9667 - val_loss: 0.0950\n",
            "Epoch 24/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9945 - loss: 0.0810 - val_accuracy: 0.9667 - val_loss: 0.0931\n",
            "Epoch 25/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0499 - val_accuracy: 0.9667 - val_loss: 0.0910\n",
            "Epoch 26/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9832 - loss: 0.1405 - val_accuracy: 0.9667 - val_loss: 0.0984\n",
            "Epoch 27/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9882 - loss: 0.0772 - val_accuracy: 0.9667 - val_loss: 0.0954\n",
            "Epoch 28/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0398 - val_accuracy: 0.9667 - val_loss: 0.0879\n",
            "Epoch 29/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0543 - val_accuracy: 0.9667 - val_loss: 0.0895\n",
            "Epoch 30/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9591 - loss: 0.1373 - val_accuracy: 0.9667 - val_loss: 0.0864\n",
            "Epoch 31/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9915 - loss: 0.0665 - val_accuracy: 0.9667 - val_loss: 0.0799\n",
            "Epoch 32/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9980 - loss: 0.0423 - val_accuracy: 0.9667 - val_loss: 0.0760\n",
            "Epoch 33/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9915 - loss: 0.0428 - val_accuracy: 0.9667 - val_loss: 0.0659\n",
            "Epoch 34/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9755 - loss: 0.0736 - val_accuracy: 0.9667 - val_loss: 0.0601\n",
            "Epoch 35/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9731 - loss: 0.0546 - val_accuracy: 0.9667 - val_loss: 0.0590\n",
            "Epoch 36/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0383 - val_accuracy: 0.9667 - val_loss: 0.0569\n",
            "Epoch 37/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9987 - loss: 0.0291 - val_accuracy: 1.0000 - val_loss: 0.0497\n",
            "Epoch 38/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0335 - val_accuracy: 1.0000 - val_loss: 0.0462\n",
            "Epoch 39/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9236 - loss: 0.1663 - val_accuracy: 1.0000 - val_loss: 0.0437\n",
            "Epoch 40/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9909 - loss: 0.0328 - val_accuracy: 0.9667 - val_loss: 0.0573\n",
            "Epoch 41/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9611 - loss: 0.1280 - val_accuracy: 0.9667 - val_loss: 0.0551\n",
            "Epoch 42/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0223 - val_accuracy: 1.0000 - val_loss: 0.0510\n",
            "Epoch 43/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9657 - loss: 0.0743 - val_accuracy: 1.0000 - val_loss: 0.0481\n",
            "Epoch 44/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9931 - loss: 0.0491 - val_accuracy: 1.0000 - val_loss: 0.0349\n",
            "Epoch 45/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8994 - loss: 0.2885 - val_accuracy: 1.0000 - val_loss: 0.0354\n",
            "Epoch 46/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0182 - val_accuracy: 1.0000 - val_loss: 0.0367\n",
            "Epoch 47/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0199 - val_accuracy: 1.0000 - val_loss: 0.0335\n",
            "Epoch 48/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9892 - loss: 0.0446 - val_accuracy: 1.0000 - val_loss: 0.0314\n",
            "Epoch 49/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0530 - val_accuracy: 1.0000 - val_loss: 0.0353\n",
            "Epoch 50/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0412 - val_accuracy: 1.0000 - val_loss: 0.0429\n",
            "Epoch 51/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9653 - loss: 0.0773 - val_accuracy: 1.0000 - val_loss: 0.0446\n",
            "Epoch 52/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0316 - val_accuracy: 1.0000 - val_loss: 0.0451\n",
            "Epoch 53/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0231 - val_accuracy: 1.0000 - val_loss: 0.0362\n",
            "Epoch 54/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0117 - val_accuracy: 1.0000 - val_loss: 0.0284\n",
            "Epoch 55/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0115 - val_accuracy: 1.0000 - val_loss: 0.0200\n",
            "Epoch 56/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0190 - val_accuracy: 1.0000 - val_loss: 0.0168\n",
            "Epoch 57/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9943 - loss: 0.0362 - val_accuracy: 1.0000 - val_loss: 0.0123\n",
            "Epoch 58/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9964 - loss: 0.0236 - val_accuracy: 1.0000 - val_loss: 0.0111\n",
            "Epoch 59/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0259 - val_accuracy: 1.0000 - val_loss: 0.0103\n",
            "Epoch 60/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9987 - loss: 0.0116 - val_accuracy: 1.0000 - val_loss: 0.0098\n",
            "Epoch 61/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9954 - loss: 0.0173 - val_accuracy: 1.0000 - val_loss: 0.0093\n",
            "Epoch 62/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9925 - loss: 0.0287 - val_accuracy: 1.0000 - val_loss: 0.0108\n",
            "Epoch 63/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0076 - val_accuracy: 1.0000 - val_loss: 0.0174\n",
            "Epoch 64/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0244 - val_accuracy: 1.0000 - val_loss: 0.0178\n",
            "Epoch 65/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9698 - loss: 0.1126 - val_accuracy: 1.0000 - val_loss: 0.0148\n",
            "Epoch 66/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0093 - val_accuracy: 1.0000 - val_loss: 0.0137\n",
            "Epoch 67/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0076 - val_accuracy: 1.0000 - val_loss: 0.0103\n",
            "Epoch 68/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0424 - val_accuracy: 1.0000 - val_loss: 0.0058\n",
            "Epoch 69/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9265 - loss: 0.1868 - val_accuracy: 1.0000 - val_loss: 0.0075\n",
            "Epoch 70/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0201 - val_accuracy: 1.0000 - val_loss: 0.0080\n",
            "Epoch 71/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9987 - loss: 0.0210 - val_accuracy: 1.0000 - val_loss: 0.0074\n",
            "Epoch 72/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9987 - loss: 0.0096 - val_accuracy: 1.0000 - val_loss: 0.0054\n",
            "Epoch 73/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9924 - loss: 0.0278 - val_accuracy: 1.0000 - val_loss: 0.0052\n",
            "Epoch 74/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8603 - loss: 0.3375 - val_accuracy: 1.0000 - val_loss: 0.0108\n",
            "Epoch 75/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 1.0000 - val_loss: 0.0102\n",
            "Epoch 76/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9685 - loss: 0.0693 - val_accuracy: 1.0000 - val_loss: 0.0058\n",
            "Epoch 77/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0339 - val_accuracy: 1.0000 - val_loss: 0.0051\n",
            "Epoch 78/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9954 - loss: 0.0160 - val_accuracy: 1.0000 - val_loss: 0.0043\n",
            "Epoch 79/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0134 - val_accuracy: 1.0000 - val_loss: 0.0040\n",
            "Epoch 80/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0094 - val_accuracy: 1.0000 - val_loss: 0.0038\n",
            "Epoch 81/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0151 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
            "Epoch 82/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9964 - loss: 0.0210 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
            "Epoch 83/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9775 - loss: 0.0362 - val_accuracy: 1.0000 - val_loss: 0.0042\n",
            "Epoch 84/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0076 - val_accuracy: 1.0000 - val_loss: 0.0041\n",
            "Epoch 85/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9903 - loss: 0.0249 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
            "Epoch 86/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9964 - loss: 0.0206 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
            "Epoch 87/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0120 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
            "Epoch 88/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0128 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
            "Epoch 89/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 0.0042\n",
            "Epoch 90/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9726 - loss: 0.1067 - val_accuracy: 1.0000 - val_loss: 0.0051\n",
            "Epoch 91/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9481 - loss: 0.1052 - val_accuracy: 1.0000 - val_loss: 0.0127\n",
            "Epoch 92/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0355 - val_accuracy: 1.0000 - val_loss: 0.0107\n",
            "Epoch 93/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9954 - loss: 0.0118 - val_accuracy: 1.0000 - val_loss: 0.0057\n",
            "Epoch 94/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9909 - loss: 0.0269 - val_accuracy: 1.0000 - val_loss: 0.0031\n",
            "Epoch 95/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9306 - loss: 0.1544 - val_accuracy: 1.0000 - val_loss: 0.0025\n",
            "Epoch 96/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0115 - val_accuracy: 1.0000 - val_loss: 0.0024\n",
            "Epoch 97/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9894 - loss: 0.0270 - val_accuracy: 1.0000 - val_loss: 0.0024\n",
            "Epoch 98/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9896 - loss: 0.0402 - val_accuracy: 1.0000 - val_loss: 0.0025\n",
            "Epoch 99/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9722 - loss: 0.0670 - val_accuracy: 1.0000 - val_loss: 0.0029\n",
            "Epoch 100/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9896 - loss: 0.0268 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 1.0000 - loss: 0.0034\n",
            "Test Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "QUe.8 How can you visualize the training process with accuracy and loss curves!\n"
      ],
      "metadata": {
        "id": "XF5XxxqhbIvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load and prepare the data (Iris dataset for example)\n",
        "data = load_iris()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Labels\n",
        "\n",
        "# Convert labels to binary for simplicity (e.g., class 0 vs classes 1 and 2)\n",
        "y = (y == 0).astype(int)  # Binary classification: Class 0 vs Class 1 or 2\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Add a hidden layer with 10 neurons and ReLU activation\n",
        "model.add(Dense(10, input_dim=4, activation='relu'))\n",
        "\n",
        "# Add output layer with Sigmoid activation for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model and store the history\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=10, validation_data=(X_test, y_test))\n",
        "\n",
        "# Extract the history of loss and accuracy\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "train_acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "# Plot the training and validation loss\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Loss plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.epoch, train_loss, label='Training Loss')\n",
        "plt.plot(history.epoch, val_loss, label='Validation Loss')\n",
        "plt.title('Loss Curve')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Accuracy plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.epoch, train_acc, label='Training Accuracy')\n",
        "plt.plot(history.epoch, val_acc, label='Validation Accuracy')\n",
        "plt.title('Accuracy Curve')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rk57oun8bLfu",
        "outputId": "112ddf79-e4b6-42ed-d1c1-5f8953ca973e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.6639 - loss: 0.8399 - val_accuracy: 0.6667 - val_loss: 0.7855\n",
            "Epoch 2/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6900 - loss: 0.7369 - val_accuracy: 0.6667 - val_loss: 0.7215\n",
            "Epoch 3/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7232 - loss: 0.6124 - val_accuracy: 0.6667 - val_loss: 0.6639\n",
            "Epoch 4/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6960 - loss: 0.6143 - val_accuracy: 0.6667 - val_loss: 0.6133\n",
            "Epoch 5/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6549 - loss: 0.6308 - val_accuracy: 0.6667 - val_loss: 0.5690\n",
            "Epoch 6/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6351 - loss: 0.6024 - val_accuracy: 0.6667 - val_loss: 0.5279\n",
            "Epoch 7/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7053 - loss: 0.5040 - val_accuracy: 0.6667 - val_loss: 0.4916\n",
            "Epoch 8/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6699 - loss: 0.4957 - val_accuracy: 0.6667 - val_loss: 0.4569\n",
            "Epoch 9/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7676 - loss: 0.3787 - val_accuracy: 0.6667 - val_loss: 0.4259\n",
            "Epoch 10/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7048 - loss: 0.3995 - val_accuracy: 0.6667 - val_loss: 0.3955\n",
            "Epoch 11/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6526 - loss: 0.4135 - val_accuracy: 0.6667 - val_loss: 0.3659\n",
            "Epoch 12/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7016 - loss: 0.3674 - val_accuracy: 0.8000 - val_loss: 0.3392\n",
            "Epoch 13/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8001 - loss: 0.3660 - val_accuracy: 0.9000 - val_loss: 0.3141\n",
            "Epoch 14/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8964 - loss: 0.3361 - val_accuracy: 1.0000 - val_loss: 0.2910\n",
            "Epoch 15/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9161 - loss: 0.3328 - val_accuracy: 1.0000 - val_loss: 0.2692\n",
            "Epoch 16/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9785 - loss: 0.2912 - val_accuracy: 1.0000 - val_loss: 0.2499\n",
            "Epoch 17/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9755 - loss: 0.2472 - val_accuracy: 1.0000 - val_loss: 0.2324\n",
            "Epoch 18/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.2177 - val_accuracy: 1.0000 - val_loss: 0.2156\n",
            "Epoch 19/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.2175 - val_accuracy: 1.0000 - val_loss: 0.2001\n",
            "Epoch 20/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.2217 - val_accuracy: 1.0000 - val_loss: 0.1850\n",
            "Epoch 21/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1877 - val_accuracy: 1.0000 - val_loss: 0.1719\n",
            "Epoch 22/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1837 - val_accuracy: 1.0000 - val_loss: 0.1604\n",
            "Epoch 23/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1671 - val_accuracy: 1.0000 - val_loss: 0.1494\n",
            "Epoch 24/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1506 - val_accuracy: 1.0000 - val_loss: 0.1399\n",
            "Epoch 25/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1517 - val_accuracy: 1.0000 - val_loss: 0.1303\n",
            "Epoch 26/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1480 - val_accuracy: 1.0000 - val_loss: 0.1218\n",
            "Epoch 27/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1324 - val_accuracy: 1.0000 - val_loss: 0.1141\n",
            "Epoch 28/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1230 - val_accuracy: 1.0000 - val_loss: 0.1072\n",
            "Epoch 29/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1098 - val_accuracy: 1.0000 - val_loss: 0.1007\n",
            "Epoch 30/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1130 - val_accuracy: 1.0000 - val_loss: 0.0950\n",
            "Epoch 31/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1023 - val_accuracy: 1.0000 - val_loss: 0.0891\n",
            "Epoch 32/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0937 - val_accuracy: 1.0000 - val_loss: 0.0841\n",
            "Epoch 33/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0946 - val_accuracy: 1.0000 - val_loss: 0.0794\n",
            "Epoch 34/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0985 - val_accuracy: 1.0000 - val_loss: 0.0749\n",
            "Epoch 35/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0779 - val_accuracy: 1.0000 - val_loss: 0.0710\n",
            "Epoch 36/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0749 - val_accuracy: 1.0000 - val_loss: 0.0673\n",
            "Epoch 37/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0773 - val_accuracy: 1.0000 - val_loss: 0.0639\n",
            "Epoch 38/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0635 - val_accuracy: 1.0000 - val_loss: 0.0612\n",
            "Epoch 39/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0678 - val_accuracy: 1.0000 - val_loss: 0.0578\n",
            "Epoch 40/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0583 - val_accuracy: 1.0000 - val_loss: 0.0549\n",
            "Epoch 41/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0665 - val_accuracy: 1.0000 - val_loss: 0.0521\n",
            "Epoch 42/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0552 - val_accuracy: 1.0000 - val_loss: 0.0499\n",
            "Epoch 43/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0635 - val_accuracy: 1.0000 - val_loss: 0.0476\n",
            "Epoch 44/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0493 - val_accuracy: 1.0000 - val_loss: 0.0456\n",
            "Epoch 45/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0466 - val_accuracy: 1.0000 - val_loss: 0.0436\n",
            "Epoch 46/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0495 - val_accuracy: 1.0000 - val_loss: 0.0416\n",
            "Epoch 47/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0477 - val_accuracy: 1.0000 - val_loss: 0.0399\n",
            "Epoch 48/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0422 - val_accuracy: 1.0000 - val_loss: 0.0381\n",
            "Epoch 49/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0414 - val_accuracy: 1.0000 - val_loss: 0.0367\n",
            "Epoch 50/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0391 - val_accuracy: 1.0000 - val_loss: 0.0351\n",
            "Epoch 51/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0389 - val_accuracy: 1.0000 - val_loss: 0.0338\n",
            "Epoch 52/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0379 - val_accuracy: 1.0000 - val_loss: 0.0324\n",
            "Epoch 53/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0359 - val_accuracy: 1.0000 - val_loss: 0.0311\n",
            "Epoch 54/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0392 - val_accuracy: 1.0000 - val_loss: 0.0301\n",
            "Epoch 55/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0347 - val_accuracy: 1.0000 - val_loss: 0.0290\n",
            "Epoch 56/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0318 - val_accuracy: 1.0000 - val_loss: 0.0279\n",
            "Epoch 57/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0301 - val_accuracy: 1.0000 - val_loss: 0.0270\n",
            "Epoch 58/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0290 - val_accuracy: 1.0000 - val_loss: 0.0259\n",
            "Epoch 59/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0326 - val_accuracy: 1.0000 - val_loss: 0.0250\n",
            "Epoch 60/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0333 - val_accuracy: 1.0000 - val_loss: 0.0241\n",
            "Epoch 61/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0237 - val_accuracy: 1.0000 - val_loss: 0.0234\n",
            "Epoch 62/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0242 - val_accuracy: 1.0000 - val_loss: 0.0226\n",
            "Epoch 63/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0301 - val_accuracy: 1.0000 - val_loss: 0.0218\n",
            "Epoch 64/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0232 - val_accuracy: 1.0000 - val_loss: 0.0211\n",
            "Epoch 65/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0242 - val_accuracy: 1.0000 - val_loss: 0.0205\n",
            "Epoch 66/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0247 - val_accuracy: 1.0000 - val_loss: 0.0198\n",
            "Epoch 67/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0203 - val_accuracy: 1.0000 - val_loss: 0.0192\n",
            "Epoch 68/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0223 - val_accuracy: 1.0000 - val_loss: 0.0185\n",
            "Epoch 69/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0223 - val_accuracy: 1.0000 - val_loss: 0.0180\n",
            "Epoch 70/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0214 - val_accuracy: 1.0000 - val_loss: 0.0175\n",
            "Epoch 71/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0201 - val_accuracy: 1.0000 - val_loss: 0.0171\n",
            "Epoch 72/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0204 - val_accuracy: 1.0000 - val_loss: 0.0166\n",
            "Epoch 73/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0201 - val_accuracy: 1.0000 - val_loss: 0.0160\n",
            "Epoch 74/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0188 - val_accuracy: 1.0000 - val_loss: 0.0156\n",
            "Epoch 75/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0205 - val_accuracy: 1.0000 - val_loss: 0.0152\n",
            "Epoch 76/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0180 - val_accuracy: 1.0000 - val_loss: 0.0147\n",
            "Epoch 77/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0176 - val_accuracy: 1.0000 - val_loss: 0.0143\n",
            "Epoch 78/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0200 - val_accuracy: 1.0000 - val_loss: 0.0139\n",
            "Epoch 79/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0174 - val_accuracy: 1.0000 - val_loss: 0.0135\n",
            "Epoch 80/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0160 - val_accuracy: 1.0000 - val_loss: 0.0132\n",
            "Epoch 81/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0141 - val_accuracy: 1.0000 - val_loss: 0.0129\n",
            "Epoch 82/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0137 - val_accuracy: 1.0000 - val_loss: 0.0125\n",
            "Epoch 83/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0127 - val_accuracy: 1.0000 - val_loss: 0.0122\n",
            "Epoch 84/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0135 - val_accuracy: 1.0000 - val_loss: 0.0119\n",
            "Epoch 85/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0120 - val_accuracy: 1.0000 - val_loss: 0.0116\n",
            "Epoch 86/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0156 - val_accuracy: 1.0000 - val_loss: 0.0114\n",
            "Epoch 87/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0127 - val_accuracy: 1.0000 - val_loss: 0.0111\n",
            "Epoch 88/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0126 - val_accuracy: 1.0000 - val_loss: 0.0108\n",
            "Epoch 89/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0143 - val_accuracy: 1.0000 - val_loss: 0.0105\n",
            "Epoch 90/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0121 - val_accuracy: 1.0000 - val_loss: 0.0103\n",
            "Epoch 91/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0116 - val_accuracy: 1.0000 - val_loss: 0.0100\n",
            "Epoch 92/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0116 - val_accuracy: 1.0000 - val_loss: 0.0098\n",
            "Epoch 93/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0101 - val_accuracy: 1.0000 - val_loss: 0.0096\n",
            "Epoch 94/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0103 - val_accuracy: 1.0000 - val_loss: 0.0094\n",
            "Epoch 95/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0126 - val_accuracy: 1.0000 - val_loss: 0.0091\n",
            "Epoch 96/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0107 - val_accuracy: 1.0000 - val_loss: 0.0090\n",
            "Epoch 97/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0123 - val_accuracy: 1.0000 - val_loss: 0.0087\n",
            "Epoch 98/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0089 - val_accuracy: 1.0000 - val_loss: 0.0085\n",
            "Epoch 99/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0117 - val_accuracy: 1.0000 - val_loss: 0.0084\n",
            "Epoch 100/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0105 - val_accuracy: 1.0000 - val_loss: 0.0082\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que.9)How can you use gradient clipping in Keras to control the gradient size and prevent exploding gradients!"
      ],
      "metadata": {
        "id": "texB919Obaou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load and prepare the data (Iris dataset for example)\n",
        "data = load_iris()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Labels\n",
        "\n",
        "# Convert labels to binary for simplicity (e.g., class 0 vs classes 1 and 2)\n",
        "y = (y == 0).astype(int)  # Binary classification: Class 0 vs Class 1 or 2\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Add a hidden layer with 10 neurons and ReLU activation\n",
        "model.add(Dense(10, input_dim=4, activation='relu'))\n",
        "\n",
        "# Add output layer with Sigmoid activation for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Define an Adam optimizer with gradient clipping\n",
        "optimizer = Adam(clipvalue=1.0)  # Clip gradients to a value of 1.0\n",
        "\n",
        "# Compile the model with the optimizer\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=10, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mn3VNZz-beYg",
        "outputId": "79195b10-9264-4635-8472-d668906930ab"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.7381 - loss: 0.6523 - val_accuracy: 0.6667 - val_loss: 0.6414\n",
            "Epoch 2/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6719 - loss: 0.6373 - val_accuracy: 0.6667 - val_loss: 0.6084\n",
            "Epoch 3/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6984 - loss: 0.5944 - val_accuracy: 0.6667 - val_loss: 0.5751\n",
            "Epoch 4/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6169 - loss: 0.5952 - val_accuracy: 0.6667 - val_loss: 0.5440\n",
            "Epoch 5/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6517 - loss: 0.5474 - val_accuracy: 0.6667 - val_loss: 0.5161\n",
            "Epoch 6/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6417 - loss: 0.5217 - val_accuracy: 0.6667 - val_loss: 0.4890\n",
            "Epoch 7/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6345 - loss: 0.5029 - val_accuracy: 0.6667 - val_loss: 0.4633\n",
            "Epoch 8/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6284 - loss: 0.4807 - val_accuracy: 0.6667 - val_loss: 0.4378\n",
            "Epoch 9/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6158 - loss: 0.4568 - val_accuracy: 0.6667 - val_loss: 0.4123\n",
            "Epoch 10/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7439 - loss: 0.3851 - val_accuracy: 0.6667 - val_loss: 0.3908\n",
            "Epoch 11/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7576 - loss: 0.3768 - val_accuracy: 0.7333 - val_loss: 0.3708\n",
            "Epoch 12/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8629 - loss: 0.3757 - val_accuracy: 0.9000 - val_loss: 0.3523\n",
            "Epoch 13/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9309 - loss: 0.3345 - val_accuracy: 1.0000 - val_loss: 0.3353\n",
            "Epoch 14/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9903 - loss: 0.3508 - val_accuracy: 1.0000 - val_loss: 0.3186\n",
            "Epoch 15/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9931 - loss: 0.3302 - val_accuracy: 1.0000 - val_loss: 0.3031\n",
            "Epoch 16/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.2973 - val_accuracy: 1.0000 - val_loss: 0.2888\n",
            "Epoch 17/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.2849 - val_accuracy: 1.0000 - val_loss: 0.2742\n",
            "Epoch 18/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.2708 - val_accuracy: 1.0000 - val_loss: 0.2605\n",
            "Epoch 19/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.2568 - val_accuracy: 1.0000 - val_loss: 0.2473\n",
            "Epoch 20/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.2541 - val_accuracy: 1.0000 - val_loss: 0.2350\n",
            "Epoch 21/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.2440 - val_accuracy: 1.0000 - val_loss: 0.2232\n",
            "Epoch 22/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.2240 - val_accuracy: 1.0000 - val_loss: 0.2124\n",
            "Epoch 23/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.2009 - val_accuracy: 1.0000 - val_loss: 0.2022\n",
            "Epoch 24/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.2026 - val_accuracy: 1.0000 - val_loss: 0.1922\n",
            "Epoch 25/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1901 - val_accuracy: 1.0000 - val_loss: 0.1830\n",
            "Epoch 26/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1706 - val_accuracy: 1.0000 - val_loss: 0.1741\n",
            "Epoch 27/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1756 - val_accuracy: 1.0000 - val_loss: 0.1658\n",
            "Epoch 28/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1647 - val_accuracy: 1.0000 - val_loss: 0.1582\n",
            "Epoch 29/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1514 - val_accuracy: 1.0000 - val_loss: 0.1510\n",
            "Epoch 30/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1484 - val_accuracy: 1.0000 - val_loss: 0.1437\n",
            "Epoch 31/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1352 - val_accuracy: 1.0000 - val_loss: 0.1374\n",
            "Epoch 32/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1474 - val_accuracy: 1.0000 - val_loss: 0.1310\n",
            "Epoch 33/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1191 - val_accuracy: 1.0000 - val_loss: 0.1255\n",
            "Epoch 34/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1273 - val_accuracy: 1.0000 - val_loss: 0.1201\n",
            "Epoch 35/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.1266 - val_accuracy: 1.0000 - val_loss: 0.1145\n",
            "Epoch 36/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1212 - val_accuracy: 1.0000 - val_loss: 0.1100\n",
            "Epoch 37/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1189 - val_accuracy: 1.0000 - val_loss: 0.1053\n",
            "Epoch 38/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1034 - val_accuracy: 1.0000 - val_loss: 0.1009\n",
            "Epoch 39/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0971 - val_accuracy: 1.0000 - val_loss: 0.0968\n",
            "Epoch 40/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1030 - val_accuracy: 1.0000 - val_loss: 0.0927\n",
            "Epoch 41/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0975 - val_accuracy: 1.0000 - val_loss: 0.0890\n",
            "Epoch 42/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0938 - val_accuracy: 1.0000 - val_loss: 0.0854\n",
            "Epoch 43/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0931 - val_accuracy: 1.0000 - val_loss: 0.0824\n",
            "Epoch 44/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0899 - val_accuracy: 1.0000 - val_loss: 0.0793\n",
            "Epoch 45/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0739 - val_accuracy: 1.0000 - val_loss: 0.0763\n",
            "Epoch 46/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0755 - val_accuracy: 1.0000 - val_loss: 0.0732\n",
            "Epoch 47/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0669 - val_accuracy: 1.0000 - val_loss: 0.0709\n",
            "Epoch 48/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0718 - val_accuracy: 1.0000 - val_loss: 0.0682\n",
            "Epoch 49/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0754 - val_accuracy: 1.0000 - val_loss: 0.0656\n",
            "Epoch 50/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0676 - val_accuracy: 1.0000 - val_loss: 0.0634\n",
            "Epoch 51/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0634 - val_accuracy: 1.0000 - val_loss: 0.0610\n",
            "Epoch 52/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0595 - val_accuracy: 1.0000 - val_loss: 0.0590\n",
            "Epoch 53/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0598 - val_accuracy: 1.0000 - val_loss: 0.0571\n",
            "Epoch 54/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0605 - val_accuracy: 1.0000 - val_loss: 0.0550\n",
            "Epoch 55/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0573 - val_accuracy: 1.0000 - val_loss: 0.0532\n",
            "Epoch 56/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0545 - val_accuracy: 1.0000 - val_loss: 0.0516\n",
            "Epoch 57/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0516 - val_accuracy: 1.0000 - val_loss: 0.0499\n",
            "Epoch 58/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0545 - val_accuracy: 1.0000 - val_loss: 0.0483\n",
            "Epoch 59/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0444 - val_accuracy: 1.0000 - val_loss: 0.0467\n",
            "Epoch 60/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0493 - val_accuracy: 1.0000 - val_loss: 0.0452\n",
            "Epoch 61/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0512 - val_accuracy: 1.0000 - val_loss: 0.0437\n",
            "Epoch 62/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0419 - val_accuracy: 1.0000 - val_loss: 0.0426\n",
            "Epoch 63/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0409 - val_accuracy: 1.0000 - val_loss: 0.0415\n",
            "Epoch 64/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0439 - val_accuracy: 1.0000 - val_loss: 0.0402\n",
            "Epoch 65/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0409 - val_accuracy: 1.0000 - val_loss: 0.0389\n",
            "Epoch 66/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0382 - val_accuracy: 1.0000 - val_loss: 0.0378\n",
            "Epoch 67/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0352 - val_accuracy: 1.0000 - val_loss: 0.0367\n",
            "Epoch 68/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0368 - val_accuracy: 1.0000 - val_loss: 0.0357\n",
            "Epoch 69/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0342 - val_accuracy: 1.0000 - val_loss: 0.0346\n",
            "Epoch 70/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0306 - val_accuracy: 1.0000 - val_loss: 0.0337\n",
            "Epoch 71/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0346 - val_accuracy: 1.0000 - val_loss: 0.0327\n",
            "Epoch 72/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0329 - val_accuracy: 1.0000 - val_loss: 0.0320\n",
            "Epoch 73/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0317 - val_accuracy: 1.0000 - val_loss: 0.0310\n",
            "Epoch 74/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0317 - val_accuracy: 1.0000 - val_loss: 0.0302\n",
            "Epoch 75/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0344 - val_accuracy: 1.0000 - val_loss: 0.0294\n",
            "Epoch 76/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0313 - val_accuracy: 1.0000 - val_loss: 0.0287\n",
            "Epoch 77/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0325 - val_accuracy: 1.0000 - val_loss: 0.0279\n",
            "Epoch 78/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0322 - val_accuracy: 1.0000 - val_loss: 0.0272\n",
            "Epoch 79/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0262 - val_accuracy: 1.0000 - val_loss: 0.0265\n",
            "Epoch 80/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0283 - val_accuracy: 1.0000 - val_loss: 0.0259\n",
            "Epoch 81/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0263 - val_accuracy: 1.0000 - val_loss: 0.0253\n",
            "Epoch 82/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0231 - val_accuracy: 1.0000 - val_loss: 0.0247\n",
            "Epoch 83/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0217 - val_accuracy: 1.0000 - val_loss: 0.0241\n",
            "Epoch 84/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0243 - val_accuracy: 1.0000 - val_loss: 0.0235\n",
            "Epoch 85/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0247 - val_accuracy: 1.0000 - val_loss: 0.0230\n",
            "Epoch 86/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0273 - val_accuracy: 1.0000 - val_loss: 0.0224\n",
            "Epoch 87/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0217 - val_accuracy: 1.0000 - val_loss: 0.0218\n",
            "Epoch 88/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0234 - val_accuracy: 1.0000 - val_loss: 0.0213\n",
            "Epoch 89/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0216 - val_accuracy: 1.0000 - val_loss: 0.0209\n",
            "Epoch 90/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0199 - val_accuracy: 1.0000 - val_loss: 0.0204\n",
            "Epoch 91/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0213 - val_accuracy: 1.0000 - val_loss: 0.0200\n",
            "Epoch 92/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0185 - val_accuracy: 1.0000 - val_loss: 0.0195\n",
            "Epoch 93/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0172 - val_accuracy: 1.0000 - val_loss: 0.0191\n",
            "Epoch 94/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0189 - val_accuracy: 1.0000 - val_loss: 0.0187\n",
            "Epoch 95/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0208 - val_accuracy: 1.0000 - val_loss: 0.0183\n",
            "Epoch 96/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0193 - val_accuracy: 1.0000 - val_loss: 0.0179\n",
            "Epoch 97/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0189 - val_accuracy: 1.0000 - val_loss: 0.0175\n",
            "Epoch 98/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0159 - val_accuracy: 1.0000 - val_loss: 0.0172\n",
            "Epoch 99/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0188 - val_accuracy: 1.0000 - val_loss: 0.0168\n",
            "Epoch 100/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0189 - val_accuracy: 1.0000 - val_loss: 0.0164\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 1.0000 - loss: 0.0164\n",
            "Test Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que.10))How can you create a custom loss function in Keras!\n"
      ],
      "metadata": {
        "id": "hmdB70Edbjs0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define a custom loss function (Mean Absolute Error + a custom penalty)\n",
        "def custom_loss(y_true, y_pred):\n",
        "    # Calculate mean absolute error\n",
        "    mae = tf.reduce_mean(tf.abs(y_true - y_pred))\n",
        "\n",
        "    # Add a custom penalty (for example, penalizing large differences)\n",
        "    penalty = tf.reduce_mean(tf.square(y_true - y_pred))\n",
        "\n",
        "    # Return the sum of MAE and penalty\n",
        "    return mae + 0.1 * penalty\n",
        "\n",
        "# Load and prepare the data (Iris dataset for example)\n",
        "data = load_iris()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Labels\n",
        "\n",
        "# Convert labels to binary for simplicity (e.g., class 0 vs classes 1 and 2)\n",
        "y = (y == 0).astype(int)  # Binary classification: Class 0 vs Class 1 or 2\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Add a hidden layer with 10 neurons and ReLU activation\n",
        "model.add(Dense(10, input_dim=4, activation='relu'))\n",
        "\n",
        "# Add output layer with Sigmoid activation for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with the custom loss function\n",
        "model.compile(optimizer=Adam(), loss=custom_loss, metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=10, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HB3eIgYEbpKz",
        "outputId": "2bc3afab-def0-423d-8eca-ceb86c21c079"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.3401 - loss: 0.7382 - val_accuracy: 0.3333 - val_loss: 0.7454\n",
            "Epoch 2/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4086 - loss: 0.6685 - val_accuracy: 0.3333 - val_loss: 0.7439\n",
            "Epoch 3/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2986 - loss: 0.7791 - val_accuracy: 0.3333 - val_loss: 0.7428\n",
            "Epoch 4/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3406 - loss: 0.7346 - val_accuracy: 0.3333 - val_loss: 0.7415\n",
            "Epoch 5/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2976 - loss: 0.7776 - val_accuracy: 0.3333 - val_loss: 0.7404\n",
            "Epoch 6/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3671 - loss: 0.7038 - val_accuracy: 0.3333 - val_loss: 0.7393\n",
            "Epoch 7/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3437 - loss: 0.7286 - val_accuracy: 0.3333 - val_loss: 0.7382\n",
            "Epoch 8/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.3485 - loss: 0.7220 - val_accuracy: 0.3333 - val_loss: 0.7372\n",
            "Epoch 9/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2796 - loss: 0.7936 - val_accuracy: 0.3333 - val_loss: 0.7363\n",
            "Epoch 10/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3344 - loss: 0.7339 - val_accuracy: 0.3333 - val_loss: 0.7350\n",
            "Epoch 11/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3135 - loss: 0.7542 - val_accuracy: 0.3333 - val_loss: 0.7330\n",
            "Epoch 12/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3163 - loss: 0.7478 - val_accuracy: 0.3333 - val_loss: 0.7290\n",
            "Epoch 13/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3638 - loss: 0.6930 - val_accuracy: 0.3333 - val_loss: 0.7194\n",
            "Epoch 14/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3260 - loss: 0.7184 - val_accuracy: 0.3333 - val_loss: 0.6898\n",
            "Epoch 15/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3250 - loss: 0.6784 - val_accuracy: 0.3333 - val_loss: 0.6097\n",
            "Epoch 16/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3380 - loss: 0.5789 - val_accuracy: 0.4667 - val_loss: 0.4765\n",
            "Epoch 17/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6292 - loss: 0.4440 - val_accuracy: 1.0000 - val_loss: 0.3615\n",
            "Epoch 18/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9972 - loss: 0.3507 - val_accuracy: 0.9667 - val_loss: 0.3099\n",
            "Epoch 19/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8749 - loss: 0.3147 - val_accuracy: 0.7000 - val_loss: 0.2889\n",
            "Epoch 20/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7230 - loss: 0.3018 - val_accuracy: 0.7000 - val_loss: 0.2741\n",
            "Epoch 21/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7312 - loss: 0.2665 - val_accuracy: 0.7333 - val_loss: 0.2627\n",
            "Epoch 22/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8468 - loss: 0.2698 - val_accuracy: 0.8000 - val_loss: 0.2521\n",
            "Epoch 23/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8682 - loss: 0.2824 - val_accuracy: 0.9667 - val_loss: 0.2410\n",
            "Epoch 24/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9471 - loss: 0.2640 - val_accuracy: 1.0000 - val_loss: 0.2302\n",
            "Epoch 25/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9839 - loss: 0.2245 - val_accuracy: 1.0000 - val_loss: 0.2203\n",
            "Epoch 26/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9747 - loss: 0.2345 - val_accuracy: 1.0000 - val_loss: 0.2092\n",
            "Epoch 27/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.2152 - val_accuracy: 1.0000 - val_loss: 0.1983\n",
            "Epoch 28/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.2045 - val_accuracy: 1.0000 - val_loss: 0.1880\n",
            "Epoch 29/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.2147 - val_accuracy: 1.0000 - val_loss: 0.1769\n",
            "Epoch 30/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1877 - val_accuracy: 1.0000 - val_loss: 0.1683\n",
            "Epoch 31/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1625 - val_accuracy: 1.0000 - val_loss: 0.1588\n",
            "Epoch 32/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1670 - val_accuracy: 1.0000 - val_loss: 0.1495\n",
            "Epoch 33/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1538 - val_accuracy: 1.0000 - val_loss: 0.1411\n",
            "Epoch 34/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1495 - val_accuracy: 1.0000 - val_loss: 0.1329\n",
            "Epoch 35/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1279 - val_accuracy: 1.0000 - val_loss: 0.1258\n",
            "Epoch 36/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1373 - val_accuracy: 1.0000 - val_loss: 0.1184\n",
            "Epoch 37/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1191 - val_accuracy: 1.0000 - val_loss: 0.1117\n",
            "Epoch 38/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1126 - val_accuracy: 1.0000 - val_loss: 0.1052\n",
            "Epoch 39/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1062 - val_accuracy: 1.0000 - val_loss: 0.1000\n",
            "Epoch 40/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0977 - val_accuracy: 1.0000 - val_loss: 0.0946\n",
            "Epoch 41/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0961 - val_accuracy: 1.0000 - val_loss: 0.0894\n",
            "Epoch 42/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0903 - val_accuracy: 1.0000 - val_loss: 0.0847\n",
            "Epoch 43/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0902 - val_accuracy: 1.0000 - val_loss: 0.0802\n",
            "Epoch 44/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0831 - val_accuracy: 1.0000 - val_loss: 0.0761\n",
            "Epoch 45/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0829 - val_accuracy: 1.0000 - val_loss: 0.0725\n",
            "Epoch 46/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0812 - val_accuracy: 1.0000 - val_loss: 0.0686\n",
            "Epoch 47/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0725 - val_accuracy: 1.0000 - val_loss: 0.0653\n",
            "Epoch 48/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0690 - val_accuracy: 1.0000 - val_loss: 0.0621\n",
            "Epoch 49/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0595 - val_accuracy: 1.0000 - val_loss: 0.0593\n",
            "Epoch 50/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0592 - val_accuracy: 1.0000 - val_loss: 0.0568\n",
            "Epoch 51/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0609 - val_accuracy: 1.0000 - val_loss: 0.0541\n",
            "Epoch 52/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0506 - val_accuracy: 1.0000 - val_loss: 0.0515\n",
            "Epoch 53/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 1.0000 - val_loss: 0.0493\n",
            "Epoch 54/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0570 - val_accuracy: 1.0000 - val_loss: 0.0472\n",
            "Epoch 55/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0506 - val_accuracy: 1.0000 - val_loss: 0.0451\n",
            "Epoch 56/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0464 - val_accuracy: 1.0000 - val_loss: 0.0432\n",
            "Epoch 57/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0521 - val_accuracy: 1.0000 - val_loss: 0.0414\n",
            "Epoch 58/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0481 - val_accuracy: 1.0000 - val_loss: 0.0396\n",
            "Epoch 59/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0413 - val_accuracy: 1.0000 - val_loss: 0.0382\n",
            "Epoch 60/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0450 - val_accuracy: 1.0000 - val_loss: 0.0366\n",
            "Epoch 61/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0437 - val_accuracy: 1.0000 - val_loss: 0.0352\n",
            "Epoch 62/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0382 - val_accuracy: 1.0000 - val_loss: 0.0339\n",
            "Epoch 63/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0372 - val_accuracy: 1.0000 - val_loss: 0.0325\n",
            "Epoch 64/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0382 - val_accuracy: 1.0000 - val_loss: 0.0314\n",
            "Epoch 65/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0317 - val_accuracy: 1.0000 - val_loss: 0.0302\n",
            "Epoch 66/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0355 - val_accuracy: 1.0000 - val_loss: 0.0292\n",
            "Epoch 67/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0362 - val_accuracy: 1.0000 - val_loss: 0.0282\n",
            "Epoch 68/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0313 - val_accuracy: 1.0000 - val_loss: 0.0271\n",
            "Epoch 69/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0328 - val_accuracy: 1.0000 - val_loss: 0.0261\n",
            "Epoch 70/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0268 - val_accuracy: 1.0000 - val_loss: 0.0254\n",
            "Epoch 71/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0252 - val_accuracy: 1.0000 - val_loss: 0.0245\n",
            "Epoch 72/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0264 - val_accuracy: 1.0000 - val_loss: 0.0237\n",
            "Epoch 73/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0230 - val_accuracy: 1.0000 - val_loss: 0.0230\n",
            "Epoch 74/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0243 - val_accuracy: 1.0000 - val_loss: 0.0222\n",
            "Epoch 75/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0222 - val_accuracy: 1.0000 - val_loss: 0.0215\n",
            "Epoch 76/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0215 - val_accuracy: 1.0000 - val_loss: 0.0210\n",
            "Epoch 77/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0244 - val_accuracy: 1.0000 - val_loss: 0.0203\n",
            "Epoch 78/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0211 - val_accuracy: 1.0000 - val_loss: 0.0195\n",
            "Epoch 79/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0214 - val_accuracy: 1.0000 - val_loss: 0.0190\n",
            "Epoch 80/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0224 - val_accuracy: 1.0000 - val_loss: 0.0185\n",
            "Epoch 81/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0177 - val_accuracy: 1.0000 - val_loss: 0.0179\n",
            "Epoch 82/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0172 - val_accuracy: 1.0000 - val_loss: 0.0174\n",
            "Epoch 83/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0187 - val_accuracy: 1.0000 - val_loss: 0.0169\n",
            "Epoch 84/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0178 - val_accuracy: 1.0000 - val_loss: 0.0164\n",
            "Epoch 85/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0188 - val_accuracy: 1.0000 - val_loss: 0.0160\n",
            "Epoch 86/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0174 - val_accuracy: 1.0000 - val_loss: 0.0156\n",
            "Epoch 87/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0152 - val_accuracy: 1.0000 - val_loss: 0.0151\n",
            "Epoch 88/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0173 - val_accuracy: 1.0000 - val_loss: 0.0146\n",
            "Epoch 89/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0150 - val_accuracy: 1.0000 - val_loss: 0.0143\n",
            "Epoch 90/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0148 - val_accuracy: 1.0000 - val_loss: 0.0140\n",
            "Epoch 91/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0159 - val_accuracy: 1.0000 - val_loss: 0.0136\n",
            "Epoch 92/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0145 - val_accuracy: 1.0000 - val_loss: 0.0132\n",
            "Epoch 93/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0120 - val_accuracy: 1.0000 - val_loss: 0.0129\n",
            "Epoch 94/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0131 - val_accuracy: 1.0000 - val_loss: 0.0126\n",
            "Epoch 95/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0130 - val_accuracy: 1.0000 - val_loss: 0.0123\n",
            "Epoch 96/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0138 - val_accuracy: 1.0000 - val_loss: 0.0120\n",
            "Epoch 97/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0132 - val_accuracy: 1.0000 - val_loss: 0.0116\n",
            "Epoch 98/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0147 - val_accuracy: 1.0000 - val_loss: 0.0113\n",
            "Epoch 99/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0126 - val_accuracy: 1.0000 - val_loss: 0.0111\n",
            "Epoch 100/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0123 - val_accuracy: 1.0000 - val_loss: 0.0109\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 1.0000 - loss: 0.0109\n",
            "Test Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que.11) How can you visualize the structure of a neural network model in Keras?"
      ],
      "metadata": {
        "id": "wED4l5pybuOQ"
      }
    },
    {
      "source": [
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import plot_model # Import plot_model\n",
        "\n",
        "# Functional API Model Example\n",
        "inputs = Input(shape=(4,))\n",
        "x = Dense(10, activation='relu')(inputs)\n",
        "outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Visualize the model structure\n",
        "plot_model(model, to_file='functional_model_structure.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "print(\"Functional model structure has been saved to 'functional_model_structure.png'\")\n",
        "plot_model(model, to_file='model_structure.png', show_shapes=True, rankdir='LR')"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "id": "e3SHbDn9b6-C",
        "outputId": "719dea18-abe9-46c2-f63a-f3b8fcf3f569"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Functional model structure has been saved to 'functional_model_structure.png'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}